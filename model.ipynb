{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--------------------------- Data Preparation ---------------------------\n",
    "\n",
    "## Read data from CSV\n",
    "doc = pd.read_csv('./datasets/dataset.csv')\n",
    "\n",
    "## Drop out timestamp\n",
    "doc = doc.drop(columns= 'datatime')\n",
    "doc.head()\n",
    "\n",
    "## Convert to np array\n",
    "data = doc.to_numpy()\n",
    "# print(data)\n",
    "\n",
    "## Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "# print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87648, 24, 3) (87648, 1)\n",
      "Train:\ttorch.Size([70118, 24, 3]), torch.Size([70118, 1])\n",
      "Val:\ttorch.Size([17530, 24, 3]), torch.Size([17530, 1])\n"
     ]
    }
   ],
   "source": [
    "## Create data sequence\n",
    "x, y = [], []\n",
    "input_length = 24\n",
    "output_length = 1\n",
    "for i in range(len(data) - input_length - output_length + 1):\n",
    "    x.append(data[i:i+input_length])  # Input sequence (24 time steps)\n",
    "    y.append(data[i+input_length : i+input_length+output_length, 2]) \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "\n",
    "## Convert data to PyTorch tensor\n",
    "x_ten = torch.tensor(x, dtype= torch.float32).to(device)\n",
    "y_ten = torch.tensor(y, dtype= torch.float32).to(device)\n",
    "\n",
    "\n",
    "## Split the data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_ten, y_ten, test_size= 0.2, shuffle= False)\n",
    "print(f'Train:\\t{x_train.shape}, {y_train.shape}\\nVal:\\t{x_val.shape}, {y_val.shape}')\n",
    "\n",
    "## Create batches for train & val\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size= 32, shuffle= True)\n",
    "val_loader = DataLoader(val_dataset, batch_size= 32, shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--------------------------- Model Preparation ---------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, n_hidden, n_lstm_layers= 1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_lstm_layers = n_lstm_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(3, n_hidden, n_lstm_layers, batch_first= True)\n",
    "        self.fc = nn.Linear(self.n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.n_lstm_layers, x.size(0), self.n_hidden).to(device)\n",
    "        c0 = torch.zeros(self.n_lstm_layers, x.size(0), self.n_hidden).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "n_hidden = 2  # Number of LSTM hidden units\n",
    "n_lstm_layers = 1  # Number of LSTM layers\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Train Loss: 1.6447, Val Loss: 0.7943\n",
      "Validation loss improved from 1000000000.0000 to 0.7943. Saving model...\n",
      "Epoch [2/10000], Train Loss: 0.4229, Val Loss: 0.5167\n",
      "Validation loss improved from 0.7943 to 0.5167. Saving model...\n",
      "Epoch [3/10000], Train Loss: 0.3684, Val Loss: 0.5206\n",
      "Epoch [4/10000], Train Loss: 0.3574, Val Loss: 0.4487\n",
      "Validation loss improved from 0.5167 to 0.4487. Saving model...\n",
      "Epoch [5/10000], Train Loss: 0.3530, Val Loss: 0.4724\n",
      "Epoch [6/10000], Train Loss: 0.3500, Val Loss: 0.5136\n",
      "Epoch [7/10000], Train Loss: 0.3479, Val Loss: 0.5388\n",
      "Epoch [8/10000], Train Loss: 0.3466, Val Loss: 0.4415\n",
      "Validation loss improved from 0.4487 to 0.4415. Saving model...\n",
      "Epoch [9/10000], Train Loss: 0.3446, Val Loss: 0.4591\n",
      "Epoch [10/10000], Train Loss: 0.3439, Val Loss: 0.4179\n",
      "Validation loss improved from 0.4415 to 0.4179. Saving model...\n",
      "Epoch [11/10000], Train Loss: 0.3435, Val Loss: 0.4694\n",
      "Epoch [12/10000], Train Loss: 0.3437, Val Loss: 0.5029\n",
      "Epoch [13/10000], Train Loss: 0.3436, Val Loss: 0.4430\n",
      "Epoch [14/10000], Train Loss: 0.3428, Val Loss: 0.4785\n",
      "Epoch [15/10000], Train Loss: 0.3422, Val Loss: 0.4164\n",
      "Validation loss improved from 0.4179 to 0.4164. Saving model...\n",
      "Epoch [16/10000], Train Loss: 0.3415, Val Loss: 0.4147\n",
      "Validation loss improved from 0.4164 to 0.4147. Saving model...\n",
      "Epoch [17/10000], Train Loss: 0.3418, Val Loss: 0.4696\n",
      "Epoch [18/10000], Train Loss: 0.3412, Val Loss: 0.4290\n",
      "Epoch [19/10000], Train Loss: 0.3414, Val Loss: 0.4398\n",
      "Epoch [20/10000], Train Loss: 0.3422, Val Loss: 0.4937\n",
      "Epoch [21/10000], Train Loss: 0.3416, Val Loss: 0.4302\n",
      "Epoch [22/10000], Train Loss: 0.3411, Val Loss: 0.4034\n",
      "Validation loss improved from 0.4147 to 0.4034. Saving model...\n",
      "Epoch [23/10000], Train Loss: 0.3401, Val Loss: 0.5365\n",
      "Epoch [24/10000], Train Loss: 0.3400, Val Loss: 0.4856\n",
      "Epoch [25/10000], Train Loss: 0.3410, Val Loss: 0.4091\n",
      "Epoch [26/10000], Train Loss: 0.3410, Val Loss: 0.4254\n",
      "Epoch [27/10000], Train Loss: 0.3405, Val Loss: 0.4188\n",
      "Epoch [28/10000], Train Loss: 0.3407, Val Loss: 0.4282\n",
      "Epoch [29/10000], Train Loss: 0.3403, Val Loss: 0.4505\n",
      "Epoch [30/10000], Train Loss: 0.3400, Val Loss: 0.4257\n",
      "Epoch [31/10000], Train Loss: 0.3394, Val Loss: 0.4258\n",
      "Epoch [32/10000], Train Loss: 0.3406, Val Loss: 0.4622\n",
      "Epoch [33/10000], Train Loss: 0.3397, Val Loss: 0.4620\n",
      "Epoch [34/10000], Train Loss: 0.3390, Val Loss: 0.4175\n",
      "Epoch [35/10000], Train Loss: 0.3393, Val Loss: 0.4201\n",
      "Epoch [36/10000], Train Loss: 0.3397, Val Loss: 0.4352\n",
      "Epoch [37/10000], Train Loss: 0.3392, Val Loss: 0.4114\n",
      "Epoch [38/10000], Train Loss: 0.3396, Val Loss: 0.4100\n",
      "Epoch [39/10000], Train Loss: 0.3387, Val Loss: 0.4347\n",
      "Epoch [40/10000], Train Loss: 0.3388, Val Loss: 0.4308\n",
      "Epoch [41/10000], Train Loss: 0.3391, Val Loss: 0.4075\n",
      "Epoch [42/10000], Train Loss: 0.3389, Val Loss: 0.4044\n",
      "Epoch [43/10000], Train Loss: 0.3394, Val Loss: 0.4062\n",
      "Epoch [44/10000], Train Loss: 0.3390, Val Loss: 0.4142\n",
      "Epoch [45/10000], Train Loss: 0.3392, Val Loss: 0.4177\n",
      "Epoch [46/10000], Train Loss: 0.3383, Val Loss: 0.4081\n",
      "Epoch [47/10000], Train Loss: 0.3389, Val Loss: 0.4044\n",
      "Epoch [48/10000], Train Loss: 0.3386, Val Loss: 0.3970\n",
      "Validation loss improved from 0.4034 to 0.3970. Saving model...\n",
      "Epoch [49/10000], Train Loss: 0.3385, Val Loss: 0.5194\n",
      "Epoch [50/10000], Train Loss: 0.3388, Val Loss: 0.4448\n",
      "Epoch [51/10000], Train Loss: 0.3390, Val Loss: 0.4835\n",
      "Epoch [52/10000], Train Loss: 0.3387, Val Loss: 0.4025\n",
      "Epoch [53/10000], Train Loss: 0.3389, Val Loss: 0.4726\n",
      "Epoch [54/10000], Train Loss: 0.3384, Val Loss: 0.4220\n",
      "Epoch [55/10000], Train Loss: 0.3382, Val Loss: 0.4414\n",
      "Epoch [56/10000], Train Loss: 0.3383, Val Loss: 0.4039\n",
      "Epoch [57/10000], Train Loss: 0.3379, Val Loss: 0.5294\n",
      "Epoch [58/10000], Train Loss: 0.3376, Val Loss: 0.4298\n",
      "Epoch [59/10000], Train Loss: 0.3384, Val Loss: 0.4281\n",
      "Epoch [60/10000], Train Loss: 0.3377, Val Loss: 0.4161\n",
      "Epoch [61/10000], Train Loss: 0.3380, Val Loss: 0.4129\n",
      "Epoch [62/10000], Train Loss: 0.3375, Val Loss: 0.4454\n",
      "Epoch [63/10000], Train Loss: 0.3378, Val Loss: 0.4658\n",
      "Epoch [64/10000], Train Loss: 0.3379, Val Loss: 0.4159\n",
      "Epoch [65/10000], Train Loss: 0.3377, Val Loss: 0.4302\n",
      "Epoch [66/10000], Train Loss: 0.3375, Val Loss: 0.4565\n",
      "Epoch [67/10000], Train Loss: 0.3372, Val Loss: 0.4174\n",
      "Epoch [68/10000], Train Loss: 0.3373, Val Loss: 0.4382\n",
      "Epoch [69/10000], Train Loss: 0.3368, Val Loss: 0.4624\n",
      "Epoch [70/10000], Train Loss: 0.3377, Val Loss: 0.4355\n",
      "Epoch [71/10000], Train Loss: 0.3374, Val Loss: 0.4103\n",
      "Epoch [72/10000], Train Loss: 0.3374, Val Loss: 0.4346\n",
      "Epoch [73/10000], Train Loss: 0.3367, Val Loss: 0.4358\n",
      "Epoch [74/10000], Train Loss: 0.3370, Val Loss: 0.4491\n",
      "Epoch [75/10000], Train Loss: 0.3376, Val Loss: 0.4211\n",
      "Epoch [76/10000], Train Loss: 0.3365, Val Loss: 0.4099\n",
      "Epoch [77/10000], Train Loss: 0.3362, Val Loss: 0.4672\n",
      "Epoch [78/10000], Train Loss: 0.3373, Val Loss: 0.4401\n",
      "Epoch [79/10000], Train Loss: 0.3364, Val Loss: 0.4098\n",
      "Epoch [80/10000], Train Loss: 0.3364, Val Loss: 0.4088\n",
      "Epoch [81/10000], Train Loss: 0.3367, Val Loss: 0.4167\n",
      "Epoch [82/10000], Train Loss: 0.3362, Val Loss: 0.4265\n",
      "Epoch [83/10000], Train Loss: 0.3367, Val Loss: 0.4581\n",
      "Epoch [84/10000], Train Loss: 0.3362, Val Loss: 0.3958\n",
      "Validation loss improved from 0.3970 to 0.3958. Saving model...\n",
      "Epoch [85/10000], Train Loss: 0.3363, Val Loss: 0.4460\n",
      "Epoch [86/10000], Train Loss: 0.3359, Val Loss: 0.5027\n",
      "Epoch [87/10000], Train Loss: 0.3360, Val Loss: 0.3957\n",
      "Validation loss improved from 0.3958 to 0.3957. Saving model...\n",
      "Epoch [88/10000], Train Loss: 0.3363, Val Loss: 0.4025\n",
      "Epoch [89/10000], Train Loss: 0.3360, Val Loss: 0.4051\n",
      "Epoch [90/10000], Train Loss: 0.3353, Val Loss: 0.4604\n",
      "Epoch [91/10000], Train Loss: 0.3359, Val Loss: 0.4021\n",
      "Epoch [92/10000], Train Loss: 0.3362, Val Loss: 0.4066\n",
      "Epoch [93/10000], Train Loss: 0.3359, Val Loss: 0.4275\n",
      "Epoch [94/10000], Train Loss: 0.3355, Val Loss: 0.4146\n",
      "Epoch [95/10000], Train Loss: 0.3356, Val Loss: 0.4030\n",
      "Epoch [96/10000], Train Loss: 0.3357, Val Loss: 0.4171\n",
      "Epoch [97/10000], Train Loss: 0.3355, Val Loss: 0.4133\n",
      "Epoch [98/10000], Train Loss: 0.3355, Val Loss: 0.4492\n",
      "Epoch [99/10000], Train Loss: 0.3359, Val Loss: 0.4021\n",
      "Epoch [100/10000], Train Loss: 0.3355, Val Loss: 0.4476\n",
      "Epoch [101/10000], Train Loss: 0.3355, Val Loss: 0.4135\n",
      "Epoch [102/10000], Train Loss: 0.3354, Val Loss: 0.4167\n",
      "Epoch [103/10000], Train Loss: 0.3353, Val Loss: 0.4500\n",
      "Epoch [104/10000], Train Loss: 0.3353, Val Loss: 0.4376\n",
      "Epoch [105/10000], Train Loss: 0.3342, Val Loss: 0.3988\n",
      "Epoch [106/10000], Train Loss: 0.3348, Val Loss: 0.4587\n",
      "Epoch [107/10000], Train Loss: 0.3347, Val Loss: 0.4442\n",
      "Epoch [108/10000], Train Loss: 0.3350, Val Loss: 0.4352\n",
      "Epoch [109/10000], Train Loss: 0.3347, Val Loss: 0.4773\n",
      "Epoch [110/10000], Train Loss: 0.3348, Val Loss: 0.3973\n",
      "Epoch [111/10000], Train Loss: 0.3351, Val Loss: 0.4012\n",
      "Epoch [112/10000], Train Loss: 0.3347, Val Loss: 0.3901\n",
      "Validation loss improved from 0.3957 to 0.3901. Saving model...\n",
      "Epoch [113/10000], Train Loss: 0.3342, Val Loss: 0.4798\n",
      "Epoch [114/10000], Train Loss: 0.3340, Val Loss: 0.4333\n",
      "Epoch [115/10000], Train Loss: 0.3345, Val Loss: 0.4018\n",
      "Epoch [116/10000], Train Loss: 0.3343, Val Loss: 0.4262\n",
      "Epoch [117/10000], Train Loss: 0.3346, Val Loss: 0.4220\n",
      "Epoch [118/10000], Train Loss: 0.3345, Val Loss: 0.3917\n",
      "Epoch [119/10000], Train Loss: 0.3344, Val Loss: 0.4391\n",
      "Epoch [120/10000], Train Loss: 0.3345, Val Loss: 0.4390\n",
      "Epoch [121/10000], Train Loss: 0.3345, Val Loss: 0.4057\n",
      "Epoch [122/10000], Train Loss: 0.3340, Val Loss: 0.4374\n",
      "Epoch [123/10000], Train Loss: 0.3347, Val Loss: 0.4043\n",
      "Epoch [124/10000], Train Loss: 0.3341, Val Loss: 0.3967\n",
      "Epoch [125/10000], Train Loss: 0.3342, Val Loss: 0.4783\n",
      "Epoch [126/10000], Train Loss: 0.3342, Val Loss: 0.4282\n",
      "Epoch [127/10000], Train Loss: 0.3337, Val Loss: 0.4153\n",
      "Epoch [128/10000], Train Loss: 0.3336, Val Loss: 0.4442\n",
      "Epoch [129/10000], Train Loss: 0.3337, Val Loss: 0.4037\n",
      "Epoch [130/10000], Train Loss: 0.3334, Val Loss: 0.4172\n",
      "Epoch [131/10000], Train Loss: 0.3339, Val Loss: 0.4716\n",
      "Epoch [132/10000], Train Loss: 0.3341, Val Loss: 0.4371\n",
      "Epoch [133/10000], Train Loss: 0.3337, Val Loss: 0.4078\n",
      "Epoch [134/10000], Train Loss: 0.3334, Val Loss: 0.4182\n",
      "Epoch [135/10000], Train Loss: 0.3341, Val Loss: 0.4072\n",
      "Epoch [136/10000], Train Loss: 0.3341, Val Loss: 0.4140\n",
      "Epoch [137/10000], Train Loss: 0.3332, Val Loss: 0.4240\n",
      "Epoch [138/10000], Train Loss: 0.3345, Val Loss: 0.4415\n",
      "Epoch [139/10000], Train Loss: 0.3336, Val Loss: 0.4450\n",
      "Epoch [140/10000], Train Loss: 0.3337, Val Loss: 0.4150\n",
      "Epoch [141/10000], Train Loss: 0.3333, Val Loss: 0.4248\n",
      "Epoch [142/10000], Train Loss: 0.3330, Val Loss: 0.3956\n",
      "Epoch [143/10000], Train Loss: 0.3335, Val Loss: 0.4175\n",
      "Epoch [144/10000], Train Loss: 0.3336, Val Loss: 0.4712\n",
      "Epoch [145/10000], Train Loss: 0.3334, Val Loss: 0.4334\n",
      "Epoch [146/10000], Train Loss: 0.3336, Val Loss: 0.4555\n",
      "Epoch [147/10000], Train Loss: 0.3332, Val Loss: 0.4087\n",
      "Epoch [148/10000], Train Loss: 0.3333, Val Loss: 0.3875\n",
      "Validation loss improved from 0.3901 to 0.3875. Saving model...\n",
      "Epoch [149/10000], Train Loss: 0.3330, Val Loss: 0.4500\n",
      "Epoch [150/10000], Train Loss: 0.3338, Val Loss: 0.4296\n",
      "Epoch [151/10000], Train Loss: 0.3331, Val Loss: 0.4644\n",
      "Epoch [152/10000], Train Loss: 0.3332, Val Loss: 0.4054\n",
      "Epoch [153/10000], Train Loss: 0.3333, Val Loss: 0.4381\n",
      "Epoch [154/10000], Train Loss: 0.3331, Val Loss: 0.3954\n",
      "Epoch [155/10000], Train Loss: 0.3337, Val Loss: 0.3971\n",
      "Epoch [156/10000], Train Loss: 0.3329, Val Loss: 0.6601\n",
      "Epoch [157/10000], Train Loss: 0.3330, Val Loss: 0.4193\n",
      "Epoch [158/10000], Train Loss: 0.3329, Val Loss: 0.4429\n",
      "Epoch [159/10000], Train Loss: 0.3329, Val Loss: 0.3933\n",
      "Epoch [160/10000], Train Loss: 0.3326, Val Loss: 0.3948\n",
      "Epoch [161/10000], Train Loss: 0.3332, Val Loss: 0.4125\n",
      "Epoch [162/10000], Train Loss: 0.3333, Val Loss: 0.4442\n",
      "Epoch [163/10000], Train Loss: 0.3325, Val Loss: 0.4538\n",
      "Epoch [164/10000], Train Loss: 0.3335, Val Loss: 0.4055\n",
      "Epoch [165/10000], Train Loss: 0.3325, Val Loss: 0.4189\n",
      "Epoch [166/10000], Train Loss: 0.3328, Val Loss: 0.4748\n",
      "Epoch [167/10000], Train Loss: 0.3330, Val Loss: 0.4381\n",
      "Epoch [168/10000], Train Loss: 0.3329, Val Loss: 0.4017\n",
      "Epoch [169/10000], Train Loss: 0.3323, Val Loss: 0.3921\n",
      "Epoch [170/10000], Train Loss: 0.3333, Val Loss: 0.3969\n",
      "Epoch [171/10000], Train Loss: 0.3326, Val Loss: 0.4206\n",
      "Epoch [172/10000], Train Loss: 0.3320, Val Loss: 0.4177\n",
      "Epoch [173/10000], Train Loss: 0.3326, Val Loss: 0.3974\n",
      "Epoch [174/10000], Train Loss: 0.3328, Val Loss: 0.4614\n",
      "Epoch [175/10000], Train Loss: 0.3328, Val Loss: 0.4141\n",
      "Epoch [176/10000], Train Loss: 0.3333, Val Loss: 0.3976\n",
      "Epoch [177/10000], Train Loss: 0.3325, Val Loss: 0.3945\n",
      "Epoch [178/10000], Train Loss: 0.3327, Val Loss: 0.4096\n",
      "Epoch [179/10000], Train Loss: 0.3328, Val Loss: 0.4525\n",
      "Epoch [180/10000], Train Loss: 0.3329, Val Loss: 0.4176\n",
      "Epoch [181/10000], Train Loss: 0.3325, Val Loss: 0.4479\n",
      "Epoch [182/10000], Train Loss: 0.3322, Val Loss: 0.4545\n",
      "Epoch [183/10000], Train Loss: 0.3319, Val Loss: 0.4273\n",
      "Epoch [184/10000], Train Loss: 0.3321, Val Loss: 0.5185\n",
      "Epoch [185/10000], Train Loss: 0.3327, Val Loss: 0.4193\n",
      "Epoch [186/10000], Train Loss: 0.3322, Val Loss: 0.3896\n",
      "Epoch [187/10000], Train Loss: 0.3326, Val Loss: 0.4520\n",
      "Epoch [188/10000], Train Loss: 0.3319, Val Loss: 0.4196\n",
      "Epoch [189/10000], Train Loss: 0.3327, Val Loss: 0.4006\n",
      "Epoch [190/10000], Train Loss: 0.3324, Val Loss: 0.4699\n",
      "Epoch [191/10000], Train Loss: 0.3325, Val Loss: 0.4107\n",
      "Epoch [192/10000], Train Loss: 0.3313, Val Loss: 0.4050\n",
      "Epoch [193/10000], Train Loss: 0.3314, Val Loss: 0.4032\n",
      "Epoch [194/10000], Train Loss: 0.3326, Val Loss: 0.4147\n",
      "Epoch [195/10000], Train Loss: 0.3328, Val Loss: 0.4267\n",
      "Epoch [196/10000], Train Loss: 0.3322, Val Loss: 0.4417\n",
      "Epoch [197/10000], Train Loss: 0.3325, Val Loss: 0.4551\n",
      "Epoch [198/10000], Train Loss: 0.3322, Val Loss: 0.4188\n",
      "Epoch [199/10000], Train Loss: 0.3316, Val Loss: 0.4071\n",
      "Epoch [200/10000], Train Loss: 0.3322, Val Loss: 0.4125\n",
      "Epoch [201/10000], Train Loss: 0.3316, Val Loss: 0.4516\n",
      "Epoch [202/10000], Train Loss: 0.3320, Val Loss: 0.3893\n",
      "Epoch [203/10000], Train Loss: 0.3320, Val Loss: 0.4087\n",
      "Epoch [204/10000], Train Loss: 0.3323, Val Loss: 0.4068\n",
      "Epoch [205/10000], Train Loss: 0.3328, Val Loss: 0.4397\n",
      "Epoch [206/10000], Train Loss: 0.3317, Val Loss: 0.3998\n",
      "Epoch [207/10000], Train Loss: 0.3325, Val Loss: 0.4123\n",
      "Epoch [208/10000], Train Loss: 0.3316, Val Loss: 0.4072\n",
      "Epoch [209/10000], Train Loss: 0.3326, Val Loss: 0.4093\n",
      "Epoch [210/10000], Train Loss: 0.3316, Val Loss: 0.4226\n",
      "Epoch [211/10000], Train Loss: 0.3318, Val Loss: 0.4079\n",
      "Epoch [212/10000], Train Loss: 0.3320, Val Loss: 0.4276\n",
      "Epoch [213/10000], Train Loss: 0.3318, Val Loss: 0.4494\n",
      "Epoch [214/10000], Train Loss: 0.3314, Val Loss: 0.4229\n",
      "Epoch [215/10000], Train Loss: 0.3317, Val Loss: 0.4453\n",
      "Epoch [216/10000], Train Loss: 0.3318, Val Loss: 0.4830\n",
      "Epoch [217/10000], Train Loss: 0.3322, Val Loss: 0.4984\n",
      "Epoch [218/10000], Train Loss: 0.3316, Val Loss: 0.4174\n",
      "Epoch [219/10000], Train Loss: 0.3320, Val Loss: 0.4262\n",
      "Epoch [220/10000], Train Loss: 0.3318, Val Loss: 0.5128\n",
      "Epoch [221/10000], Train Loss: 0.3319, Val Loss: 0.3943\n",
      "Epoch [222/10000], Train Loss: 0.3318, Val Loss: 0.4301\n",
      "Epoch [223/10000], Train Loss: 0.3319, Val Loss: 0.4400\n",
      "Epoch [224/10000], Train Loss: 0.3317, Val Loss: 0.4067\n",
      "Epoch [225/10000], Train Loss: 0.3321, Val Loss: 0.3875\n",
      "Epoch [226/10000], Train Loss: 0.3318, Val Loss: 0.4234\n",
      "Epoch [227/10000], Train Loss: 0.3313, Val Loss: 0.4144\n",
      "Epoch [228/10000], Train Loss: 0.3324, Val Loss: 0.4520\n",
      "Epoch [229/10000], Train Loss: 0.3317, Val Loss: 0.4346\n",
      "Epoch [230/10000], Train Loss: 0.3318, Val Loss: 0.4044\n",
      "Epoch [231/10000], Train Loss: 0.3312, Val Loss: 0.4483\n",
      "Epoch [232/10000], Train Loss: 0.3320, Val Loss: 0.4367\n",
      "Epoch [233/10000], Train Loss: 0.3322, Val Loss: 0.4204\n",
      "Epoch [234/10000], Train Loss: 0.3318, Val Loss: 0.4091\n",
      "Epoch [235/10000], Train Loss: 0.3323, Val Loss: 0.4586\n",
      "Epoch [236/10000], Train Loss: 0.3319, Val Loss: 0.3936\n",
      "Epoch [237/10000], Train Loss: 0.3314, Val Loss: 0.4001\n",
      "Epoch [238/10000], Train Loss: 0.3319, Val Loss: 0.3982\n",
      "Epoch [239/10000], Train Loss: 0.3313, Val Loss: 0.4456\n",
      "Epoch [240/10000], Train Loss: 0.3316, Val Loss: 0.4079\n",
      "Epoch [241/10000], Train Loss: 0.3316, Val Loss: 0.4398\n",
      "Epoch [242/10000], Train Loss: 0.3326, Val Loss: 0.4391\n",
      "Epoch [243/10000], Train Loss: 0.3312, Val Loss: 0.4068\n",
      "Epoch [244/10000], Train Loss: 0.3311, Val Loss: 0.4097\n",
      "Epoch [245/10000], Train Loss: 0.3316, Val Loss: 0.4189\n",
      "Epoch [246/10000], Train Loss: 0.3317, Val Loss: 0.3882\n",
      "Epoch [247/10000], Train Loss: 0.3318, Val Loss: 0.4008\n",
      "Epoch [248/10000], Train Loss: 0.3322, Val Loss: 0.5586\n",
      "Epoch [249/10000], Train Loss: 0.3326, Val Loss: 0.4071\n",
      "Epoch [250/10000], Train Loss: 0.3310, Val Loss: 0.4203\n",
      "Epoch [251/10000], Train Loss: 0.3313, Val Loss: 0.4353\n",
      "Epoch [252/10000], Train Loss: 0.3314, Val Loss: 0.4029\n",
      "Epoch [253/10000], Train Loss: 0.3312, Val Loss: 0.3965\n",
      "Epoch [254/10000], Train Loss: 0.3313, Val Loss: 0.4226\n",
      "Epoch [255/10000], Train Loss: 0.3303, Val Loss: 0.4012\n",
      "Epoch [256/10000], Train Loss: 0.3310, Val Loss: 0.4490\n",
      "Epoch [257/10000], Train Loss: 0.3313, Val Loss: 0.4092\n",
      "Epoch [258/10000], Train Loss: 0.3320, Val Loss: 0.3949\n",
      "Epoch [259/10000], Train Loss: 0.3310, Val Loss: 0.4995\n",
      "Epoch [260/10000], Train Loss: 0.3315, Val Loss: 0.4260\n",
      "Epoch [261/10000], Train Loss: 0.3312, Val Loss: 0.4051\n",
      "Epoch [262/10000], Train Loss: 0.3322, Val Loss: 0.4196\n",
      "Epoch [263/10000], Train Loss: 0.3310, Val Loss: 0.4249\n",
      "Epoch [264/10000], Train Loss: 0.3308, Val Loss: 0.3980\n",
      "Epoch [265/10000], Train Loss: 0.3313, Val Loss: 0.3953\n",
      "Epoch [266/10000], Train Loss: 0.3313, Val Loss: 0.4299\n",
      "Epoch [267/10000], Train Loss: 0.3326, Val Loss: 0.4192\n",
      "Epoch [268/10000], Train Loss: 0.3310, Val Loss: 0.4990\n",
      "Epoch [269/10000], Train Loss: 0.3315, Val Loss: 0.4713\n",
      "Epoch [270/10000], Train Loss: 0.3312, Val Loss: 0.4510\n",
      "Epoch [271/10000], Train Loss: 0.3310, Val Loss: 0.4521\n",
      "Epoch [272/10000], Train Loss: 0.3310, Val Loss: 0.3962\n",
      "Epoch [273/10000], Train Loss: 0.3313, Val Loss: 0.3908\n",
      "Epoch [274/10000], Train Loss: 0.3311, Val Loss: 0.4621\n",
      "Epoch [275/10000], Train Loss: 0.3313, Val Loss: 0.4152\n",
      "Epoch [276/10000], Train Loss: 0.3311, Val Loss: 0.4189\n",
      "Epoch [277/10000], Train Loss: 0.3319, Val Loss: 0.4121\n",
      "Epoch [278/10000], Train Loss: 0.3316, Val Loss: 0.4304\n",
      "Epoch [279/10000], Train Loss: 0.3307, Val Loss: 0.4495\n",
      "Epoch [280/10000], Train Loss: 0.3307, Val Loss: 0.4371\n",
      "Epoch [281/10000], Train Loss: 0.3316, Val Loss: 0.4295\n",
      "Epoch [282/10000], Train Loss: 0.3316, Val Loss: 0.4120\n",
      "Epoch [283/10000], Train Loss: 0.3309, Val Loss: 0.3956\n",
      "Epoch [284/10000], Train Loss: 0.3306, Val Loss: 0.4066\n",
      "Epoch [285/10000], Train Loss: 0.3312, Val Loss: 0.4029\n",
      "Epoch [286/10000], Train Loss: 0.3306, Val Loss: 0.4181\n",
      "Epoch [287/10000], Train Loss: 0.3309, Val Loss: 0.4182\n",
      "Epoch [288/10000], Train Loss: 0.3311, Val Loss: 0.4242\n",
      "Epoch [289/10000], Train Loss: 0.3313, Val Loss: 0.4903\n",
      "Epoch [290/10000], Train Loss: 0.3311, Val Loss: 0.5567\n",
      "Epoch [291/10000], Train Loss: 0.3312, Val Loss: 0.4162\n",
      "Epoch [292/10000], Train Loss: 0.3307, Val Loss: 0.3988\n",
      "Epoch [293/10000], Train Loss: 0.3309, Val Loss: 0.4022\n",
      "Epoch [294/10000], Train Loss: 0.3309, Val Loss: 0.3977\n",
      "Epoch [295/10000], Train Loss: 0.3308, Val Loss: 0.3985\n",
      "Epoch [296/10000], Train Loss: 0.3303, Val Loss: 0.4592\n",
      "Epoch [297/10000], Train Loss: 0.3307, Val Loss: 0.4169\n",
      "Epoch [298/10000], Train Loss: 0.3308, Val Loss: 0.3994\n",
      "Epoch [299/10000], Train Loss: 0.3305, Val Loss: 0.5351\n",
      "Epoch [300/10000], Train Loss: 0.3303, Val Loss: 0.4593\n",
      "Epoch [301/10000], Train Loss: 0.3305, Val Loss: 0.4050\n",
      "Epoch [302/10000], Train Loss: 0.3310, Val Loss: 0.3978\n",
      "Epoch [303/10000], Train Loss: 0.3309, Val Loss: 0.4193\n",
      "Epoch [304/10000], Train Loss: 0.3308, Val Loss: 0.4029\n",
      "Epoch [305/10000], Train Loss: 0.3311, Val Loss: 0.4036\n",
      "Epoch [306/10000], Train Loss: 0.3303, Val Loss: 0.4304\n",
      "Epoch [307/10000], Train Loss: 0.3311, Val Loss: 0.4070\n",
      "Epoch [308/10000], Train Loss: 0.3307, Val Loss: 0.3965\n",
      "Epoch [309/10000], Train Loss: 0.3312, Val Loss: 0.4263\n",
      "Epoch [310/10000], Train Loss: 0.3305, Val Loss: 0.4406\n",
      "Epoch [311/10000], Train Loss: 0.3301, Val Loss: 0.4032\n",
      "Epoch [312/10000], Train Loss: 0.3301, Val Loss: 0.3998\n",
      "Epoch [313/10000], Train Loss: 0.3307, Val Loss: 0.4282\n",
      "Epoch [314/10000], Train Loss: 0.3305, Val Loss: 0.4190\n",
      "Epoch [315/10000], Train Loss: 0.3304, Val Loss: 0.4604\n",
      "Epoch [316/10000], Train Loss: 0.3301, Val Loss: 0.4162\n",
      "Epoch [317/10000], Train Loss: 0.3314, Val Loss: 0.4249\n",
      "Epoch [318/10000], Train Loss: 0.3301, Val Loss: 0.3984\n",
      "Epoch [319/10000], Train Loss: 0.3299, Val Loss: 0.4070\n",
      "Epoch [320/10000], Train Loss: 0.3305, Val Loss: 0.4271\n",
      "Epoch [321/10000], Train Loss: 0.3302, Val Loss: 0.4051\n",
      "Epoch [322/10000], Train Loss: 0.3305, Val Loss: 0.3926\n",
      "Epoch [323/10000], Train Loss: 0.3304, Val Loss: 0.4824\n",
      "Epoch [324/10000], Train Loss: 0.3304, Val Loss: 0.4907\n",
      "Epoch [325/10000], Train Loss: 0.3303, Val Loss: 0.4060\n",
      "Epoch [326/10000], Train Loss: 0.3299, Val Loss: 0.4118\n",
      "Epoch [327/10000], Train Loss: 0.3297, Val Loss: 0.5237\n",
      "Epoch [328/10000], Train Loss: 0.3301, Val Loss: 0.4096\n",
      "Epoch [329/10000], Train Loss: 0.3301, Val Loss: 0.4103\n",
      "Epoch [330/10000], Train Loss: 0.3303, Val Loss: 0.3949\n",
      "Epoch [331/10000], Train Loss: 0.3306, Val Loss: 0.4204\n",
      "Epoch [332/10000], Train Loss: 0.3293, Val Loss: 0.4020\n",
      "Epoch [333/10000], Train Loss: 0.3299, Val Loss: 0.4798\n",
      "Epoch [334/10000], Train Loss: 0.3301, Val Loss: 0.4296\n",
      "Epoch [335/10000], Train Loss: 0.3293, Val Loss: 0.5557\n",
      "Epoch [336/10000], Train Loss: 0.3291, Val Loss: 0.4400\n",
      "Epoch [337/10000], Train Loss: 0.3301, Val Loss: 0.4368\n",
      "Epoch [338/10000], Train Loss: 0.3298, Val Loss: 0.4127\n",
      "Epoch [339/10000], Train Loss: 0.3298, Val Loss: 0.4139\n",
      "Epoch [340/10000], Train Loss: 0.3288, Val Loss: 0.3956\n",
      "Epoch [341/10000], Train Loss: 0.3304, Val Loss: 0.4385\n",
      "Epoch [342/10000], Train Loss: 0.3294, Val Loss: 0.4725\n",
      "Epoch [343/10000], Train Loss: 0.3298, Val Loss: 0.4020\n",
      "Epoch [344/10000], Train Loss: 0.3296, Val Loss: 0.4619\n",
      "Epoch [345/10000], Train Loss: 0.3296, Val Loss: 0.4124\n",
      "Epoch [346/10000], Train Loss: 0.3298, Val Loss: 0.4485\n",
      "Epoch [347/10000], Train Loss: 0.3295, Val Loss: 0.4343\n",
      "Epoch [348/10000], Train Loss: 0.3292, Val Loss: 0.4349\n",
      "Epoch [349/10000], Train Loss: 0.3297, Val Loss: 0.3940\n",
      "Epoch [350/10000], Train Loss: 0.3297, Val Loss: 0.4239\n",
      "Epoch [351/10000], Train Loss: 0.3289, Val Loss: 0.4060\n",
      "Epoch [352/10000], Train Loss: 0.3292, Val Loss: 0.4090\n",
      "Epoch [353/10000], Train Loss: 0.3292, Val Loss: 0.3982\n",
      "Epoch [354/10000], Train Loss: 0.3295, Val Loss: 0.4252\n",
      "Epoch [355/10000], Train Loss: 0.3297, Val Loss: 0.4141\n",
      "Epoch [356/10000], Train Loss: 0.3298, Val Loss: 0.3972\n",
      "Epoch [357/10000], Train Loss: 0.3293, Val Loss: 0.4033\n",
      "Epoch [358/10000], Train Loss: 0.3292, Val Loss: 0.4207\n",
      "Epoch [359/10000], Train Loss: 0.3293, Val Loss: 0.3923\n",
      "Epoch [360/10000], Train Loss: 0.3302, Val Loss: 0.5026\n",
      "Epoch [361/10000], Train Loss: 0.3291, Val Loss: 0.5309\n",
      "Epoch [362/10000], Train Loss: 0.3292, Val Loss: 0.4642\n",
      "Epoch [363/10000], Train Loss: 0.3290, Val Loss: 0.4420\n",
      "Epoch [364/10000], Train Loss: 0.3288, Val Loss: 0.4888\n",
      "Epoch [365/10000], Train Loss: 0.3294, Val Loss: 0.4007\n",
      "Epoch [366/10000], Train Loss: 0.3291, Val Loss: 0.4140\n",
      "Epoch [367/10000], Train Loss: 0.3290, Val Loss: 0.4175\n",
      "Epoch [368/10000], Train Loss: 0.3294, Val Loss: 0.4234\n",
      "Epoch [369/10000], Train Loss: 0.3292, Val Loss: 0.4129\n",
      "Epoch [370/10000], Train Loss: 0.3294, Val Loss: 0.4291\n",
      "Epoch [371/10000], Train Loss: 0.3292, Val Loss: 0.4613\n",
      "Epoch [372/10000], Train Loss: 0.3291, Val Loss: 0.4222\n",
      "Epoch [373/10000], Train Loss: 0.3289, Val Loss: 0.4142\n",
      "Epoch [374/10000], Train Loss: 0.3293, Val Loss: 0.4223\n",
      "Epoch [375/10000], Train Loss: 0.3289, Val Loss: 0.4116\n",
      "Epoch [376/10000], Train Loss: 0.3291, Val Loss: 0.3904\n",
      "Epoch [377/10000], Train Loss: 0.3289, Val Loss: 0.4014\n",
      "Epoch [378/10000], Train Loss: 0.3290, Val Loss: 0.4632\n",
      "Epoch [379/10000], Train Loss: 0.3289, Val Loss: 0.3949\n",
      "Epoch [380/10000], Train Loss: 0.3284, Val Loss: 0.5610\n",
      "Epoch [381/10000], Train Loss: 0.3297, Val Loss: 0.4155\n",
      "Epoch [382/10000], Train Loss: 0.3285, Val Loss: 0.4757\n",
      "Epoch [383/10000], Train Loss: 0.3286, Val Loss: 0.4123\n",
      "Epoch [384/10000], Train Loss: 0.3291, Val Loss: 0.4456\n",
      "Epoch [385/10000], Train Loss: 0.3291, Val Loss: 0.4169\n",
      "Epoch [386/10000], Train Loss: 0.3289, Val Loss: 0.4046\n",
      "Epoch [387/10000], Train Loss: 0.3296, Val Loss: 0.4061\n",
      "Epoch [388/10000], Train Loss: 0.3288, Val Loss: 0.4588\n",
      "Epoch [389/10000], Train Loss: 0.3289, Val Loss: 0.4851\n",
      "Epoch [390/10000], Train Loss: 0.3283, Val Loss: 0.4057\n",
      "Epoch [391/10000], Train Loss: 0.3286, Val Loss: 0.4400\n",
      "Epoch [392/10000], Train Loss: 0.3289, Val Loss: 0.4423\n",
      "Epoch [393/10000], Train Loss: 0.3285, Val Loss: 0.4111\n",
      "Epoch [394/10000], Train Loss: 0.3287, Val Loss: 0.4230\n",
      "Epoch [395/10000], Train Loss: 0.3287, Val Loss: 0.4079\n",
      "Epoch [396/10000], Train Loss: 0.3292, Val Loss: 0.4857\n",
      "Epoch [397/10000], Train Loss: 0.3291, Val Loss: 0.5001\n",
      "Epoch [398/10000], Train Loss: 0.3289, Val Loss: 0.4032\n",
      "Epoch [399/10000], Train Loss: 0.3296, Val Loss: 0.4359\n",
      "Epoch [400/10000], Train Loss: 0.3289, Val Loss: 0.4077\n",
      "Epoch [401/10000], Train Loss: 0.3291, Val Loss: 0.4473\n",
      "Epoch [402/10000], Train Loss: 0.3288, Val Loss: 0.4067\n",
      "Epoch [403/10000], Train Loss: 0.3287, Val Loss: 0.4090\n",
      "Epoch [404/10000], Train Loss: 0.3289, Val Loss: 0.4244\n",
      "Epoch [405/10000], Train Loss: 0.3284, Val Loss: 0.4485\n",
      "Epoch [406/10000], Train Loss: 0.3294, Val Loss: 0.3961\n",
      "Epoch [407/10000], Train Loss: 0.3293, Val Loss: 0.4353\n",
      "Epoch [408/10000], Train Loss: 0.3291, Val Loss: 0.5674\n",
      "Epoch [409/10000], Train Loss: 0.3289, Val Loss: 0.4313\n",
      "Epoch [410/10000], Train Loss: 0.3291, Val Loss: 0.4255\n",
      "Epoch [411/10000], Train Loss: 0.3288, Val Loss: 0.4284\n",
      "Epoch [412/10000], Train Loss: 0.3290, Val Loss: 0.4759\n",
      "Epoch [413/10000], Train Loss: 0.3291, Val Loss: 0.4002\n",
      "Epoch [414/10000], Train Loss: 0.3292, Val Loss: 0.4166\n",
      "Epoch [415/10000], Train Loss: 0.3288, Val Loss: 0.4712\n",
      "Epoch [416/10000], Train Loss: 0.3286, Val Loss: 0.4506\n",
      "Epoch [417/10000], Train Loss: 0.3282, Val Loss: 0.5391\n",
      "Epoch [418/10000], Train Loss: 0.3283, Val Loss: 0.3993\n",
      "Epoch [419/10000], Train Loss: 0.3286, Val Loss: 0.4768\n",
      "Epoch [420/10000], Train Loss: 0.3293, Val Loss: 0.4048\n",
      "Epoch [421/10000], Train Loss: 0.3289, Val Loss: 0.4385\n",
      "Epoch [422/10000], Train Loss: 0.3296, Val Loss: 0.4798\n",
      "Epoch [423/10000], Train Loss: 0.3289, Val Loss: 0.4612\n",
      "Epoch [424/10000], Train Loss: 0.3289, Val Loss: 0.4032\n",
      "Epoch [425/10000], Train Loss: 0.3289, Val Loss: 0.4494\n",
      "Epoch [426/10000], Train Loss: 0.3291, Val Loss: 0.4106\n",
      "Epoch [427/10000], Train Loss: 0.3291, Val Loss: 0.4199\n",
      "Epoch [428/10000], Train Loss: 0.3296, Val Loss: 0.4181\n",
      "Epoch [429/10000], Train Loss: 0.3285, Val Loss: 0.4292\n",
      "Epoch [430/10000], Train Loss: 0.3286, Val Loss: 0.4076\n",
      "Epoch [431/10000], Train Loss: 0.3289, Val Loss: 0.5692\n",
      "Epoch [432/10000], Train Loss: 0.3289, Val Loss: 0.4115\n",
      "Epoch [433/10000], Train Loss: 0.3293, Val Loss: 0.3999\n",
      "Epoch [434/10000], Train Loss: 0.3287, Val Loss: 0.4194\n",
      "Epoch [435/10000], Train Loss: 0.3295, Val Loss: 0.3991\n",
      "Epoch [436/10000], Train Loss: 0.3291, Val Loss: 0.4292\n",
      "Epoch [437/10000], Train Loss: 0.3291, Val Loss: 0.5019\n",
      "Epoch [438/10000], Train Loss: 0.3291, Val Loss: 0.4095\n",
      "Epoch [439/10000], Train Loss: 0.3288, Val Loss: 0.4205\n",
      "Epoch [440/10000], Train Loss: 0.3288, Val Loss: 0.4728\n",
      "Epoch [441/10000], Train Loss: 0.3293, Val Loss: 0.4161\n",
      "Epoch [442/10000], Train Loss: 0.3285, Val Loss: 0.4454\n",
      "Epoch [443/10000], Train Loss: 0.3289, Val Loss: 0.3936\n",
      "Epoch [444/10000], Train Loss: 0.3292, Val Loss: 0.3973\n",
      "Epoch [445/10000], Train Loss: 0.3287, Val Loss: 0.4094\n",
      "Epoch [446/10000], Train Loss: 0.3293, Val Loss: 0.4244\n",
      "Epoch [447/10000], Train Loss: 0.3279, Val Loss: 0.5139\n",
      "Epoch [448/10000], Train Loss: 0.3289, Val Loss: 0.4203\n",
      "Epoch [449/10000], Train Loss: 0.3283, Val Loss: 0.4408\n",
      "Epoch [450/10000], Train Loss: 0.3290, Val Loss: 0.4078\n",
      "Epoch [451/10000], Train Loss: 0.3301, Val Loss: 0.4707\n",
      "Epoch [452/10000], Train Loss: 0.3287, Val Loss: 0.4333\n",
      "Epoch [453/10000], Train Loss: 0.3291, Val Loss: 0.4575\n",
      "Epoch [454/10000], Train Loss: 0.3282, Val Loss: 0.4875\n",
      "Epoch [455/10000], Train Loss: 0.3289, Val Loss: 0.4081\n",
      "Epoch [456/10000], Train Loss: 0.3288, Val Loss: 0.4256\n",
      "Epoch [457/10000], Train Loss: 0.3284, Val Loss: 0.3985\n",
      "Epoch [458/10000], Train Loss: 0.3288, Val Loss: 0.4032\n",
      "Epoch [459/10000], Train Loss: 0.3288, Val Loss: 0.4057\n",
      "Epoch [460/10000], Train Loss: 0.3293, Val Loss: 0.4081\n",
      "Epoch [461/10000], Train Loss: 0.3287, Val Loss: 0.4120\n",
      "Epoch [462/10000], Train Loss: 0.3293, Val Loss: 0.3893\n",
      "Epoch [463/10000], Train Loss: 0.3286, Val Loss: 0.4484\n",
      "Epoch [464/10000], Train Loss: 0.3287, Val Loss: 0.4084\n",
      "Epoch [465/10000], Train Loss: 0.3284, Val Loss: 0.4006\n",
      "Epoch [466/10000], Train Loss: 0.3281, Val Loss: 0.4057\n",
      "Epoch [467/10000], Train Loss: 0.3296, Val Loss: 0.4224\n",
      "Epoch [468/10000], Train Loss: 0.3286, Val Loss: 0.4067\n",
      "Epoch [469/10000], Train Loss: 0.3287, Val Loss: 0.4730\n",
      "Epoch [470/10000], Train Loss: 0.3283, Val Loss: 0.4171\n",
      "Epoch [471/10000], Train Loss: 0.3287, Val Loss: 0.4305\n",
      "Epoch [472/10000], Train Loss: 0.3283, Val Loss: 0.4087\n",
      "Epoch [473/10000], Train Loss: 0.3291, Val Loss: 0.5627\n",
      "Epoch [474/10000], Train Loss: 0.3285, Val Loss: 0.4313\n",
      "Epoch [475/10000], Train Loss: 0.3288, Val Loss: 0.4179\n",
      "Epoch [476/10000], Train Loss: 0.3283, Val Loss: 0.4200\n",
      "Epoch [477/10000], Train Loss: 0.3287, Val Loss: 0.4105\n",
      "Epoch [478/10000], Train Loss: 0.3294, Val Loss: 0.4521\n",
      "Epoch [479/10000], Train Loss: 0.3290, Val Loss: 0.4727\n",
      "Epoch [480/10000], Train Loss: 0.3284, Val Loss: 0.4425\n",
      "Epoch [481/10000], Train Loss: 0.3283, Val Loss: 0.4061\n",
      "Epoch [482/10000], Train Loss: 0.3292, Val Loss: 0.4091\n",
      "Epoch [483/10000], Train Loss: 0.3287, Val Loss: 0.4526\n",
      "Epoch [484/10000], Train Loss: 0.3290, Val Loss: 0.5409\n",
      "Epoch [485/10000], Train Loss: 0.3283, Val Loss: 0.4491\n",
      "Epoch [486/10000], Train Loss: 0.3290, Val Loss: 0.4005\n",
      "Epoch [487/10000], Train Loss: 0.3292, Val Loss: 0.4061\n",
      "Epoch [488/10000], Train Loss: 0.3295, Val Loss: 0.3979\n",
      "Epoch [489/10000], Train Loss: 0.3289, Val Loss: 0.4209\n",
      "Epoch [490/10000], Train Loss: 0.3278, Val Loss: 0.4721\n",
      "Epoch [491/10000], Train Loss: 0.3286, Val Loss: 0.5342\n",
      "Epoch [492/10000], Train Loss: 0.3298, Val Loss: 0.4330\n",
      "Epoch [493/10000], Train Loss: 0.3290, Val Loss: 0.4457\n",
      "Epoch [494/10000], Train Loss: 0.3290, Val Loss: 0.5245\n",
      "Epoch [495/10000], Train Loss: 0.3288, Val Loss: 0.4156\n",
      "Epoch [496/10000], Train Loss: 0.3287, Val Loss: 0.3953\n",
      "Epoch [497/10000], Train Loss: 0.3287, Val Loss: 0.3997\n",
      "Epoch [498/10000], Train Loss: 0.3285, Val Loss: 0.4727\n",
      "Epoch [499/10000], Train Loss: 0.3286, Val Loss: 0.4682\n",
      "Epoch [500/10000], Train Loss: 0.3286, Val Loss: 0.4216\n",
      "Epoch [501/10000], Train Loss: 0.3286, Val Loss: 0.4112\n",
      "Epoch [502/10000], Train Loss: 0.3294, Val Loss: 0.4036\n",
      "Epoch [503/10000], Train Loss: 0.3289, Val Loss: 0.4127\n",
      "Epoch [504/10000], Train Loss: 0.3285, Val Loss: 0.4183\n",
      "Epoch [505/10000], Train Loss: 0.3295, Val Loss: 0.4084\n",
      "Epoch [506/10000], Train Loss: 0.3296, Val Loss: 0.4266\n",
      "Epoch [507/10000], Train Loss: 0.3285, Val Loss: 0.4434\n",
      "Epoch [508/10000], Train Loss: 0.3294, Val Loss: 0.4093\n",
      "Epoch [509/10000], Train Loss: 0.3289, Val Loss: 0.4373\n",
      "Epoch [510/10000], Train Loss: 0.3289, Val Loss: 0.4435\n",
      "Epoch [511/10000], Train Loss: 0.3288, Val Loss: 0.4107\n",
      "Epoch [512/10000], Train Loss: 0.3280, Val Loss: 0.4375\n",
      "Epoch [513/10000], Train Loss: 0.3289, Val Loss: 0.4061\n",
      "Epoch [514/10000], Train Loss: 0.3296, Val Loss: 0.4039\n",
      "Epoch [515/10000], Train Loss: 0.3287, Val Loss: 0.4518\n",
      "Epoch [516/10000], Train Loss: 0.3283, Val Loss: 0.3977\n",
      "Epoch [517/10000], Train Loss: 0.3290, Val Loss: 0.4064\n",
      "Epoch [518/10000], Train Loss: 0.3287, Val Loss: 0.4234\n",
      "Epoch [519/10000], Train Loss: 0.3287, Val Loss: 0.3955\n",
      "Epoch [520/10000], Train Loss: 0.3288, Val Loss: 0.4221\n",
      "Epoch [521/10000], Train Loss: 0.3286, Val Loss: 0.4341\n",
      "Epoch [522/10000], Train Loss: 0.3285, Val Loss: 0.4060\n",
      "Epoch [523/10000], Train Loss: 0.3291, Val Loss: 0.3967\n",
      "Epoch [524/10000], Train Loss: 0.3286, Val Loss: 0.4120\n",
      "Epoch [525/10000], Train Loss: 0.3287, Val Loss: 0.3999\n",
      "Epoch [526/10000], Train Loss: 0.3288, Val Loss: 0.4320\n",
      "Epoch [527/10000], Train Loss: 0.3284, Val Loss: 0.4590\n",
      "Epoch [528/10000], Train Loss: 0.3290, Val Loss: 0.4220\n",
      "Epoch [529/10000], Train Loss: 0.3285, Val Loss: 0.4321\n",
      "Epoch [530/10000], Train Loss: 0.3286, Val Loss: 0.3994\n",
      "Epoch [531/10000], Train Loss: 0.3295, Val Loss: 0.4639\n",
      "Epoch [532/10000], Train Loss: 0.3278, Val Loss: 0.5204\n",
      "Epoch [533/10000], Train Loss: 0.3288, Val Loss: 0.4456\n",
      "Epoch [534/10000], Train Loss: 0.3287, Val Loss: 0.4119\n",
      "Epoch [535/10000], Train Loss: 0.3282, Val Loss: 0.3901\n",
      "Epoch [536/10000], Train Loss: 0.3290, Val Loss: 0.3974\n",
      "Epoch [537/10000], Train Loss: 0.3285, Val Loss: 0.4196\n",
      "Epoch [538/10000], Train Loss: 0.3288, Val Loss: 0.4070\n",
      "Epoch [539/10000], Train Loss: 0.3288, Val Loss: 0.4404\n",
      "Epoch [540/10000], Train Loss: 0.3282, Val Loss: 0.4071\n",
      "Epoch [541/10000], Train Loss: 0.3288, Val Loss: 0.4117\n",
      "Epoch [542/10000], Train Loss: 0.3281, Val Loss: 0.3937\n",
      "Epoch [543/10000], Train Loss: 0.3283, Val Loss: 0.4860\n",
      "Epoch [544/10000], Train Loss: 0.3282, Val Loss: 0.4067\n",
      "Epoch [545/10000], Train Loss: 0.3283, Val Loss: 0.4610\n",
      "Epoch [546/10000], Train Loss: 0.3282, Val Loss: 0.4265\n",
      "Epoch [547/10000], Train Loss: 0.3289, Val Loss: 0.4108\n",
      "Epoch [548/10000], Train Loss: 0.3289, Val Loss: 0.4031\n",
      "Epoch [549/10000], Train Loss: 0.3281, Val Loss: 0.4213\n",
      "Epoch [550/10000], Train Loss: 0.3289, Val Loss: 0.4014\n",
      "Epoch [551/10000], Train Loss: 0.3288, Val Loss: 0.4241\n",
      "Epoch [552/10000], Train Loss: 0.3285, Val Loss: 0.3950\n",
      "Epoch [553/10000], Train Loss: 0.3293, Val Loss: 0.4503\n",
      "Epoch [554/10000], Train Loss: 0.3281, Val Loss: 0.4168\n",
      "Epoch [555/10000], Train Loss: 0.3287, Val Loss: 0.4457\n",
      "Epoch [556/10000], Train Loss: 0.3287, Val Loss: 0.4497\n",
      "Epoch [557/10000], Train Loss: 0.3285, Val Loss: 0.4197\n",
      "Epoch [558/10000], Train Loss: 0.3286, Val Loss: 0.4019\n",
      "Epoch [559/10000], Train Loss: 0.3283, Val Loss: 0.4601\n",
      "Epoch [560/10000], Train Loss: 0.3288, Val Loss: 0.4112\n",
      "Epoch [561/10000], Train Loss: 0.3286, Val Loss: 0.4178\n",
      "Epoch [562/10000], Train Loss: 0.3278, Val Loss: 0.5134\n",
      "Epoch [563/10000], Train Loss: 0.3286, Val Loss: 0.4159\n",
      "Epoch [564/10000], Train Loss: 0.3280, Val Loss: 0.3948\n",
      "Epoch [565/10000], Train Loss: 0.3285, Val Loss: 0.4056\n",
      "Epoch [566/10000], Train Loss: 0.3278, Val Loss: 0.4221\n",
      "Epoch [567/10000], Train Loss: 0.3287, Val Loss: 0.3947\n",
      "Epoch [568/10000], Train Loss: 0.3286, Val Loss: 0.4268\n",
      "Epoch [569/10000], Train Loss: 0.3284, Val Loss: 0.4261\n",
      "Epoch [570/10000], Train Loss: 0.3283, Val Loss: 0.4196\n",
      "Epoch [571/10000], Train Loss: 0.3283, Val Loss: 0.4240\n",
      "Epoch [572/10000], Train Loss: 0.3287, Val Loss: 0.4519\n",
      "Epoch [573/10000], Train Loss: 0.3282, Val Loss: 0.4103\n",
      "Epoch [574/10000], Train Loss: 0.3290, Val Loss: 0.4093\n",
      "Epoch [575/10000], Train Loss: 0.3285, Val Loss: 0.4169\n",
      "Epoch [576/10000], Train Loss: 0.3285, Val Loss: 0.4393\n",
      "Epoch [577/10000], Train Loss: 0.3287, Val Loss: 0.4093\n",
      "Epoch [578/10000], Train Loss: 0.3286, Val Loss: 0.4453\n",
      "Epoch [579/10000], Train Loss: 0.3285, Val Loss: 0.4291\n",
      "Epoch [580/10000], Train Loss: 0.3288, Val Loss: 0.4246\n",
      "Epoch [581/10000], Train Loss: 0.3288, Val Loss: 0.4296\n",
      "Epoch [582/10000], Train Loss: 0.3286, Val Loss: 0.4416\n",
      "Epoch [583/10000], Train Loss: 0.3288, Val Loss: 0.4200\n",
      "Epoch [584/10000], Train Loss: 0.3290, Val Loss: 0.4082\n",
      "Epoch [585/10000], Train Loss: 0.3286, Val Loss: 0.4417\n",
      "Epoch [586/10000], Train Loss: 0.3287, Val Loss: 0.3995\n",
      "Epoch [587/10000], Train Loss: 0.3284, Val Loss: 0.3964\n",
      "Epoch [588/10000], Train Loss: 0.3292, Val Loss: 0.4863\n",
      "Epoch [589/10000], Train Loss: 0.3289, Val Loss: 0.4093\n",
      "Epoch [590/10000], Train Loss: 0.3281, Val Loss: 0.4427\n",
      "Epoch [591/10000], Train Loss: 0.3286, Val Loss: 0.3992\n",
      "Epoch [592/10000], Train Loss: 0.3284, Val Loss: 0.4587\n",
      "Epoch [593/10000], Train Loss: 0.3291, Val Loss: 0.4167\n",
      "Epoch [594/10000], Train Loss: 0.3291, Val Loss: 0.4067\n",
      "Epoch [595/10000], Train Loss: 0.3293, Val Loss: 0.4053\n",
      "Epoch [596/10000], Train Loss: 0.3281, Val Loss: 0.4177\n",
      "Epoch [597/10000], Train Loss: 0.3290, Val Loss: 0.4329\n",
      "Epoch [598/10000], Train Loss: 0.3284, Val Loss: 0.4071\n",
      "Epoch [599/10000], Train Loss: 0.3286, Val Loss: 0.4078\n",
      "Epoch [600/10000], Train Loss: 0.3283, Val Loss: 0.4728\n",
      "Epoch [601/10000], Train Loss: 0.3280, Val Loss: 0.4382\n",
      "Epoch [602/10000], Train Loss: 0.3285, Val Loss: 0.4410\n",
      "Epoch [603/10000], Train Loss: 0.3282, Val Loss: 0.4217\n",
      "Epoch [604/10000], Train Loss: 0.3285, Val Loss: 0.4181\n",
      "Epoch [605/10000], Train Loss: 0.3284, Val Loss: 0.4215\n",
      "Epoch [606/10000], Train Loss: 0.3323, Val Loss: 0.4122\n",
      "Epoch [607/10000], Train Loss: 0.3286, Val Loss: 0.4160\n",
      "Epoch [608/10000], Train Loss: 0.3289, Val Loss: 0.4232\n",
      "Epoch [609/10000], Train Loss: 0.3282, Val Loss: 0.4023\n",
      "Epoch [610/10000], Train Loss: 0.3281, Val Loss: 0.4082\n",
      "Epoch [611/10000], Train Loss: 0.3287, Val Loss: 0.4495\n",
      "Epoch [612/10000], Train Loss: 0.3284, Val Loss: 0.4272\n",
      "Epoch [613/10000], Train Loss: 0.3282, Val Loss: 0.4426\n",
      "Epoch [614/10000], Train Loss: 0.3286, Val Loss: 0.3945\n",
      "Epoch [615/10000], Train Loss: 0.3296, Val Loss: 0.4389\n",
      "Epoch [616/10000], Train Loss: 0.3281, Val Loss: 0.5976\n",
      "Epoch [617/10000], Train Loss: 0.3285, Val Loss: 0.5152\n",
      "Epoch [618/10000], Train Loss: 0.3278, Val Loss: 0.4129\n",
      "Epoch [619/10000], Train Loss: 0.3284, Val Loss: 0.4705\n",
      "Epoch [620/10000], Train Loss: 0.3288, Val Loss: 0.4517\n",
      "Epoch [621/10000], Train Loss: 0.3291, Val Loss: 0.4107\n",
      "Epoch [622/10000], Train Loss: 0.3290, Val Loss: 0.4331\n",
      "Epoch [623/10000], Train Loss: 0.3291, Val Loss: 0.4245\n",
      "Epoch [624/10000], Train Loss: 0.3284, Val Loss: 0.4043\n",
      "Epoch [625/10000], Train Loss: 0.3285, Val Loss: 0.4178\n",
      "Epoch [626/10000], Train Loss: 0.3295, Val Loss: 0.3969\n",
      "Epoch [627/10000], Train Loss: 0.3283, Val Loss: 0.4022\n",
      "Epoch [628/10000], Train Loss: 0.3284, Val Loss: 0.4382\n",
      "Epoch [629/10000], Train Loss: 0.3284, Val Loss: 0.4130\n",
      "Epoch [630/10000], Train Loss: 0.3282, Val Loss: 0.4198\n",
      "Epoch [631/10000], Train Loss: 0.3284, Val Loss: 0.5248\n",
      "Epoch [632/10000], Train Loss: 0.3282, Val Loss: 0.3953\n",
      "Epoch [633/10000], Train Loss: 0.3289, Val Loss: 0.4559\n",
      "Epoch [634/10000], Train Loss: 0.3292, Val Loss: 0.4046\n",
      "Epoch [635/10000], Train Loss: 0.3284, Val Loss: 0.3919\n",
      "Epoch [636/10000], Train Loss: 0.3277, Val Loss: 0.4390\n",
      "Epoch [637/10000], Train Loss: 0.3288, Val Loss: 0.4145\n",
      "Epoch [638/10000], Train Loss: 0.3283, Val Loss: 0.4092\n",
      "Epoch [639/10000], Train Loss: 0.3293, Val Loss: 0.4542\n",
      "Epoch [640/10000], Train Loss: 0.3284, Val Loss: 0.4056\n",
      "Epoch [641/10000], Train Loss: 0.3280, Val Loss: 0.4070\n",
      "Epoch [642/10000], Train Loss: 0.3284, Val Loss: 0.4071\n",
      "Epoch [643/10000], Train Loss: 0.3280, Val Loss: 0.4103\n",
      "Epoch [644/10000], Train Loss: 0.3282, Val Loss: 0.3994\n",
      "Epoch [645/10000], Train Loss: 0.3284, Val Loss: 0.4134\n",
      "Epoch [646/10000], Train Loss: 0.3283, Val Loss: 0.3983\n",
      "Epoch [647/10000], Train Loss: 0.3287, Val Loss: 0.4074\n",
      "Epoch [648/10000], Train Loss: 0.3286, Val Loss: 0.5604\n",
      "Epoch [649/10000], Train Loss: 0.3287, Val Loss: 0.5020\n",
      "Epoch [650/10000], Train Loss: 0.3286, Val Loss: 0.3988\n",
      "Epoch [651/10000], Train Loss: 0.3296, Val Loss: 0.4612\n",
      "Epoch [652/10000], Train Loss: 0.3290, Val Loss: 0.4046\n",
      "Epoch [653/10000], Train Loss: 0.3280, Val Loss: 0.4180\n",
      "Epoch [654/10000], Train Loss: 0.3282, Val Loss: 0.4652\n",
      "Epoch [655/10000], Train Loss: 0.3285, Val Loss: 0.4010\n",
      "Epoch [656/10000], Train Loss: 0.3285, Val Loss: 0.4064\n",
      "Epoch [657/10000], Train Loss: 0.3284, Val Loss: 0.4584\n",
      "Epoch [658/10000], Train Loss: 0.3289, Val Loss: 0.5276\n",
      "Epoch [659/10000], Train Loss: 0.3287, Val Loss: 0.3895\n",
      "Epoch [660/10000], Train Loss: 0.3285, Val Loss: 0.4069\n",
      "Epoch [661/10000], Train Loss: 0.3283, Val Loss: 0.4416\n",
      "Epoch [662/10000], Train Loss: 0.3289, Val Loss: 0.4506\n",
      "Epoch [663/10000], Train Loss: 0.3286, Val Loss: 0.4130\n",
      "Epoch [664/10000], Train Loss: 0.3281, Val Loss: 0.4244\n",
      "Epoch [665/10000], Train Loss: 0.3287, Val Loss: 0.4210\n",
      "Epoch [666/10000], Train Loss: 0.3279, Val Loss: 0.3984\n",
      "Epoch [667/10000], Train Loss: 0.3289, Val Loss: 0.4193\n",
      "Epoch [668/10000], Train Loss: 0.3286, Val Loss: 0.4326\n",
      "Epoch [669/10000], Train Loss: 0.3292, Val Loss: 0.4140\n",
      "Epoch [670/10000], Train Loss: 0.3282, Val Loss: 0.4071\n",
      "Epoch [671/10000], Train Loss: 0.3279, Val Loss: 0.4031\n",
      "Epoch [672/10000], Train Loss: 0.3286, Val Loss: 0.4395\n",
      "Epoch [673/10000], Train Loss: 0.3289, Val Loss: 0.4071\n",
      "Epoch [674/10000], Train Loss: 0.3284, Val Loss: 0.4293\n",
      "Epoch [675/10000], Train Loss: 0.3283, Val Loss: 0.3975\n",
      "Epoch [676/10000], Train Loss: 0.3287, Val Loss: 0.4807\n",
      "Epoch [677/10000], Train Loss: 0.3292, Val Loss: 0.4611\n",
      "Epoch [678/10000], Train Loss: 0.3290, Val Loss: 0.4195\n",
      "Epoch [679/10000], Train Loss: 0.3281, Val Loss: 0.4377\n",
      "Epoch [680/10000], Train Loss: 0.3285, Val Loss: 0.4475\n",
      "Epoch [681/10000], Train Loss: 0.3290, Val Loss: 0.4390\n",
      "Epoch [682/10000], Train Loss: 0.3289, Val Loss: 0.3960\n",
      "Epoch [683/10000], Train Loss: 0.3287, Val Loss: 0.4000\n",
      "Epoch [684/10000], Train Loss: 0.3286, Val Loss: 0.3933\n",
      "Epoch [685/10000], Train Loss: 0.3288, Val Loss: 0.4484\n",
      "Epoch [686/10000], Train Loss: 0.3289, Val Loss: 0.3934\n",
      "Epoch [687/10000], Train Loss: 0.3288, Val Loss: 0.4166\n",
      "Epoch [688/10000], Train Loss: 0.3287, Val Loss: 0.4589\n",
      "Epoch [689/10000], Train Loss: 0.3288, Val Loss: 0.5191\n",
      "Epoch [690/10000], Train Loss: 0.3291, Val Loss: 0.4110\n",
      "Epoch [691/10000], Train Loss: 0.3282, Val Loss: 0.4674\n",
      "Epoch [692/10000], Train Loss: 0.3282, Val Loss: 0.4047\n",
      "Epoch [693/10000], Train Loss: 0.3285, Val Loss: 0.4130\n",
      "Epoch [694/10000], Train Loss: 0.3286, Val Loss: 0.4019\n",
      "Epoch [695/10000], Train Loss: 0.3294, Val Loss: 0.4345\n",
      "Epoch [696/10000], Train Loss: 0.3283, Val Loss: 0.4356\n",
      "Epoch [697/10000], Train Loss: 0.3286, Val Loss: 0.3988\n",
      "Epoch [698/10000], Train Loss: 0.3281, Val Loss: 0.3994\n",
      "Epoch [699/10000], Train Loss: 0.3287, Val Loss: 0.3961\n",
      "Epoch [700/10000], Train Loss: 0.3286, Val Loss: 0.3972\n",
      "Epoch [701/10000], Train Loss: 0.3284, Val Loss: 0.4459\n",
      "Epoch [702/10000], Train Loss: 0.3293, Val Loss: 0.4152\n",
      "Epoch [703/10000], Train Loss: 0.3287, Val Loss: 0.4053\n",
      "Epoch [704/10000], Train Loss: 0.3280, Val Loss: 0.4104\n",
      "Epoch [705/10000], Train Loss: 0.3285, Val Loss: 0.4045\n",
      "Epoch [706/10000], Train Loss: 0.3282, Val Loss: 0.5289\n",
      "Epoch [707/10000], Train Loss: 0.3278, Val Loss: 0.4771\n",
      "Epoch [708/10000], Train Loss: 0.3281, Val Loss: 0.4048\n",
      "Epoch [709/10000], Train Loss: 0.3284, Val Loss: 0.4379\n",
      "Epoch [710/10000], Train Loss: 0.3285, Val Loss: 0.4042\n",
      "Epoch [711/10000], Train Loss: 0.3283, Val Loss: 0.4224\n",
      "Epoch [712/10000], Train Loss: 0.3280, Val Loss: 0.4043\n",
      "Epoch [713/10000], Train Loss: 0.3280, Val Loss: 0.4113\n",
      "Epoch [714/10000], Train Loss: 0.3288, Val Loss: 0.4021\n",
      "Epoch [715/10000], Train Loss: 0.3287, Val Loss: 0.4891\n",
      "Epoch [716/10000], Train Loss: 0.3286, Val Loss: 0.4071\n",
      "Epoch [717/10000], Train Loss: 0.3283, Val Loss: 0.4020\n",
      "Epoch [718/10000], Train Loss: 0.3290, Val Loss: 0.4132\n",
      "Epoch [719/10000], Train Loss: 0.3281, Val Loss: 0.3968\n",
      "Epoch [720/10000], Train Loss: 0.3283, Val Loss: 0.4011\n",
      "Epoch [721/10000], Train Loss: 0.3286, Val Loss: 0.4108\n",
      "Epoch [722/10000], Train Loss: 0.3283, Val Loss: 0.4448\n",
      "Epoch [723/10000], Train Loss: 0.3282, Val Loss: 0.4505\n",
      "Epoch [724/10000], Train Loss: 0.3284, Val Loss: 0.4209\n",
      "Epoch [725/10000], Train Loss: 0.3282, Val Loss: 0.4334\n",
      "Epoch [726/10000], Train Loss: 0.3289, Val Loss: 0.4163\n",
      "Epoch [727/10000], Train Loss: 0.3286, Val Loss: 0.4092\n",
      "Epoch [728/10000], Train Loss: 0.3292, Val Loss: 0.4551\n",
      "Epoch [729/10000], Train Loss: 0.3281, Val Loss: 0.4920\n",
      "Epoch [730/10000], Train Loss: 0.3287, Val Loss: 0.5332\n",
      "Epoch [731/10000], Train Loss: 0.3287, Val Loss: 0.4303\n",
      "Epoch [732/10000], Train Loss: 0.3290, Val Loss: 0.4204\n",
      "Epoch [733/10000], Train Loss: 0.3283, Val Loss: 0.4095\n",
      "Epoch [734/10000], Train Loss: 0.3282, Val Loss: 0.3979\n",
      "Epoch [735/10000], Train Loss: 0.3283, Val Loss: 0.4209\n",
      "Epoch [736/10000], Train Loss: 0.3284, Val Loss: 0.4073\n",
      "Epoch [737/10000], Train Loss: 0.3281, Val Loss: 0.4051\n",
      "Epoch [738/10000], Train Loss: 0.3282, Val Loss: 0.4174\n",
      "Epoch [739/10000], Train Loss: 0.3281, Val Loss: 0.4551\n",
      "Epoch [740/10000], Train Loss: 0.3287, Val Loss: 0.5119\n",
      "Epoch [741/10000], Train Loss: 0.3287, Val Loss: 0.4128\n",
      "Epoch [742/10000], Train Loss: 0.3290, Val Loss: 0.4927\n",
      "Epoch [743/10000], Train Loss: 0.3281, Val Loss: 0.4825\n",
      "Epoch [744/10000], Train Loss: 0.3291, Val Loss: 0.5039\n",
      "Epoch [745/10000], Train Loss: 0.3287, Val Loss: 0.5083\n",
      "Epoch [746/10000], Train Loss: 0.3281, Val Loss: 0.4019\n",
      "Epoch [747/10000], Train Loss: 0.3289, Val Loss: 0.4367\n",
      "Epoch [748/10000], Train Loss: 0.3285, Val Loss: 0.4112\n",
      "Epoch [749/10000], Train Loss: 0.3282, Val Loss: 0.4087\n",
      "Epoch [750/10000], Train Loss: 0.3282, Val Loss: 0.4689\n",
      "Epoch [751/10000], Train Loss: 0.3278, Val Loss: 0.4794\n",
      "Epoch [752/10000], Train Loss: 0.3286, Val Loss: 0.3967\n",
      "Epoch [753/10000], Train Loss: 0.3282, Val Loss: 0.4026\n",
      "Epoch [754/10000], Train Loss: 0.3278, Val Loss: 0.4055\n",
      "Epoch [755/10000], Train Loss: 0.3292, Val Loss: 0.4754\n",
      "Epoch [756/10000], Train Loss: 0.3288, Val Loss: 0.5306\n",
      "Epoch [757/10000], Train Loss: 0.3286, Val Loss: 0.4035\n",
      "Epoch [758/10000], Train Loss: 0.3285, Val Loss: 0.4134\n",
      "Epoch [759/10000], Train Loss: 0.3290, Val Loss: 0.4797\n",
      "Epoch [760/10000], Train Loss: 0.3282, Val Loss: 0.4653\n",
      "Epoch [761/10000], Train Loss: 0.3287, Val Loss: 0.4166\n",
      "Epoch [762/10000], Train Loss: 0.3289, Val Loss: 0.4643\n",
      "Epoch [763/10000], Train Loss: 0.3281, Val Loss: 0.4315\n",
      "Epoch [764/10000], Train Loss: 0.3285, Val Loss: 0.4102\n",
      "Epoch [765/10000], Train Loss: 0.3281, Val Loss: 0.4115\n",
      "Epoch [766/10000], Train Loss: 0.3290, Val Loss: 0.4513\n",
      "Epoch [767/10000], Train Loss: 0.3283, Val Loss: 0.4487\n",
      "Epoch [768/10000], Train Loss: 0.3301, Val Loss: 0.4003\n",
      "Epoch [769/10000], Train Loss: 0.3288, Val Loss: 0.4102\n",
      "Epoch [770/10000], Train Loss: 0.3288, Val Loss: 0.4192\n",
      "Epoch [771/10000], Train Loss: 0.3293, Val Loss: 0.4464\n",
      "Epoch [772/10000], Train Loss: 0.3285, Val Loss: 0.4382\n",
      "Epoch [773/10000], Train Loss: 0.3278, Val Loss: 0.4006\n",
      "Epoch [774/10000], Train Loss: 0.3291, Val Loss: 0.4087\n",
      "Epoch [775/10000], Train Loss: 0.3287, Val Loss: 0.4134\n",
      "Epoch [776/10000], Train Loss: 0.3284, Val Loss: 0.4315\n",
      "Epoch [777/10000], Train Loss: 0.3289, Val Loss: 0.4004\n",
      "Epoch [778/10000], Train Loss: 0.3288, Val Loss: 0.3941\n",
      "Epoch [779/10000], Train Loss: 0.3291, Val Loss: 0.4112\n",
      "Epoch [780/10000], Train Loss: 0.3285, Val Loss: 0.4220\n",
      "Epoch [781/10000], Train Loss: 0.3301, Val Loss: 0.4494\n",
      "Epoch [782/10000], Train Loss: 0.3286, Val Loss: 0.3940\n",
      "Epoch [783/10000], Train Loss: 0.3287, Val Loss: 0.4205\n",
      "Epoch [784/10000], Train Loss: 0.3286, Val Loss: 0.4117\n",
      "Epoch [785/10000], Train Loss: 0.3282, Val Loss: 0.4135\n",
      "Epoch [786/10000], Train Loss: 0.3287, Val Loss: 0.3944\n",
      "Epoch [787/10000], Train Loss: 0.3288, Val Loss: 0.4183\n",
      "Epoch [788/10000], Train Loss: 0.3281, Val Loss: 0.4039\n",
      "Epoch [789/10000], Train Loss: 0.3286, Val Loss: 0.3989\n",
      "Epoch [790/10000], Train Loss: 0.3287, Val Loss: 0.4076\n",
      "Epoch [791/10000], Train Loss: 0.3278, Val Loss: 0.4031\n",
      "Epoch [792/10000], Train Loss: 0.3285, Val Loss: 0.4413\n",
      "Epoch [793/10000], Train Loss: 0.3293, Val Loss: 0.4125\n",
      "Epoch [794/10000], Train Loss: 0.3282, Val Loss: 0.4393\n",
      "Epoch [795/10000], Train Loss: 0.3281, Val Loss: 0.3936\n",
      "Epoch [796/10000], Train Loss: 0.3286, Val Loss: 0.5496\n",
      "Epoch [797/10000], Train Loss: 0.3281, Val Loss: 0.4027\n",
      "Epoch [798/10000], Train Loss: 0.3280, Val Loss: 0.4317\n",
      "Epoch [799/10000], Train Loss: 0.3290, Val Loss: 0.4121\n",
      "Epoch [800/10000], Train Loss: 0.3287, Val Loss: 0.4181\n",
      "Epoch [801/10000], Train Loss: 0.3282, Val Loss: 0.4221\n",
      "Epoch [802/10000], Train Loss: 0.3283, Val Loss: 0.4495\n",
      "Epoch [803/10000], Train Loss: 0.3284, Val Loss: 0.4050\n",
      "Epoch [804/10000], Train Loss: 0.3294, Val Loss: 0.5278\n",
      "Epoch [805/10000], Train Loss: 0.3287, Val Loss: 0.4044\n",
      "Epoch [806/10000], Train Loss: 0.3283, Val Loss: 0.4373\n",
      "Epoch [807/10000], Train Loss: 0.3285, Val Loss: 0.4127\n",
      "Epoch [808/10000], Train Loss: 0.3289, Val Loss: 0.3980\n",
      "Epoch [809/10000], Train Loss: 0.3281, Val Loss: 0.3940\n",
      "Epoch [810/10000], Train Loss: 0.3282, Val Loss: 0.4327\n",
      "Epoch [811/10000], Train Loss: 0.3286, Val Loss: 0.3907\n",
      "Epoch [812/10000], Train Loss: 0.3288, Val Loss: 0.4075\n",
      "Epoch [813/10000], Train Loss: 0.3288, Val Loss: 0.5454\n",
      "Epoch [814/10000], Train Loss: 0.3282, Val Loss: 0.4032\n",
      "Epoch [815/10000], Train Loss: 0.3282, Val Loss: 0.4176\n",
      "Epoch [816/10000], Train Loss: 0.3286, Val Loss: 0.4054\n",
      "Epoch [817/10000], Train Loss: 0.3283, Val Loss: 0.3979\n",
      "Epoch [818/10000], Train Loss: 0.3285, Val Loss: 0.4138\n",
      "Epoch [819/10000], Train Loss: 0.3278, Val Loss: 0.4082\n",
      "Epoch [820/10000], Train Loss: 0.3285, Val Loss: 0.4618\n",
      "Epoch [821/10000], Train Loss: 0.3293, Val Loss: 0.4541\n",
      "Epoch [822/10000], Train Loss: 0.3276, Val Loss: 0.4140\n",
      "Epoch [823/10000], Train Loss: 0.3286, Val Loss: 0.4115\n",
      "Epoch [824/10000], Train Loss: 0.3285, Val Loss: 0.4131\n",
      "Epoch [825/10000], Train Loss: 0.3282, Val Loss: 0.4735\n",
      "Epoch [826/10000], Train Loss: 0.3290, Val Loss: 0.4106\n",
      "Epoch [827/10000], Train Loss: 0.3284, Val Loss: 0.3908\n",
      "Epoch [828/10000], Train Loss: 0.3283, Val Loss: 0.5157\n",
      "Epoch [829/10000], Train Loss: 0.3283, Val Loss: 0.4025\n",
      "Epoch [830/10000], Train Loss: 0.3280, Val Loss: 0.3996\n",
      "Epoch [831/10000], Train Loss: 0.3279, Val Loss: 0.4604\n",
      "Epoch [832/10000], Train Loss: 0.3282, Val Loss: 0.4243\n",
      "Epoch [833/10000], Train Loss: 0.3286, Val Loss: 0.4016\n",
      "Epoch [834/10000], Train Loss: 0.3285, Val Loss: 0.4051\n",
      "Epoch [835/10000], Train Loss: 0.3276, Val Loss: 0.4560\n",
      "Epoch [836/10000], Train Loss: 0.3288, Val Loss: 0.3990\n",
      "Epoch [837/10000], Train Loss: 0.3282, Val Loss: 0.4595\n",
      "Epoch [838/10000], Train Loss: 0.3282, Val Loss: 0.4092\n",
      "Epoch [839/10000], Train Loss: 0.3277, Val Loss: 0.4070\n",
      "Epoch [840/10000], Train Loss: 0.3287, Val Loss: 0.5196\n",
      "Epoch [841/10000], Train Loss: 0.3284, Val Loss: 0.4644\n",
      "Epoch [842/10000], Train Loss: 0.3281, Val Loss: 0.3945\n",
      "Epoch [843/10000], Train Loss: 0.3278, Val Loss: 0.4266\n",
      "Epoch [844/10000], Train Loss: 0.3284, Val Loss: 0.3959\n",
      "Epoch [845/10000], Train Loss: 0.3277, Val Loss: 0.3954\n",
      "Epoch [846/10000], Train Loss: 0.3289, Val Loss: 0.5653\n",
      "Epoch [847/10000], Train Loss: 0.3286, Val Loss: 0.4440\n",
      "Epoch [848/10000], Train Loss: 0.3275, Val Loss: 0.4341\n",
      "Epoch [849/10000], Train Loss: 0.3281, Val Loss: 0.3943\n",
      "Epoch [850/10000], Train Loss: 0.3278, Val Loss: 0.4659\n",
      "Epoch [851/10000], Train Loss: 0.3285, Val Loss: 0.4269\n",
      "Epoch [852/10000], Train Loss: 0.3282, Val Loss: 0.4237\n",
      "Epoch [853/10000], Train Loss: 0.3279, Val Loss: 0.4334\n",
      "Epoch [854/10000], Train Loss: 0.3280, Val Loss: 0.4605\n",
      "Epoch [855/10000], Train Loss: 0.3282, Val Loss: 0.4248\n",
      "Epoch [856/10000], Train Loss: 0.3278, Val Loss: 0.4147\n",
      "Epoch [857/10000], Train Loss: 0.3280, Val Loss: 0.4676\n",
      "Epoch [858/10000], Train Loss: 0.3283, Val Loss: 0.4146\n",
      "Epoch [859/10000], Train Loss: 0.3292, Val Loss: 0.4260\n",
      "Epoch [860/10000], Train Loss: 0.3278, Val Loss: 0.3974\n",
      "Epoch [861/10000], Train Loss: 0.3280, Val Loss: 0.4469\n",
      "Epoch [862/10000], Train Loss: 0.3282, Val Loss: 0.4912\n",
      "Epoch [863/10000], Train Loss: 0.3284, Val Loss: 0.5080\n",
      "Epoch [864/10000], Train Loss: 0.3276, Val Loss: 0.5873\n",
      "Epoch [865/10000], Train Loss: 0.3281, Val Loss: 0.4023\n",
      "Epoch [866/10000], Train Loss: 0.3279, Val Loss: 0.4220\n",
      "Epoch [867/10000], Train Loss: 0.3290, Val Loss: 0.4182\n",
      "Epoch [868/10000], Train Loss: 0.3283, Val Loss: 0.4046\n",
      "Epoch [869/10000], Train Loss: 0.3280, Val Loss: 0.3975\n",
      "Epoch [870/10000], Train Loss: 0.3281, Val Loss: 0.4015\n",
      "Epoch [871/10000], Train Loss: 0.3285, Val Loss: 0.3950\n",
      "Epoch [872/10000], Train Loss: 0.3281, Val Loss: 0.4162\n",
      "Epoch [873/10000], Train Loss: 0.3284, Val Loss: 0.4133\n",
      "Epoch [874/10000], Train Loss: 0.3279, Val Loss: 0.4005\n",
      "Epoch [875/10000], Train Loss: 0.3289, Val Loss: 0.3980\n",
      "Epoch [876/10000], Train Loss: 0.3278, Val Loss: 0.4188\n",
      "Epoch [877/10000], Train Loss: 0.3290, Val Loss: 0.4595\n",
      "Epoch [878/10000], Train Loss: 0.3279, Val Loss: 0.4118\n",
      "Epoch [879/10000], Train Loss: 0.3278, Val Loss: 0.6047\n",
      "Epoch [880/10000], Train Loss: 0.3283, Val Loss: 0.5126\n",
      "Epoch [881/10000], Train Loss: 0.3279, Val Loss: 0.3910\n",
      "Epoch [882/10000], Train Loss: 0.3285, Val Loss: 0.4359\n",
      "Epoch [883/10000], Train Loss: 0.3276, Val Loss: 0.4108\n",
      "Epoch [884/10000], Train Loss: 0.3281, Val Loss: 0.4442\n",
      "Epoch [885/10000], Train Loss: 0.3278, Val Loss: 0.3952\n",
      "Epoch [886/10000], Train Loss: 0.3274, Val Loss: 0.4837\n",
      "Epoch [887/10000], Train Loss: 0.3275, Val Loss: 0.4530\n",
      "Epoch [888/10000], Train Loss: 0.3277, Val Loss: 0.4633\n",
      "Epoch [889/10000], Train Loss: 0.3284, Val Loss: 0.4205\n",
      "Epoch [890/10000], Train Loss: 0.3273, Val Loss: 0.3957\n",
      "Epoch [891/10000], Train Loss: 0.3280, Val Loss: 0.3941\n",
      "Epoch [892/10000], Train Loss: 0.3277, Val Loss: 0.4022\n",
      "Epoch [893/10000], Train Loss: 0.3275, Val Loss: 0.4300\n",
      "Epoch [894/10000], Train Loss: 0.3270, Val Loss: 0.3961\n",
      "Epoch [895/10000], Train Loss: 0.3274, Val Loss: 0.3965\n",
      "Epoch [896/10000], Train Loss: 0.3278, Val Loss: 0.4382\n",
      "Epoch [897/10000], Train Loss: 0.3281, Val Loss: 0.4338\n",
      "Epoch [898/10000], Train Loss: 0.3276, Val Loss: 0.4100\n",
      "Epoch [899/10000], Train Loss: 0.3273, Val Loss: 0.4330\n",
      "Epoch [900/10000], Train Loss: 0.3279, Val Loss: 0.3941\n",
      "Epoch [901/10000], Train Loss: 0.3273, Val Loss: 0.4112\n",
      "Epoch [902/10000], Train Loss: 0.3275, Val Loss: 0.4384\n",
      "Epoch [903/10000], Train Loss: 0.3276, Val Loss: 0.4002\n",
      "Epoch [904/10000], Train Loss: 0.3274, Val Loss: 0.4400\n",
      "Epoch [905/10000], Train Loss: 0.3277, Val Loss: 0.4007\n",
      "Epoch [906/10000], Train Loss: 0.3271, Val Loss: 0.4008\n",
      "Epoch [907/10000], Train Loss: 0.3274, Val Loss: 0.4608\n",
      "Epoch [908/10000], Train Loss: 0.3273, Val Loss: 0.4016\n",
      "Epoch [909/10000], Train Loss: 0.3269, Val Loss: 0.4553\n",
      "Epoch [910/10000], Train Loss: 0.3273, Val Loss: 0.4059\n",
      "Epoch [911/10000], Train Loss: 0.3268, Val Loss: 0.4582\n",
      "Epoch [912/10000], Train Loss: 0.3269, Val Loss: 0.4077\n",
      "Epoch [913/10000], Train Loss: 0.3276, Val Loss: 0.4107\n",
      "Epoch [914/10000], Train Loss: 0.3268, Val Loss: 0.4123\n",
      "Epoch [915/10000], Train Loss: 0.3273, Val Loss: 0.3979\n",
      "Epoch [916/10000], Train Loss: 0.3275, Val Loss: 0.4026\n",
      "Epoch [917/10000], Train Loss: 0.3273, Val Loss: 0.4508\n",
      "Epoch [918/10000], Train Loss: 0.3271, Val Loss: 0.4378\n",
      "Epoch [919/10000], Train Loss: 0.3268, Val Loss: 0.3964\n",
      "Epoch [920/10000], Train Loss: 0.3270, Val Loss: 0.4533\n",
      "Epoch [921/10000], Train Loss: 0.3265, Val Loss: 0.5378\n",
      "Epoch [922/10000], Train Loss: 0.3281, Val Loss: 0.4068\n",
      "Epoch [923/10000], Train Loss: 0.3271, Val Loss: 0.6164\n",
      "Epoch [924/10000], Train Loss: 0.3273, Val Loss: 0.4056\n",
      "Epoch [925/10000], Train Loss: 0.3269, Val Loss: 0.4537\n",
      "Epoch [926/10000], Train Loss: 0.3267, Val Loss: 0.4206\n",
      "Epoch [927/10000], Train Loss: 0.3270, Val Loss: 0.4066\n",
      "Epoch [928/10000], Train Loss: 0.3266, Val Loss: 0.4283\n",
      "Epoch [929/10000], Train Loss: 0.3264, Val Loss: 0.4568\n",
      "Epoch [930/10000], Train Loss: 0.3266, Val Loss: 0.3937\n",
      "Epoch [931/10000], Train Loss: 0.3275, Val Loss: 0.4033\n",
      "Epoch [932/10000], Train Loss: 0.3261, Val Loss: 0.4140\n",
      "Epoch [933/10000], Train Loss: 0.3270, Val Loss: 0.4531\n",
      "Epoch [934/10000], Train Loss: 0.3271, Val Loss: 0.4222\n",
      "Epoch [935/10000], Train Loss: 0.3265, Val Loss: 0.4262\n",
      "Epoch [936/10000], Train Loss: 0.3270, Val Loss: 0.4081\n",
      "Epoch [937/10000], Train Loss: 0.3266, Val Loss: 0.4009\n",
      "Epoch [938/10000], Train Loss: 0.3263, Val Loss: 0.5014\n",
      "Epoch [939/10000], Train Loss: 0.3268, Val Loss: 0.4344\n",
      "Epoch [940/10000], Train Loss: 0.3273, Val Loss: 0.3987\n",
      "Epoch [941/10000], Train Loss: 0.3262, Val Loss: 0.4344\n",
      "Epoch [942/10000], Train Loss: 0.3271, Val Loss: 0.4610\n",
      "Epoch [943/10000], Train Loss: 0.3264, Val Loss: 0.4009\n",
      "Epoch [944/10000], Train Loss: 0.3305, Val Loss: 0.4886\n",
      "Epoch [945/10000], Train Loss: 0.3288, Val Loss: 0.4816\n",
      "Epoch [946/10000], Train Loss: 0.3260, Val Loss: 0.4034\n",
      "Epoch [947/10000], Train Loss: 0.3270, Val Loss: 0.3869\n",
      "Validation loss improved from 0.3875 to 0.3869. Saving model...\n",
      "Epoch [948/10000], Train Loss: 0.3273, Val Loss: 0.4023\n",
      "Epoch [949/10000], Train Loss: 0.3266, Val Loss: 0.4042\n",
      "Epoch [950/10000], Train Loss: 0.3271, Val Loss: 0.4086\n",
      "Epoch [951/10000], Train Loss: 0.3263, Val Loss: 0.5291\n",
      "Epoch [952/10000], Train Loss: 0.3272, Val Loss: 0.4148\n",
      "Epoch [953/10000], Train Loss: 0.3262, Val Loss: 0.3985\n",
      "Epoch [954/10000], Train Loss: 0.3261, Val Loss: 0.3932\n",
      "Epoch [955/10000], Train Loss: 0.3264, Val Loss: 0.4060\n",
      "Epoch [956/10000], Train Loss: 0.3267, Val Loss: 0.4022\n",
      "Epoch [957/10000], Train Loss: 0.3268, Val Loss: 0.4184\n",
      "Epoch [958/10000], Train Loss: 0.3269, Val Loss: 0.5155\n",
      "Epoch [959/10000], Train Loss: 0.3263, Val Loss: 0.4179\n",
      "Epoch [960/10000], Train Loss: 0.3266, Val Loss: 0.4151\n",
      "Epoch [961/10000], Train Loss: 0.3271, Val Loss: 0.4045\n",
      "Epoch [962/10000], Train Loss: 0.3265, Val Loss: 0.4861\n",
      "Epoch [963/10000], Train Loss: 0.3260, Val Loss: 0.4151\n",
      "Epoch [964/10000], Train Loss: 0.3258, Val Loss: 0.4191\n",
      "Epoch [965/10000], Train Loss: 0.3264, Val Loss: 0.6235\n",
      "Epoch [966/10000], Train Loss: 0.3267, Val Loss: 0.4047\n",
      "Epoch [967/10000], Train Loss: 0.3262, Val Loss: 0.4893\n",
      "Epoch [968/10000], Train Loss: 0.3266, Val Loss: 0.4618\n",
      "Epoch [969/10000], Train Loss: 0.3266, Val Loss: 0.4172\n",
      "Epoch [970/10000], Train Loss: 0.3274, Val Loss: 0.4857\n",
      "Epoch [971/10000], Train Loss: 0.3273, Val Loss: 0.4329\n",
      "Epoch [972/10000], Train Loss: 0.3269, Val Loss: 0.4035\n",
      "Epoch [973/10000], Train Loss: 0.3264, Val Loss: 0.4076\n",
      "Epoch [974/10000], Train Loss: 0.3263, Val Loss: 0.4284\n",
      "Epoch [975/10000], Train Loss: 0.3265, Val Loss: 0.4196\n",
      "Epoch [976/10000], Train Loss: 0.3269, Val Loss: 0.4253\n",
      "Epoch [977/10000], Train Loss: 0.3260, Val Loss: 0.4082\n",
      "Epoch [978/10000], Train Loss: 0.3264, Val Loss: 0.5420\n",
      "Epoch [979/10000], Train Loss: 0.3267, Val Loss: 0.4165\n",
      "Epoch [980/10000], Train Loss: 0.3268, Val Loss: 0.4660\n",
      "Epoch [981/10000], Train Loss: 0.3266, Val Loss: 0.5704\n",
      "Epoch [982/10000], Train Loss: 0.3258, Val Loss: 0.4206\n",
      "Epoch [983/10000], Train Loss: 0.3254, Val Loss: 0.4067\n",
      "Epoch [984/10000], Train Loss: 0.3258, Val Loss: 0.4549\n",
      "Epoch [985/10000], Train Loss: 0.3267, Val Loss: 0.4444\n",
      "Epoch [986/10000], Train Loss: 0.3269, Val Loss: 0.4862\n",
      "Epoch [987/10000], Train Loss: 0.3263, Val Loss: 0.3977\n",
      "Epoch [988/10000], Train Loss: 0.3262, Val Loss: 0.4038\n",
      "Epoch [989/10000], Train Loss: 0.3268, Val Loss: 0.4164\n",
      "Epoch [990/10000], Train Loss: 0.3261, Val Loss: 0.3925\n",
      "Epoch [991/10000], Train Loss: 0.3262, Val Loss: 0.3960\n",
      "Epoch [992/10000], Train Loss: 0.3265, Val Loss: 0.4561\n",
      "Epoch [993/10000], Train Loss: 0.3265, Val Loss: 0.4001\n",
      "Epoch [994/10000], Train Loss: 0.3266, Val Loss: 0.4259\n",
      "Epoch [995/10000], Train Loss: 0.3262, Val Loss: 0.4206\n",
      "Epoch [996/10000], Train Loss: 0.3262, Val Loss: 0.4314\n",
      "Epoch [997/10000], Train Loss: 0.3265, Val Loss: 0.4263\n",
      "Epoch [998/10000], Train Loss: 0.3265, Val Loss: 0.3945\n",
      "Epoch [999/10000], Train Loss: 0.3265, Val Loss: 0.3983\n",
      "Epoch [1000/10000], Train Loss: 0.3266, Val Loss: 0.3976\n",
      "Epoch [1001/10000], Train Loss: 0.3259, Val Loss: 0.3988\n",
      "Epoch [1002/10000], Train Loss: 0.3263, Val Loss: 0.4264\n",
      "Epoch [1003/10000], Train Loss: 0.3261, Val Loss: 0.4062\n",
      "Epoch [1004/10000], Train Loss: 0.3259, Val Loss: 0.4132\n",
      "Epoch [1005/10000], Train Loss: 0.3270, Val Loss: 0.3944\n",
      "Epoch [1006/10000], Train Loss: 0.3258, Val Loss: 0.4029\n",
      "Epoch [1007/10000], Train Loss: 0.3266, Val Loss: 0.4223\n",
      "Epoch [1008/10000], Train Loss: 0.3260, Val Loss: 0.4192\n",
      "Epoch [1009/10000], Train Loss: 0.3261, Val Loss: 0.4057\n",
      "Epoch [1010/10000], Train Loss: 0.3268, Val Loss: 0.4340\n",
      "Epoch [1011/10000], Train Loss: 0.3258, Val Loss: 0.4043\n",
      "Epoch [1012/10000], Train Loss: 0.3263, Val Loss: 0.4790\n",
      "Epoch [1013/10000], Train Loss: 0.3261, Val Loss: 0.4111\n",
      "Epoch [1014/10000], Train Loss: 0.3255, Val Loss: 0.4267\n",
      "Epoch [1015/10000], Train Loss: 0.3258, Val Loss: 0.4153\n",
      "Epoch [1016/10000], Train Loss: 0.3263, Val Loss: 0.4089\n",
      "Epoch [1017/10000], Train Loss: 0.3257, Val Loss: 0.4007\n",
      "Epoch [1018/10000], Train Loss: 0.3267, Val Loss: 0.4969\n",
      "Epoch [1019/10000], Train Loss: 0.3262, Val Loss: 0.4189\n",
      "Epoch [1020/10000], Train Loss: 0.3274, Val Loss: 0.6537\n",
      "Epoch [1021/10000], Train Loss: 0.3260, Val Loss: 0.4369\n",
      "Epoch [1022/10000], Train Loss: 0.3267, Val Loss: 0.4259\n",
      "Epoch [1023/10000], Train Loss: 0.3268, Val Loss: 0.4182\n",
      "Epoch [1024/10000], Train Loss: 0.3265, Val Loss: 0.4095\n",
      "Epoch [1025/10000], Train Loss: 0.3261, Val Loss: 0.4083\n",
      "Epoch [1026/10000], Train Loss: 0.3261, Val Loss: 0.4216\n",
      "Epoch [1027/10000], Train Loss: 0.3257, Val Loss: 0.4112\n",
      "Epoch [1028/10000], Train Loss: 0.3262, Val Loss: 0.4178\n",
      "Epoch [1029/10000], Train Loss: 0.3257, Val Loss: 0.4148\n",
      "Epoch [1030/10000], Train Loss: 0.3261, Val Loss: 0.4105\n",
      "Epoch [1031/10000], Train Loss: 0.3300, Val Loss: 0.3964\n",
      "Epoch [1032/10000], Train Loss: 0.3253, Val Loss: 0.3964\n",
      "Epoch [1033/10000], Train Loss: 0.3259, Val Loss: 0.4031\n",
      "Epoch [1034/10000], Train Loss: 0.3262, Val Loss: 0.3888\n",
      "Epoch [1035/10000], Train Loss: 0.3265, Val Loss: 0.4118\n",
      "Epoch [1036/10000], Train Loss: 0.3258, Val Loss: 0.4282\n",
      "Epoch [1037/10000], Train Loss: 0.3260, Val Loss: 0.4327\n",
      "Epoch [1038/10000], Train Loss: 0.3261, Val Loss: 0.4101\n",
      "Epoch [1039/10000], Train Loss: 0.3259, Val Loss: 0.3923\n",
      "Epoch [1040/10000], Train Loss: 0.3264, Val Loss: 0.3964\n",
      "Epoch [1041/10000], Train Loss: 0.3260, Val Loss: 0.4436\n",
      "Epoch [1042/10000], Train Loss: 0.3265, Val Loss: 0.4017\n",
      "Epoch [1043/10000], Train Loss: 0.3256, Val Loss: 0.4020\n",
      "Epoch [1044/10000], Train Loss: 0.3268, Val Loss: 0.4355\n",
      "Epoch [1045/10000], Train Loss: 0.3256, Val Loss: 0.4782\n",
      "Epoch [1046/10000], Train Loss: 0.3268, Val Loss: 0.3990\n",
      "Epoch [1047/10000], Train Loss: 0.3257, Val Loss: 0.3971\n",
      "Epoch [1048/10000], Train Loss: 0.3261, Val Loss: 0.4266\n",
      "Epoch [1049/10000], Train Loss: 0.3265, Val Loss: 0.4632\n",
      "Epoch [1050/10000], Train Loss: 0.3264, Val Loss: 0.3907\n",
      "Epoch [1051/10000], Train Loss: 0.3267, Val Loss: 0.4112\n",
      "Epoch [1052/10000], Train Loss: 0.3261, Val Loss: 0.4111\n",
      "Epoch [1053/10000], Train Loss: 0.3261, Val Loss: 0.3979\n",
      "Epoch [1054/10000], Train Loss: 0.3261, Val Loss: 0.4203\n",
      "Epoch [1055/10000], Train Loss: 0.3260, Val Loss: 0.4365\n",
      "Epoch [1056/10000], Train Loss: 0.3264, Val Loss: 0.4114\n",
      "Epoch [1057/10000], Train Loss: 0.3261, Val Loss: 0.4220\n",
      "Epoch [1058/10000], Train Loss: 0.3254, Val Loss: 0.4298\n",
      "Epoch [1059/10000], Train Loss: 0.3264, Val Loss: 0.3944\n",
      "Epoch [1060/10000], Train Loss: 0.3259, Val Loss: 0.3915\n",
      "Epoch [1061/10000], Train Loss: 0.3259, Val Loss: 0.4820\n",
      "Epoch [1062/10000], Train Loss: 0.3264, Val Loss: 0.4062\n",
      "Epoch [1063/10000], Train Loss: 0.3255, Val Loss: 0.4404\n",
      "Epoch [1064/10000], Train Loss: 0.3258, Val Loss: 0.3954\n",
      "Epoch [1065/10000], Train Loss: 0.3260, Val Loss: 0.4609\n",
      "Epoch [1066/10000], Train Loss: 0.3271, Val Loss: 0.4720\n",
      "Epoch [1067/10000], Train Loss: 0.3269, Val Loss: 0.4079\n",
      "Epoch [1068/10000], Train Loss: 0.3257, Val Loss: 0.4231\n",
      "Epoch [1069/10000], Train Loss: 0.3258, Val Loss: 0.4425\n",
      "Epoch [1070/10000], Train Loss: 0.3261, Val Loss: 0.5171\n",
      "Epoch [1071/10000], Train Loss: 0.3268, Val Loss: 0.4035\n",
      "Epoch [1072/10000], Train Loss: 0.3272, Val Loss: 0.3981\n",
      "Epoch [1073/10000], Train Loss: 0.3261, Val Loss: 0.4251\n",
      "Epoch [1074/10000], Train Loss: 0.3267, Val Loss: 0.3972\n",
      "Epoch [1075/10000], Train Loss: 0.3261, Val Loss: 0.4630\n",
      "Epoch [1076/10000], Train Loss: 0.3263, Val Loss: 0.3860\n",
      "Validation loss improved from 0.3869 to 0.3860. Saving model...\n",
      "Epoch [1077/10000], Train Loss: 0.3266, Val Loss: 0.4401\n",
      "Epoch [1078/10000], Train Loss: 0.3263, Val Loss: 0.3878\n",
      "Epoch [1079/10000], Train Loss: 0.3256, Val Loss: 0.3966\n",
      "Epoch [1080/10000], Train Loss: 0.3260, Val Loss: 0.3962\n",
      "Epoch [1081/10000], Train Loss: 0.3261, Val Loss: 0.4077\n",
      "Epoch [1082/10000], Train Loss: 0.3262, Val Loss: 0.4103\n",
      "Epoch [1083/10000], Train Loss: 0.3255, Val Loss: 0.4156\n",
      "Epoch [1084/10000], Train Loss: 0.3259, Val Loss: 0.4462\n",
      "Epoch [1085/10000], Train Loss: 0.3263, Val Loss: 0.3900\n",
      "Epoch [1086/10000], Train Loss: 0.3256, Val Loss: 0.4763\n",
      "Epoch [1087/10000], Train Loss: 0.3262, Val Loss: 0.3971\n",
      "Epoch [1088/10000], Train Loss: 0.3258, Val Loss: 0.3993\n",
      "Epoch [1089/10000], Train Loss: 0.3261, Val Loss: 0.4450\n",
      "Epoch [1090/10000], Train Loss: 0.3268, Val Loss: 0.4287\n",
      "Epoch [1091/10000], Train Loss: 0.3259, Val Loss: 0.4445\n",
      "Epoch [1092/10000], Train Loss: 0.3256, Val Loss: 0.3923\n",
      "Epoch [1093/10000], Train Loss: 0.3266, Val Loss: 0.4142\n",
      "Epoch [1094/10000], Train Loss: 0.3261, Val Loss: 0.4101\n",
      "Epoch [1095/10000], Train Loss: 0.3265, Val Loss: 0.4133\n",
      "Epoch [1096/10000], Train Loss: 0.3253, Val Loss: 0.4050\n",
      "Epoch [1097/10000], Train Loss: 0.3261, Val Loss: 0.4395\n",
      "Epoch [1098/10000], Train Loss: 0.3263, Val Loss: 0.4058\n",
      "Epoch [1099/10000], Train Loss: 0.3253, Val Loss: 0.3881\n",
      "Epoch [1100/10000], Train Loss: 0.3256, Val Loss: 0.4666\n",
      "Epoch [1101/10000], Train Loss: 0.3260, Val Loss: 0.3926\n",
      "Epoch [1102/10000], Train Loss: 0.3259, Val Loss: 0.4055\n",
      "Epoch [1103/10000], Train Loss: 0.3253, Val Loss: 0.3870\n",
      "Epoch [1104/10000], Train Loss: 0.3261, Val Loss: 0.4284\n",
      "Epoch [1105/10000], Train Loss: 0.3254, Val Loss: 0.4100\n",
      "Epoch [1106/10000], Train Loss: 0.3258, Val Loss: 0.4164\n",
      "Epoch [1107/10000], Train Loss: 0.3253, Val Loss: 0.4037\n",
      "Epoch [1108/10000], Train Loss: 0.3259, Val Loss: 0.4098\n",
      "Epoch [1109/10000], Train Loss: 0.3257, Val Loss: 0.3926\n",
      "Epoch [1110/10000], Train Loss: 0.3258, Val Loss: 0.4219\n",
      "Epoch [1111/10000], Train Loss: 0.3256, Val Loss: 0.4310\n",
      "Epoch [1112/10000], Train Loss: 0.3261, Val Loss: 0.5254\n",
      "Epoch [1113/10000], Train Loss: 0.3259, Val Loss: 0.4518\n",
      "Epoch [1114/10000], Train Loss: 0.3253, Val Loss: 0.4483\n",
      "Epoch [1115/10000], Train Loss: 0.3264, Val Loss: 0.4095\n",
      "Epoch [1116/10000], Train Loss: 0.3258, Val Loss: 0.4069\n",
      "Epoch [1117/10000], Train Loss: 0.3261, Val Loss: 0.4033\n",
      "Epoch [1118/10000], Train Loss: 0.3258, Val Loss: 0.4949\n",
      "Epoch [1119/10000], Train Loss: 0.3262, Val Loss: 0.4372\n",
      "Epoch [1120/10000], Train Loss: 0.3263, Val Loss: 0.4028\n",
      "Epoch [1121/10000], Train Loss: 0.3259, Val Loss: 0.4073\n",
      "Epoch [1122/10000], Train Loss: 0.3258, Val Loss: 0.4053\n",
      "Epoch [1123/10000], Train Loss: 0.3262, Val Loss: 0.4484\n",
      "Epoch [1124/10000], Train Loss: 0.3261, Val Loss: 0.4276\n",
      "Epoch [1125/10000], Train Loss: 0.3254, Val Loss: 0.4130\n",
      "Epoch [1126/10000], Train Loss: 0.3260, Val Loss: 0.4280\n",
      "Epoch [1127/10000], Train Loss: 0.3257, Val Loss: 0.3926\n",
      "Epoch [1128/10000], Train Loss: 0.3256, Val Loss: 0.4066\n",
      "Epoch [1129/10000], Train Loss: 0.3259, Val Loss: 0.3966\n",
      "Epoch [1130/10000], Train Loss: 0.3255, Val Loss: 0.3956\n",
      "Epoch [1131/10000], Train Loss: 0.3255, Val Loss: 0.4336\n",
      "Epoch [1132/10000], Train Loss: 0.3262, Val Loss: 0.4234\n",
      "Epoch [1133/10000], Train Loss: 0.3264, Val Loss: 0.4191\n",
      "Epoch [1134/10000], Train Loss: 0.3260, Val Loss: 0.4920\n",
      "Epoch [1135/10000], Train Loss: 0.3266, Val Loss: 0.3942\n",
      "Epoch [1136/10000], Train Loss: 0.3265, Val Loss: 0.5612\n",
      "Epoch [1137/10000], Train Loss: 0.3258, Val Loss: 0.3964\n",
      "Epoch [1138/10000], Train Loss: 0.3264, Val Loss: 0.4390\n",
      "Epoch [1139/10000], Train Loss: 0.3256, Val Loss: 0.4226\n",
      "Epoch [1140/10000], Train Loss: 0.3260, Val Loss: 0.4035\n",
      "Epoch [1141/10000], Train Loss: 0.3258, Val Loss: 0.4275\n",
      "Epoch [1142/10000], Train Loss: 0.3261, Val Loss: 0.4512\n",
      "Epoch [1143/10000], Train Loss: 0.3258, Val Loss: 0.4089\n",
      "Epoch [1144/10000], Train Loss: 0.3259, Val Loss: 0.4001\n",
      "Epoch [1145/10000], Train Loss: 0.3253, Val Loss: 0.3990\n",
      "Epoch [1146/10000], Train Loss: 0.3257, Val Loss: 0.4276\n",
      "Epoch [1147/10000], Train Loss: 0.3263, Val Loss: 0.3986\n",
      "Epoch [1148/10000], Train Loss: 0.3261, Val Loss: 0.4120\n",
      "Epoch [1149/10000], Train Loss: 0.3254, Val Loss: 0.4294\n",
      "Epoch [1150/10000], Train Loss: 0.3265, Val Loss: 0.4030\n",
      "Epoch [1151/10000], Train Loss: 0.3252, Val Loss: 0.4674\n",
      "Epoch [1152/10000], Train Loss: 0.3249, Val Loss: 0.4164\n",
      "Epoch [1153/10000], Train Loss: 0.3257, Val Loss: 0.4594\n",
      "Epoch [1154/10000], Train Loss: 0.3258, Val Loss: 0.4084\n",
      "Epoch [1155/10000], Train Loss: 0.3264, Val Loss: 0.4090\n",
      "Epoch [1156/10000], Train Loss: 0.3256, Val Loss: 0.4163\n",
      "Epoch [1157/10000], Train Loss: 0.3256, Val Loss: 0.4532\n",
      "Epoch [1158/10000], Train Loss: 0.3254, Val Loss: 0.4202\n",
      "Epoch [1159/10000], Train Loss: 0.3264, Val Loss: 0.3845\n",
      "Validation loss improved from 0.3860 to 0.3845. Saving model...\n",
      "Epoch [1160/10000], Train Loss: 0.3257, Val Loss: 0.3993\n",
      "Epoch [1161/10000], Train Loss: 0.3258, Val Loss: 0.6129\n",
      "Epoch [1162/10000], Train Loss: 0.3253, Val Loss: 0.3916\n",
      "Epoch [1163/10000], Train Loss: 0.3259, Val Loss: 0.4694\n",
      "Epoch [1164/10000], Train Loss: 0.3264, Val Loss: 0.4078\n",
      "Epoch [1165/10000], Train Loss: 0.3256, Val Loss: 0.3997\n",
      "Epoch [1166/10000], Train Loss: 0.3258, Val Loss: 0.4120\n",
      "Epoch [1167/10000], Train Loss: 0.3258, Val Loss: 0.5189\n",
      "Epoch [1168/10000], Train Loss: 0.3258, Val Loss: 0.3903\n",
      "Epoch [1169/10000], Train Loss: 0.3257, Val Loss: 0.3989\n",
      "Epoch [1170/10000], Train Loss: 0.3260, Val Loss: 0.3928\n",
      "Epoch [1171/10000], Train Loss: 0.3255, Val Loss: 0.4250\n",
      "Epoch [1172/10000], Train Loss: 0.3260, Val Loss: 0.4024\n",
      "Epoch [1173/10000], Train Loss: 0.3253, Val Loss: 0.4779\n",
      "Epoch [1174/10000], Train Loss: 0.3260, Val Loss: 0.4028\n",
      "Epoch [1175/10000], Train Loss: 0.3259, Val Loss: 0.3924\n",
      "Epoch [1176/10000], Train Loss: 0.3262, Val Loss: 0.4371\n",
      "Epoch [1177/10000], Train Loss: 0.3257, Val Loss: 0.8010\n",
      "Epoch [1178/10000], Train Loss: 0.3265, Val Loss: 0.4290\n",
      "Epoch [1179/10000], Train Loss: 0.3257, Val Loss: 0.5955\n",
      "Epoch [1180/10000], Train Loss: 0.3250, Val Loss: 0.4202\n",
      "Epoch [1181/10000], Train Loss: 0.3252, Val Loss: 0.4122\n",
      "Epoch [1182/10000], Train Loss: 0.3261, Val Loss: 0.4535\n",
      "Epoch [1183/10000], Train Loss: 0.3260, Val Loss: 0.3934\n",
      "Epoch [1184/10000], Train Loss: 0.3261, Val Loss: 0.4017\n",
      "Epoch [1185/10000], Train Loss: 0.3259, Val Loss: 0.4107\n",
      "Epoch [1186/10000], Train Loss: 0.3256, Val Loss: 0.4314\n",
      "Epoch [1187/10000], Train Loss: 0.3263, Val Loss: 0.3989\n",
      "Epoch [1188/10000], Train Loss: 0.3246, Val Loss: 0.4022\n",
      "Epoch [1189/10000], Train Loss: 0.3256, Val Loss: 0.4606\n",
      "Epoch [1190/10000], Train Loss: 0.3264, Val Loss: 0.4034\n",
      "Epoch [1191/10000], Train Loss: 0.3259, Val Loss: 0.4713\n",
      "Epoch [1192/10000], Train Loss: 0.3268, Val Loss: 0.4453\n",
      "Epoch [1193/10000], Train Loss: 0.3257, Val Loss: 0.3878\n",
      "Epoch [1194/10000], Train Loss: 0.3250, Val Loss: 0.4070\n",
      "Epoch [1195/10000], Train Loss: 0.3261, Val Loss: 0.3866\n",
      "Epoch [1196/10000], Train Loss: 0.3253, Val Loss: 0.4390\n",
      "Epoch [1197/10000], Train Loss: 0.3257, Val Loss: 0.4244\n",
      "Epoch [1198/10000], Train Loss: 0.3254, Val Loss: 0.4070\n",
      "Epoch [1199/10000], Train Loss: 0.3254, Val Loss: 0.5006\n",
      "Epoch [1200/10000], Train Loss: 0.3262, Val Loss: 0.4094\n",
      "Epoch [1201/10000], Train Loss: 0.3254, Val Loss: 0.4006\n",
      "Epoch [1202/10000], Train Loss: 0.3264, Val Loss: 0.4025\n",
      "Epoch [1203/10000], Train Loss: 0.3256, Val Loss: 0.4017\n",
      "Epoch [1204/10000], Train Loss: 0.3257, Val Loss: 0.4186\n",
      "Epoch [1205/10000], Train Loss: 0.3256, Val Loss: 0.4081\n",
      "Epoch [1206/10000], Train Loss: 0.3267, Val Loss: 0.4175\n",
      "Epoch [1207/10000], Train Loss: 0.3256, Val Loss: 0.4715\n",
      "Epoch [1208/10000], Train Loss: 0.3253, Val Loss: 0.4694\n",
      "Epoch [1209/10000], Train Loss: 0.3258, Val Loss: 0.4096\n",
      "Epoch [1210/10000], Train Loss: 0.3259, Val Loss: 0.4012\n",
      "Epoch [1211/10000], Train Loss: 0.3265, Val Loss: 0.3943\n",
      "Epoch [1212/10000], Train Loss: 0.3263, Val Loss: 0.4134\n",
      "Epoch [1213/10000], Train Loss: 0.3258, Val Loss: 0.3963\n",
      "Epoch [1214/10000], Train Loss: 0.3256, Val Loss: 0.4096\n",
      "Epoch [1215/10000], Train Loss: 0.3260, Val Loss: 0.3965\n",
      "Epoch [1216/10000], Train Loss: 0.3262, Val Loss: 0.3975\n",
      "Epoch [1217/10000], Train Loss: 0.3269, Val Loss: 0.5187\n",
      "Epoch [1218/10000], Train Loss: 0.3254, Val Loss: 0.4909\n",
      "Epoch [1219/10000], Train Loss: 0.3254, Val Loss: 0.3944\n",
      "Epoch [1220/10000], Train Loss: 0.3259, Val Loss: 0.3996\n",
      "Epoch [1221/10000], Train Loss: 0.3259, Val Loss: 0.3932\n",
      "Epoch [1222/10000], Train Loss: 0.3258, Val Loss: 0.3973\n",
      "Epoch [1223/10000], Train Loss: 0.3262, Val Loss: 0.3876\n",
      "Epoch [1224/10000], Train Loss: 0.3253, Val Loss: 0.4117\n",
      "Epoch [1225/10000], Train Loss: 0.3260, Val Loss: 0.3975\n",
      "Epoch [1226/10000], Train Loss: 0.3257, Val Loss: 0.3986\n",
      "Epoch [1227/10000], Train Loss: 0.3251, Val Loss: 0.4660\n",
      "Epoch [1228/10000], Train Loss: 0.3254, Val Loss: 0.3975\n",
      "Epoch [1229/10000], Train Loss: 0.3266, Val Loss: 0.4643\n",
      "Epoch [1230/10000], Train Loss: 0.3258, Val Loss: 0.4175\n",
      "Epoch [1231/10000], Train Loss: 0.3261, Val Loss: 0.4128\n",
      "Epoch [1232/10000], Train Loss: 0.3257, Val Loss: 0.4418\n",
      "Epoch [1233/10000], Train Loss: 0.3259, Val Loss: 0.4015\n",
      "Epoch [1234/10000], Train Loss: 0.3259, Val Loss: 0.3891\n",
      "Epoch [1235/10000], Train Loss: 0.3252, Val Loss: 0.4094\n",
      "Epoch [1236/10000], Train Loss: 0.3260, Val Loss: 0.4102\n",
      "Epoch [1237/10000], Train Loss: 0.3257, Val Loss: 0.4914\n",
      "Epoch [1238/10000], Train Loss: 0.3254, Val Loss: 0.3951\n",
      "Epoch [1239/10000], Train Loss: 0.3261, Val Loss: 0.3899\n",
      "Epoch [1240/10000], Train Loss: 0.3258, Val Loss: 0.4215\n",
      "Epoch [1241/10000], Train Loss: 0.3254, Val Loss: 0.4025\n",
      "Epoch [1242/10000], Train Loss: 0.3256, Val Loss: 0.4739\n",
      "Epoch [1243/10000], Train Loss: 0.3259, Val Loss: 0.3921\n",
      "Epoch [1244/10000], Train Loss: 0.3258, Val Loss: 0.4294\n",
      "Epoch [1245/10000], Train Loss: 0.3259, Val Loss: 0.4110\n",
      "Epoch [1246/10000], Train Loss: 0.3251, Val Loss: 0.4090\n",
      "Epoch [1247/10000], Train Loss: 0.3258, Val Loss: 0.3901\n",
      "Epoch [1248/10000], Train Loss: 0.3253, Val Loss: 0.4201\n",
      "Epoch [1249/10000], Train Loss: 0.3253, Val Loss: 0.4245\n",
      "Epoch [1250/10000], Train Loss: 0.3260, Val Loss: 0.4331\n",
      "Epoch [1251/10000], Train Loss: 0.3254, Val Loss: 0.4407\n",
      "Epoch [1252/10000], Train Loss: 0.3251, Val Loss: 0.4151\n",
      "Epoch [1253/10000], Train Loss: 0.3258, Val Loss: 0.4790\n",
      "Epoch [1254/10000], Train Loss: 0.3255, Val Loss: 0.4473\n",
      "Epoch [1255/10000], Train Loss: 0.3256, Val Loss: 0.4057\n",
      "Epoch [1256/10000], Train Loss: 0.3252, Val Loss: 0.4405\n",
      "Epoch [1257/10000], Train Loss: 0.3258, Val Loss: 0.3922\n",
      "Epoch [1258/10000], Train Loss: 0.3265, Val Loss: 0.4438\n",
      "Epoch [1259/10000], Train Loss: 0.3256, Val Loss: 0.3893\n",
      "Epoch [1260/10000], Train Loss: 0.3255, Val Loss: 0.3883\n",
      "Epoch [1261/10000], Train Loss: 0.3270, Val Loss: 0.3940\n",
      "Epoch [1262/10000], Train Loss: 0.3248, Val Loss: 0.4251\n",
      "Epoch [1263/10000], Train Loss: 0.3255, Val Loss: 0.4289\n",
      "Epoch [1264/10000], Train Loss: 0.3251, Val Loss: 0.4579\n",
      "Epoch [1265/10000], Train Loss: 0.3249, Val Loss: 0.4082\n",
      "Epoch [1266/10000], Train Loss: 0.3254, Val Loss: 0.4033\n",
      "Epoch [1267/10000], Train Loss: 0.3248, Val Loss: 0.4287\n",
      "Epoch [1268/10000], Train Loss: 0.3253, Val Loss: 0.3988\n",
      "Epoch [1269/10000], Train Loss: 0.3260, Val Loss: 0.4876\n",
      "Epoch [1270/10000], Train Loss: 0.3261, Val Loss: 0.4040\n",
      "Epoch [1271/10000], Train Loss: 0.3254, Val Loss: 0.4064\n",
      "Epoch [1272/10000], Train Loss: 0.3255, Val Loss: 0.4054\n",
      "Epoch [1273/10000], Train Loss: 0.3260, Val Loss: 0.5207\n",
      "Epoch [1274/10000], Train Loss: 0.3256, Val Loss: 0.4659\n",
      "Epoch [1275/10000], Train Loss: 0.3255, Val Loss: 0.3983\n",
      "Epoch [1276/10000], Train Loss: 0.3256, Val Loss: 0.3866\n",
      "Epoch [1277/10000], Train Loss: 0.3254, Val Loss: 0.4226\n",
      "Epoch [1278/10000], Train Loss: 0.3257, Val Loss: 0.4168\n",
      "Epoch [1279/10000], Train Loss: 0.3253, Val Loss: 0.3863\n",
      "Epoch [1280/10000], Train Loss: 0.3258, Val Loss: 0.4702\n",
      "Epoch [1281/10000], Train Loss: 0.3254, Val Loss: 0.3948\n",
      "Epoch [1282/10000], Train Loss: 0.3257, Val Loss: 0.4327\n",
      "Epoch [1283/10000], Train Loss: 0.3253, Val Loss: 0.3909\n",
      "Epoch [1284/10000], Train Loss: 0.3251, Val Loss: 0.4045\n",
      "Epoch [1285/10000], Train Loss: 0.3254, Val Loss: 0.4275\n",
      "Epoch [1286/10000], Train Loss: 0.3253, Val Loss: 0.3962\n",
      "Epoch [1287/10000], Train Loss: 0.3254, Val Loss: 0.4283\n",
      "Epoch [1288/10000], Train Loss: 0.3257, Val Loss: 0.4756\n",
      "Epoch [1289/10000], Train Loss: 0.3250, Val Loss: 0.6072\n",
      "Epoch [1290/10000], Train Loss: 0.3259, Val Loss: 0.4082\n",
      "Epoch [1291/10000], Train Loss: 0.3259, Val Loss: 0.4899\n",
      "Epoch [1292/10000], Train Loss: 0.3254, Val Loss: 0.4140\n",
      "Epoch [1293/10000], Train Loss: 0.3250, Val Loss: 0.4254\n",
      "Epoch [1294/10000], Train Loss: 0.3266, Val Loss: 0.5036\n",
      "Epoch [1295/10000], Train Loss: 0.3251, Val Loss: 0.4023\n",
      "Epoch [1296/10000], Train Loss: 0.3261, Val Loss: 0.3925\n",
      "Epoch [1297/10000], Train Loss: 0.3246, Val Loss: 0.4132\n",
      "Epoch [1298/10000], Train Loss: 0.3258, Val Loss: 0.4780\n",
      "Epoch [1299/10000], Train Loss: 0.3257, Val Loss: 0.3923\n",
      "Epoch [1300/10000], Train Loss: 0.3253, Val Loss: 0.4497\n",
      "Epoch [1301/10000], Train Loss: 0.3259, Val Loss: 0.4175\n",
      "Epoch [1302/10000], Train Loss: 0.3260, Val Loss: 0.4204\n",
      "Epoch [1303/10000], Train Loss: 0.3254, Val Loss: 0.4250\n",
      "Epoch [1304/10000], Train Loss: 0.3255, Val Loss: 0.3993\n",
      "Epoch [1305/10000], Train Loss: 0.3263, Val Loss: 0.3948\n",
      "Epoch [1306/10000], Train Loss: 0.3255, Val Loss: 0.5227\n",
      "Epoch [1307/10000], Train Loss: 0.3255, Val Loss: 0.4408\n",
      "Epoch [1308/10000], Train Loss: 0.3260, Val Loss: 0.4075\n",
      "Epoch [1309/10000], Train Loss: 0.3255, Val Loss: 0.4388\n",
      "Epoch [1310/10000], Train Loss: 0.3255, Val Loss: 0.3855\n",
      "Epoch [1311/10000], Train Loss: 0.3253, Val Loss: 0.4115\n",
      "Epoch [1312/10000], Train Loss: 0.3252, Val Loss: 0.4053\n",
      "Epoch [1313/10000], Train Loss: 0.3254, Val Loss: 0.3877\n",
      "Epoch [1314/10000], Train Loss: 0.3259, Val Loss: 0.3936\n",
      "Epoch [1315/10000], Train Loss: 0.3266, Val Loss: 0.4414\n",
      "Epoch [1316/10000], Train Loss: 0.3247, Val Loss: 0.4233\n",
      "Epoch [1317/10000], Train Loss: 0.3253, Val Loss: 0.4040\n",
      "Epoch [1318/10000], Train Loss: 0.3251, Val Loss: 0.4932\n",
      "Epoch [1319/10000], Train Loss: 0.3260, Val Loss: 0.4378\n",
      "Epoch [1320/10000], Train Loss: 0.3252, Val Loss: 0.4038\n",
      "Epoch [1321/10000], Train Loss: 0.3254, Val Loss: 0.4259\n",
      "Epoch [1322/10000], Train Loss: 0.3250, Val Loss: 0.4015\n",
      "Epoch [1323/10000], Train Loss: 0.3257, Val Loss: 0.4067\n",
      "Epoch [1324/10000], Train Loss: 0.3263, Val Loss: 0.4129\n",
      "Epoch [1325/10000], Train Loss: 0.3254, Val Loss: 0.3926\n",
      "Epoch [1326/10000], Train Loss: 0.3263, Val Loss: 0.4064\n",
      "Epoch [1327/10000], Train Loss: 0.3251, Val Loss: 0.4102\n",
      "Epoch [1328/10000], Train Loss: 0.3252, Val Loss: 0.5006\n",
      "Epoch [1329/10000], Train Loss: 0.3253, Val Loss: 0.4040\n",
      "Epoch [1330/10000], Train Loss: 0.3253, Val Loss: 0.3918\n",
      "Epoch [1331/10000], Train Loss: 0.3255, Val Loss: 0.4153\n",
      "Epoch [1332/10000], Train Loss: 0.3254, Val Loss: 0.5231\n",
      "Epoch [1333/10000], Train Loss: 0.3255, Val Loss: 0.4006\n",
      "Epoch [1334/10000], Train Loss: 0.3263, Val Loss: 0.4217\n",
      "Epoch [1335/10000], Train Loss: 0.3255, Val Loss: 0.4193\n",
      "Epoch [1336/10000], Train Loss: 0.3252, Val Loss: 0.4169\n",
      "Epoch [1337/10000], Train Loss: 0.3257, Val Loss: 0.6005\n",
      "Epoch [1338/10000], Train Loss: 0.3260, Val Loss: 0.3959\n",
      "Epoch [1339/10000], Train Loss: 0.3253, Val Loss: 0.3834\n",
      "Validation loss improved from 0.3845 to 0.3834. Saving model...\n",
      "Epoch [1340/10000], Train Loss: 0.3255, Val Loss: 0.4503\n",
      "Epoch [1341/10000], Train Loss: 0.3255, Val Loss: 0.3938\n",
      "Epoch [1342/10000], Train Loss: 0.3255, Val Loss: 0.3923\n",
      "Epoch [1343/10000], Train Loss: 0.3261, Val Loss: 0.4430\n",
      "Epoch [1344/10000], Train Loss: 0.3254, Val Loss: 0.4624\n",
      "Epoch [1345/10000], Train Loss: 0.3261, Val Loss: 0.3946\n",
      "Epoch [1346/10000], Train Loss: 0.3252, Val Loss: 0.4163\n",
      "Epoch [1347/10000], Train Loss: 0.3253, Val Loss: 0.5618\n",
      "Epoch [1348/10000], Train Loss: 0.3253, Val Loss: 0.3991\n",
      "Epoch [1349/10000], Train Loss: 0.3252, Val Loss: 0.4219\n",
      "Epoch [1350/10000], Train Loss: 0.3256, Val Loss: 0.3981\n",
      "Epoch [1351/10000], Train Loss: 0.3255, Val Loss: 0.4789\n",
      "Epoch [1352/10000], Train Loss: 0.3251, Val Loss: 0.4118\n",
      "Epoch [1353/10000], Train Loss: 0.3254, Val Loss: 0.3970\n",
      "Epoch [1354/10000], Train Loss: 0.3254, Val Loss: 0.4805\n",
      "Epoch [1355/10000], Train Loss: 0.3257, Val Loss: 0.4401\n",
      "Epoch [1356/10000], Train Loss: 0.3254, Val Loss: 0.4588\n",
      "Epoch [1357/10000], Train Loss: 0.3256, Val Loss: 0.4257\n",
      "Epoch [1358/10000], Train Loss: 0.3256, Val Loss: 0.4196\n",
      "Epoch [1359/10000], Train Loss: 0.3259, Val Loss: 0.4135\n",
      "Epoch [1360/10000], Train Loss: 0.3253, Val Loss: 0.4224\n",
      "Epoch [1361/10000], Train Loss: 0.3262, Val Loss: 0.3914\n",
      "Epoch [1362/10000], Train Loss: 0.3258, Val Loss: 0.4363\n",
      "Epoch [1363/10000], Train Loss: 0.3250, Val Loss: 0.3914\n",
      "Epoch [1364/10000], Train Loss: 0.3250, Val Loss: 0.5270\n",
      "Epoch [1365/10000], Train Loss: 0.3255, Val Loss: 0.4046\n",
      "Epoch [1366/10000], Train Loss: 0.3249, Val Loss: 0.4125\n",
      "Epoch [1367/10000], Train Loss: 0.3259, Val Loss: 0.3918\n",
      "Epoch [1368/10000], Train Loss: 0.3256, Val Loss: 0.4394\n",
      "Epoch [1369/10000], Train Loss: 0.3255, Val Loss: 0.3869\n",
      "Epoch [1370/10000], Train Loss: 0.3246, Val Loss: 0.4358\n",
      "Epoch [1371/10000], Train Loss: 0.3258, Val Loss: 0.4451\n",
      "Epoch [1372/10000], Train Loss: 0.3252, Val Loss: 0.4323\n",
      "Epoch [1373/10000], Train Loss: 0.3253, Val Loss: 0.3902\n",
      "Epoch [1374/10000], Train Loss: 0.3256, Val Loss: 0.3962\n",
      "Epoch [1375/10000], Train Loss: 0.3247, Val Loss: 0.3943\n",
      "Epoch [1376/10000], Train Loss: 0.3253, Val Loss: 0.4082\n",
      "Epoch [1377/10000], Train Loss: 0.3254, Val Loss: 0.4992\n",
      "Epoch [1378/10000], Train Loss: 0.3255, Val Loss: 0.3962\n",
      "Epoch [1379/10000], Train Loss: 0.3250, Val Loss: 0.4584\n",
      "Epoch [1380/10000], Train Loss: 0.3246, Val Loss: 0.3878\n",
      "Epoch [1381/10000], Train Loss: 0.3244, Val Loss: 0.3962\n",
      "Epoch [1382/10000], Train Loss: 0.3270, Val Loss: 0.4016\n",
      "Epoch [1383/10000], Train Loss: 0.3244, Val Loss: 0.4301\n",
      "Epoch [1384/10000], Train Loss: 0.3250, Val Loss: 0.4242\n",
      "Epoch [1385/10000], Train Loss: 0.3253, Val Loss: 0.3863\n",
      "Epoch [1386/10000], Train Loss: 0.3246, Val Loss: 0.4183\n",
      "Epoch [1387/10000], Train Loss: 0.3245, Val Loss: 0.3925\n",
      "Epoch [1388/10000], Train Loss: 0.3251, Val Loss: 0.4133\n",
      "Epoch [1389/10000], Train Loss: 0.3248, Val Loss: 0.3931\n",
      "Epoch [1390/10000], Train Loss: 0.3246, Val Loss: 0.3933\n",
      "Epoch [1391/10000], Train Loss: 0.3245, Val Loss: 0.4432\n",
      "Epoch [1392/10000], Train Loss: 0.3249, Val Loss: 0.4394\n",
      "Epoch [1393/10000], Train Loss: 0.3245, Val Loss: 0.3862\n",
      "Epoch [1394/10000], Train Loss: 0.3250, Val Loss: 0.4092\n",
      "Epoch [1395/10000], Train Loss: 0.3246, Val Loss: 0.4089\n",
      "Epoch [1396/10000], Train Loss: 0.3246, Val Loss: 0.3996\n",
      "Epoch [1397/10000], Train Loss: 0.3242, Val Loss: 0.3952\n",
      "Epoch [1398/10000], Train Loss: 0.3242, Val Loss: 0.3997\n",
      "Epoch [1399/10000], Train Loss: 0.3250, Val Loss: 0.3892\n",
      "Epoch [1400/10000], Train Loss: 0.3235, Val Loss: 0.4596\n",
      "Epoch [1401/10000], Train Loss: 0.3245, Val Loss: 0.4023\n",
      "Epoch [1402/10000], Train Loss: 0.3248, Val Loss: 0.3908\n",
      "Epoch [1403/10000], Train Loss: 0.3256, Val Loss: 0.4096\n",
      "Epoch [1404/10000], Train Loss: 0.3246, Val Loss: 0.3820\n",
      "Validation loss improved from 0.3834 to 0.3820. Saving model...\n",
      "Epoch [1405/10000], Train Loss: 0.3246, Val Loss: 0.4121\n",
      "Epoch [1406/10000], Train Loss: 0.3249, Val Loss: 0.3861\n",
      "Epoch [1407/10000], Train Loss: 0.3246, Val Loss: 0.3870\n",
      "Epoch [1408/10000], Train Loss: 0.3245, Val Loss: 0.4226\n",
      "Epoch [1409/10000], Train Loss: 0.3241, Val Loss: 0.3949\n",
      "Epoch [1410/10000], Train Loss: 0.3249, Val Loss: 0.4059\n",
      "Epoch [1411/10000], Train Loss: 0.3250, Val Loss: 0.4116\n",
      "Epoch [1412/10000], Train Loss: 0.3243, Val Loss: 0.4105\n",
      "Epoch [1413/10000], Train Loss: 0.3251, Val Loss: 0.4052\n",
      "Epoch [1414/10000], Train Loss: 0.3248, Val Loss: 0.3973\n",
      "Epoch [1415/10000], Train Loss: 0.3246, Val Loss: 0.3884\n",
      "Epoch [1416/10000], Train Loss: 0.3249, Val Loss: 0.3857\n",
      "Epoch [1417/10000], Train Loss: 0.3247, Val Loss: 0.4426\n",
      "Epoch [1418/10000], Train Loss: 0.3245, Val Loss: 0.4325\n",
      "Epoch [1419/10000], Train Loss: 0.3245, Val Loss: 0.4419\n",
      "Epoch [1420/10000], Train Loss: 0.3247, Val Loss: 0.4004\n",
      "Epoch [1421/10000], Train Loss: 0.3241, Val Loss: 0.4134\n",
      "Epoch [1422/10000], Train Loss: 0.3244, Val Loss: 0.3829\n",
      "Epoch [1423/10000], Train Loss: 0.3249, Val Loss: 0.3928\n",
      "Epoch [1424/10000], Train Loss: 0.3246, Val Loss: 0.4294\n",
      "Epoch [1425/10000], Train Loss: 0.3243, Val Loss: 0.4016\n",
      "Epoch [1426/10000], Train Loss: 0.3239, Val Loss: 0.4287\n",
      "Epoch [1427/10000], Train Loss: 0.3240, Val Loss: 0.3950\n",
      "Epoch [1428/10000], Train Loss: 0.3242, Val Loss: 0.3910\n",
      "Epoch [1429/10000], Train Loss: 0.3241, Val Loss: 0.3854\n",
      "Epoch [1430/10000], Train Loss: 0.3245, Val Loss: 0.3951\n",
      "Epoch [1431/10000], Train Loss: 0.3242, Val Loss: 0.3878\n",
      "Epoch [1432/10000], Train Loss: 0.3248, Val Loss: 0.4052\n",
      "Epoch [1433/10000], Train Loss: 0.3250, Val Loss: 0.5476\n",
      "Epoch [1434/10000], Train Loss: 0.3243, Val Loss: 0.4152\n",
      "Epoch [1435/10000], Train Loss: 0.3247, Val Loss: 0.4521\n",
      "Epoch [1436/10000], Train Loss: 0.3240, Val Loss: 0.3838\n",
      "Epoch [1437/10000], Train Loss: 0.3247, Val Loss: 0.3969\n",
      "Epoch [1438/10000], Train Loss: 0.3245, Val Loss: 0.5042\n",
      "Epoch [1439/10000], Train Loss: 0.3247, Val Loss: 0.4464\n",
      "Epoch [1440/10000], Train Loss: 0.3257, Val Loss: 0.4109\n",
      "Epoch [1441/10000], Train Loss: 0.3245, Val Loss: 0.3904\n",
      "Epoch [1442/10000], Train Loss: 0.3245, Val Loss: 0.3873\n",
      "Epoch [1443/10000], Train Loss: 0.3242, Val Loss: 0.3958\n",
      "Epoch [1444/10000], Train Loss: 0.3241, Val Loss: 0.3966\n",
      "Epoch [1445/10000], Train Loss: 0.3244, Val Loss: 0.5303\n",
      "Epoch [1446/10000], Train Loss: 0.3242, Val Loss: 0.3879\n",
      "Epoch [1447/10000], Train Loss: 0.3248, Val Loss: 0.4031\n",
      "Epoch [1448/10000], Train Loss: 0.3249, Val Loss: 0.4125\n",
      "Epoch [1449/10000], Train Loss: 0.3244, Val Loss: 0.3965\n",
      "Epoch [1450/10000], Train Loss: 0.3242, Val Loss: 0.5184\n",
      "Epoch [1451/10000], Train Loss: 0.3247, Val Loss: 0.4235\n",
      "Epoch [1452/10000], Train Loss: 0.3241, Val Loss: 0.4715\n",
      "Epoch [1453/10000], Train Loss: 0.3249, Val Loss: 0.4290\n",
      "Epoch [1454/10000], Train Loss: 0.3244, Val Loss: 0.3935\n",
      "Epoch [1455/10000], Train Loss: 0.3245, Val Loss: 0.4156\n",
      "Epoch [1456/10000], Train Loss: 0.3245, Val Loss: 0.4846\n",
      "Epoch [1457/10000], Train Loss: 0.3247, Val Loss: 0.3832\n",
      "Epoch [1458/10000], Train Loss: 0.3242, Val Loss: 0.4230\n",
      "Epoch [1459/10000], Train Loss: 0.3243, Val Loss: 0.4027\n",
      "Epoch [1460/10000], Train Loss: 0.3245, Val Loss: 0.3825\n",
      "Epoch [1461/10000], Train Loss: 0.3244, Val Loss: 0.4325\n",
      "Epoch [1462/10000], Train Loss: 0.3241, Val Loss: 0.4181\n",
      "Epoch [1463/10000], Train Loss: 0.3242, Val Loss: 0.4007\n",
      "Epoch [1464/10000], Train Loss: 0.3239, Val Loss: 0.4042\n",
      "Epoch [1465/10000], Train Loss: 0.3242, Val Loss: 0.4430\n",
      "Epoch [1466/10000], Train Loss: 0.3242, Val Loss: 0.3959\n",
      "Epoch [1467/10000], Train Loss: 0.3245, Val Loss: 0.3906\n",
      "Epoch [1468/10000], Train Loss: 0.3246, Val Loss: 0.3973\n",
      "Epoch [1469/10000], Train Loss: 0.3239, Val Loss: 0.4497\n",
      "Epoch [1470/10000], Train Loss: 0.3241, Val Loss: 0.4291\n",
      "Epoch [1471/10000], Train Loss: 0.3243, Val Loss: 0.3994\n",
      "Epoch [1472/10000], Train Loss: 0.3243, Val Loss: 0.3859\n",
      "Epoch [1473/10000], Train Loss: 0.3248, Val Loss: 0.3883\n",
      "Epoch [1474/10000], Train Loss: 0.3247, Val Loss: 0.5705\n",
      "Epoch [1475/10000], Train Loss: 0.3243, Val Loss: 0.3989\n",
      "Epoch [1476/10000], Train Loss: 0.3240, Val Loss: 0.4756\n",
      "Epoch [1477/10000], Train Loss: 0.3242, Val Loss: 0.4279\n",
      "Epoch [1478/10000], Train Loss: 0.3248, Val Loss: 0.4055\n",
      "Epoch [1479/10000], Train Loss: 0.3244, Val Loss: 0.4017\n",
      "Epoch [1480/10000], Train Loss: 0.3242, Val Loss: 0.4216\n",
      "Epoch [1481/10000], Train Loss: 0.3250, Val Loss: 0.3998\n",
      "Epoch [1482/10000], Train Loss: 0.3246, Val Loss: 0.4433\n",
      "Epoch [1483/10000], Train Loss: 0.3245, Val Loss: 0.3936\n",
      "Epoch [1484/10000], Train Loss: 0.3242, Val Loss: 0.4248\n",
      "Epoch [1485/10000], Train Loss: 0.3245, Val Loss: 0.3942\n",
      "Epoch [1486/10000], Train Loss: 0.3237, Val Loss: 0.4144\n",
      "Epoch [1487/10000], Train Loss: 0.3242, Val Loss: 0.4175\n",
      "Epoch [1488/10000], Train Loss: 0.3244, Val Loss: 0.4382\n",
      "Epoch [1489/10000], Train Loss: 0.3239, Val Loss: 0.4370\n",
      "Epoch [1490/10000], Train Loss: 0.3246, Val Loss: 0.4030\n",
      "Epoch [1491/10000], Train Loss: 0.3255, Val Loss: 0.3889\n",
      "Epoch [1492/10000], Train Loss: 0.3236, Val Loss: 0.3912\n",
      "Epoch [1493/10000], Train Loss: 0.3246, Val Loss: 0.4489\n",
      "Epoch [1494/10000], Train Loss: 0.3242, Val Loss: 0.3984\n",
      "Epoch [1495/10000], Train Loss: 0.3242, Val Loss: 0.4325\n",
      "Epoch [1496/10000], Train Loss: 0.3237, Val Loss: 0.4318\n",
      "Epoch [1497/10000], Train Loss: 0.3238, Val Loss: 0.4177\n",
      "Epoch [1498/10000], Train Loss: 0.3246, Val Loss: 0.3932\n",
      "Epoch [1499/10000], Train Loss: 0.3243, Val Loss: 0.3940\n",
      "Epoch [1500/10000], Train Loss: 0.3240, Val Loss: 0.4013\n",
      "Epoch [1501/10000], Train Loss: 0.3241, Val Loss: 0.3883\n",
      "Epoch [1502/10000], Train Loss: 0.3243, Val Loss: 0.3922\n",
      "Epoch [1503/10000], Train Loss: 0.3250, Val Loss: 0.4347\n",
      "Epoch [1504/10000], Train Loss: 0.3248, Val Loss: 0.4008\n",
      "Epoch [1505/10000], Train Loss: 0.3248, Val Loss: 0.4022\n",
      "Epoch [1506/10000], Train Loss: 0.3246, Val Loss: 0.3978\n",
      "Epoch [1507/10000], Train Loss: 0.3238, Val Loss: 0.4047\n",
      "Epoch [1508/10000], Train Loss: 0.3241, Val Loss: 0.9589\n",
      "Epoch [1509/10000], Train Loss: 0.3243, Val Loss: 0.3980\n",
      "Epoch [1510/10000], Train Loss: 0.3242, Val Loss: 0.3851\n",
      "Epoch [1511/10000], Train Loss: 0.3240, Val Loss: 0.4199\n",
      "Epoch [1512/10000], Train Loss: 0.3242, Val Loss: 0.7105\n",
      "Epoch [1513/10000], Train Loss: 0.3248, Val Loss: 0.4000\n",
      "Epoch [1514/10000], Train Loss: 0.3240, Val Loss: 0.5844\n",
      "Epoch [1515/10000], Train Loss: 0.3242, Val Loss: 0.3796\n",
      "Validation loss improved from 0.3820 to 0.3796. Saving model...\n",
      "Epoch [1516/10000], Train Loss: 0.3243, Val Loss: 0.4958\n",
      "Epoch [1517/10000], Train Loss: 0.3247, Val Loss: 0.4616\n",
      "Epoch [1518/10000], Train Loss: 0.3244, Val Loss: 0.3838\n",
      "Epoch [1519/10000], Train Loss: 0.3242, Val Loss: 0.4126\n",
      "Epoch [1520/10000], Train Loss: 0.3245, Val Loss: 0.3870\n",
      "Epoch [1521/10000], Train Loss: 0.3241, Val Loss: 0.4318\n",
      "Epoch [1522/10000], Train Loss: 0.3240, Val Loss: 0.3848\n",
      "Epoch [1523/10000], Train Loss: 0.3242, Val Loss: 0.3964\n",
      "Epoch [1524/10000], Train Loss: 0.3240, Val Loss: 0.3826\n",
      "Epoch [1525/10000], Train Loss: 0.3241, Val Loss: 0.4033\n",
      "Epoch [1526/10000], Train Loss: 0.3242, Val Loss: 0.4144\n",
      "Epoch [1527/10000], Train Loss: 0.3242, Val Loss: 0.3916\n",
      "Epoch [1528/10000], Train Loss: 0.3250, Val Loss: 0.4466\n",
      "Epoch [1529/10000], Train Loss: 0.3234, Val Loss: 0.4084\n",
      "Epoch [1530/10000], Train Loss: 0.3250, Val Loss: 0.4068\n",
      "Epoch [1531/10000], Train Loss: 0.3243, Val Loss: 0.4488\n",
      "Epoch [1532/10000], Train Loss: 0.3240, Val Loss: 0.4074\n",
      "Epoch [1533/10000], Train Loss: 0.3241, Val Loss: 0.4403\n",
      "Epoch [1534/10000], Train Loss: 0.3243, Val Loss: 0.4164\n",
      "Epoch [1535/10000], Train Loss: 0.3248, Val Loss: 0.4296\n",
      "Epoch [1536/10000], Train Loss: 0.3242, Val Loss: 0.4041\n",
      "Epoch [1537/10000], Train Loss: 0.3244, Val Loss: 0.3832\n",
      "Epoch [1538/10000], Train Loss: 0.3241, Val Loss: 0.4227\n",
      "Epoch [1539/10000], Train Loss: 0.3242, Val Loss: 0.3815\n",
      "Epoch [1540/10000], Train Loss: 0.3244, Val Loss: 0.4033\n",
      "Epoch [1541/10000], Train Loss: 0.3242, Val Loss: 0.4016\n",
      "Epoch [1542/10000], Train Loss: 0.3246, Val Loss: 0.3857\n",
      "Epoch [1543/10000], Train Loss: 0.3244, Val Loss: 0.3921\n",
      "Epoch [1544/10000], Train Loss: 0.3242, Val Loss: 0.4173\n",
      "Epoch [1545/10000], Train Loss: 0.3251, Val Loss: 0.4030\n",
      "Epoch [1546/10000], Train Loss: 0.3237, Val Loss: 0.4122\n",
      "Epoch [1547/10000], Train Loss: 0.3254, Val Loss: 0.4156\n",
      "Epoch [1548/10000], Train Loss: 0.3244, Val Loss: 0.4183\n",
      "Epoch [1549/10000], Train Loss: 0.3246, Val Loss: 0.5113\n",
      "Epoch [1550/10000], Train Loss: 0.3239, Val Loss: 0.4236\n",
      "Epoch [1551/10000], Train Loss: 0.3237, Val Loss: 0.3868\n",
      "Epoch [1552/10000], Train Loss: 0.3247, Val Loss: 0.4524\n",
      "Epoch [1553/10000], Train Loss: 0.3238, Val Loss: 0.4740\n",
      "Epoch [1554/10000], Train Loss: 0.3244, Val Loss: 0.3864\n",
      "Epoch [1555/10000], Train Loss: 0.3246, Val Loss: 0.4035\n",
      "Epoch [1556/10000], Train Loss: 0.3243, Val Loss: 0.3834\n",
      "Epoch [1557/10000], Train Loss: 0.3244, Val Loss: 0.3996\n",
      "Epoch [1558/10000], Train Loss: 0.3240, Val Loss: 0.4060\n",
      "Epoch [1559/10000], Train Loss: 0.3245, Val Loss: 0.4173\n",
      "Epoch [1560/10000], Train Loss: 0.3249, Val Loss: 0.3844\n",
      "Epoch [1561/10000], Train Loss: 0.3242, Val Loss: 0.3968\n",
      "Epoch [1562/10000], Train Loss: 0.3242, Val Loss: 0.3938\n",
      "Epoch [1563/10000], Train Loss: 0.3244, Val Loss: 0.4329\n",
      "Epoch [1564/10000], Train Loss: 0.3246, Val Loss: 0.4020\n",
      "Epoch [1565/10000], Train Loss: 0.3247, Val Loss: 0.3833\n",
      "Epoch [1566/10000], Train Loss: 0.3239, Val Loss: 0.4214\n",
      "Epoch [1567/10000], Train Loss: 0.3244, Val Loss: 0.4643\n",
      "Epoch [1568/10000], Train Loss: 0.3236, Val Loss: 0.4363\n",
      "Epoch [1569/10000], Train Loss: 0.3238, Val Loss: 0.4381\n",
      "Epoch [1570/10000], Train Loss: 0.3241, Val Loss: 0.3902\n",
      "Epoch [1571/10000], Train Loss: 0.3239, Val Loss: 0.3918\n",
      "Epoch [1572/10000], Train Loss: 0.3246, Val Loss: 0.4036\n",
      "Epoch [1573/10000], Train Loss: 0.3239, Val Loss: 0.4139\n",
      "Epoch [1574/10000], Train Loss: 0.3244, Val Loss: 0.4002\n",
      "Epoch [1575/10000], Train Loss: 0.3243, Val Loss: 0.3883\n",
      "Epoch [1576/10000], Train Loss: 0.3239, Val Loss: 0.3881\n",
      "Epoch [1577/10000], Train Loss: 0.3239, Val Loss: 0.4085\n",
      "Epoch [1578/10000], Train Loss: 0.3246, Val Loss: 0.4028\n",
      "Epoch [1579/10000], Train Loss: 0.3240, Val Loss: 0.3979\n",
      "Epoch [1580/10000], Train Loss: 0.3240, Val Loss: 0.4186\n",
      "Epoch [1581/10000], Train Loss: 0.3250, Val Loss: 0.3910\n",
      "Epoch [1582/10000], Train Loss: 0.3239, Val Loss: 0.4022\n",
      "Epoch [1583/10000], Train Loss: 0.3249, Val Loss: 0.3881\n",
      "Epoch [1584/10000], Train Loss: 0.3238, Val Loss: 0.3882\n",
      "Epoch [1585/10000], Train Loss: 0.3240, Val Loss: 0.4407\n",
      "Epoch [1586/10000], Train Loss: 0.3244, Val Loss: 0.3905\n",
      "Epoch [1587/10000], Train Loss: 0.3238, Val Loss: 0.4017\n",
      "Epoch [1588/10000], Train Loss: 0.3248, Val Loss: 0.3872\n",
      "Epoch [1589/10000], Train Loss: 0.3240, Val Loss: 0.3890\n",
      "Epoch [1590/10000], Train Loss: 0.3237, Val Loss: 0.3939\n",
      "Epoch [1591/10000], Train Loss: 0.3235, Val Loss: 0.4056\n",
      "Epoch [1592/10000], Train Loss: 0.3243, Val Loss: 0.4630\n",
      "Epoch [1593/10000], Train Loss: 0.3235, Val Loss: 0.3877\n",
      "Epoch [1594/10000], Train Loss: 0.3246, Val Loss: 0.3925\n",
      "Epoch [1595/10000], Train Loss: 0.3238, Val Loss: 0.3868\n",
      "Epoch [1596/10000], Train Loss: 0.3241, Val Loss: 0.4706\n",
      "Epoch [1597/10000], Train Loss: 0.3245, Val Loss: 0.3899\n",
      "Epoch [1598/10000], Train Loss: 0.3246, Val Loss: 0.3863\n",
      "Epoch [1599/10000], Train Loss: 0.3236, Val Loss: 0.3976\n",
      "Epoch [1600/10000], Train Loss: 0.3236, Val Loss: 0.3956\n",
      "Epoch [1601/10000], Train Loss: 0.3241, Val Loss: 0.4022\n",
      "Epoch [1602/10000], Train Loss: 0.3241, Val Loss: 0.3940\n",
      "Epoch [1603/10000], Train Loss: 0.3240, Val Loss: 0.3898\n",
      "Epoch [1604/10000], Train Loss: 0.3240, Val Loss: 0.3891\n",
      "Epoch [1605/10000], Train Loss: 0.3240, Val Loss: 0.4050\n",
      "Epoch [1606/10000], Train Loss: 0.3234, Val Loss: 0.3962\n",
      "Epoch [1607/10000], Train Loss: 0.3236, Val Loss: 0.3897\n",
      "Epoch [1608/10000], Train Loss: 0.3236, Val Loss: 0.4303\n",
      "Epoch [1609/10000], Train Loss: 0.3248, Val Loss: 0.4449\n",
      "Epoch [1610/10000], Train Loss: 0.3244, Val Loss: 0.3802\n",
      "Epoch [1611/10000], Train Loss: 0.3238, Val Loss: 0.3853\n",
      "Epoch [1612/10000], Train Loss: 0.3237, Val Loss: 0.3912\n",
      "Epoch [1613/10000], Train Loss: 0.3242, Val Loss: 0.4128\n",
      "Epoch [1614/10000], Train Loss: 0.3245, Val Loss: 0.3958\n",
      "Epoch [1615/10000], Train Loss: 0.3243, Val Loss: 0.4104\n",
      "Epoch [1616/10000], Train Loss: 0.3246, Val Loss: 0.4267\n",
      "Epoch [1617/10000], Train Loss: 0.3246, Val Loss: 0.4406\n",
      "Epoch [1618/10000], Train Loss: 0.3242, Val Loss: 0.3983\n",
      "Epoch [1619/10000], Train Loss: 0.3239, Val Loss: 0.4730\n",
      "Epoch [1620/10000], Train Loss: 0.3242, Val Loss: 0.3829\n",
      "Epoch [1621/10000], Train Loss: 0.3241, Val Loss: 0.3806\n",
      "Epoch [1622/10000], Train Loss: 0.3238, Val Loss: 0.4104\n",
      "Epoch [1623/10000], Train Loss: 0.3240, Val Loss: 0.4003\n",
      "Epoch [1624/10000], Train Loss: 0.3245, Val Loss: 0.3896\n",
      "Epoch [1625/10000], Train Loss: 0.3244, Val Loss: 0.4086\n",
      "Epoch [1626/10000], Train Loss: 0.3239, Val Loss: 0.3945\n",
      "Epoch [1627/10000], Train Loss: 0.3234, Val Loss: 0.3841\n",
      "Epoch [1628/10000], Train Loss: 0.3237, Val Loss: 0.4113\n",
      "Epoch [1629/10000], Train Loss: 0.3242, Val Loss: 0.4893\n",
      "Epoch [1630/10000], Train Loss: 0.3236, Val Loss: 0.3985\n",
      "Epoch [1631/10000], Train Loss: 0.3243, Val Loss: 0.5141\n",
      "Epoch [1632/10000], Train Loss: 0.3239, Val Loss: 0.4420\n",
      "Epoch [1633/10000], Train Loss: 0.3238, Val Loss: 0.3873\n",
      "Epoch [1634/10000], Train Loss: 0.3240, Val Loss: 0.4390\n",
      "Epoch [1635/10000], Train Loss: 0.3241, Val Loss: 0.4125\n",
      "Epoch [1636/10000], Train Loss: 0.3234, Val Loss: 0.4018\n",
      "Epoch [1637/10000], Train Loss: 0.3236, Val Loss: 0.3944\n",
      "Epoch [1638/10000], Train Loss: 0.3235, Val Loss: 0.3929\n",
      "Epoch [1639/10000], Train Loss: 0.3240, Val Loss: 0.3816\n",
      "Epoch [1640/10000], Train Loss: 0.3240, Val Loss: 0.3788\n",
      "Validation loss improved from 0.3796 to 0.3788. Saving model...\n",
      "Epoch [1641/10000], Train Loss: 0.3241, Val Loss: 0.3976\n",
      "Epoch [1642/10000], Train Loss: 0.3240, Val Loss: 0.3851\n",
      "Epoch [1643/10000], Train Loss: 0.3237, Val Loss: 0.4029\n",
      "Epoch [1644/10000], Train Loss: 0.3241, Val Loss: 0.4026\n",
      "Epoch [1645/10000], Train Loss: 0.3240, Val Loss: 0.4218\n",
      "Epoch [1646/10000], Train Loss: 0.3243, Val Loss: 0.4011\n",
      "Epoch [1647/10000], Train Loss: 0.3244, Val Loss: 0.4555\n",
      "Epoch [1648/10000], Train Loss: 0.3240, Val Loss: 0.3820\n",
      "Epoch [1649/10000], Train Loss: 0.3244, Val Loss: 0.4018\n",
      "Epoch [1650/10000], Train Loss: 0.3233, Val Loss: 0.3977\n",
      "Epoch [1651/10000], Train Loss: 0.3240, Val Loss: 0.4469\n",
      "Epoch [1652/10000], Train Loss: 0.3237, Val Loss: 0.3826\n",
      "Epoch [1653/10000], Train Loss: 0.3238, Val Loss: 0.4313\n",
      "Epoch [1654/10000], Train Loss: 0.3236, Val Loss: 0.4037\n",
      "Epoch [1655/10000], Train Loss: 0.3244, Val Loss: 0.5623\n",
      "Epoch [1656/10000], Train Loss: 0.3243, Val Loss: 0.3802\n",
      "Epoch [1657/10000], Train Loss: 0.3243, Val Loss: 0.4122\n",
      "Epoch [1658/10000], Train Loss: 0.3242, Val Loss: 0.3849\n",
      "Epoch [1659/10000], Train Loss: 0.3239, Val Loss: 0.4009\n",
      "Epoch [1660/10000], Train Loss: 0.3242, Val Loss: 0.3882\n",
      "Epoch [1661/10000], Train Loss: 0.3242, Val Loss: 0.4022\n",
      "Epoch [1662/10000], Train Loss: 0.3243, Val Loss: 0.4172\n",
      "Epoch [1663/10000], Train Loss: 0.3240, Val Loss: 0.3839\n",
      "Epoch [1664/10000], Train Loss: 0.3241, Val Loss: 0.4030\n",
      "Epoch [1665/10000], Train Loss: 0.3243, Val Loss: 0.4318\n",
      "Epoch [1666/10000], Train Loss: 0.3239, Val Loss: 0.3814\n",
      "Epoch [1667/10000], Train Loss: 0.3238, Val Loss: 0.4560\n",
      "Epoch [1668/10000], Train Loss: 0.3239, Val Loss: 0.4172\n",
      "Epoch [1669/10000], Train Loss: 0.3238, Val Loss: 0.3828\n",
      "Epoch [1670/10000], Train Loss: 0.3239, Val Loss: 0.4013\n",
      "Epoch [1671/10000], Train Loss: 0.3237, Val Loss: 0.4295\n",
      "Epoch [1672/10000], Train Loss: 0.3236, Val Loss: 0.3981\n",
      "Epoch [1673/10000], Train Loss: 0.3243, Val Loss: 0.3958\n",
      "Epoch [1674/10000], Train Loss: 0.3234, Val Loss: 0.3857\n",
      "Epoch [1675/10000], Train Loss: 0.3240, Val Loss: 0.3852\n",
      "Epoch [1676/10000], Train Loss: 0.3236, Val Loss: 0.3790\n",
      "Epoch [1677/10000], Train Loss: 0.3233, Val Loss: 0.4095\n",
      "Epoch [1678/10000], Train Loss: 0.3241, Val Loss: 0.4019\n",
      "Epoch [1679/10000], Train Loss: 0.3242, Val Loss: 0.3967\n",
      "Epoch [1680/10000], Train Loss: 0.3237, Val Loss: 0.3942\n",
      "Epoch [1681/10000], Train Loss: 0.3240, Val Loss: 0.4273\n",
      "Epoch [1682/10000], Train Loss: 0.3236, Val Loss: 0.3779\n",
      "Validation loss improved from 0.3788 to 0.3779. Saving model...\n",
      "Epoch [1683/10000], Train Loss: 0.3235, Val Loss: 0.4115\n",
      "Epoch [1684/10000], Train Loss: 0.3237, Val Loss: 0.3992\n",
      "Epoch [1685/10000], Train Loss: 0.3233, Val Loss: 0.4049\n",
      "Epoch [1686/10000], Train Loss: 0.3233, Val Loss: 0.4009\n",
      "Epoch [1687/10000], Train Loss: 0.3240, Val Loss: 0.3853\n",
      "Epoch [1688/10000], Train Loss: 0.3241, Val Loss: 0.3942\n",
      "Epoch [1689/10000], Train Loss: 0.3234, Val Loss: 0.4481\n",
      "Epoch [1690/10000], Train Loss: 0.3236, Val Loss: 0.4069\n",
      "Epoch [1691/10000], Train Loss: 0.3234, Val Loss: 0.3838\n",
      "Epoch [1692/10000], Train Loss: 0.3233, Val Loss: 0.3838\n",
      "Epoch [1693/10000], Train Loss: 0.3238, Val Loss: 0.3987\n",
      "Epoch [1694/10000], Train Loss: 0.3237, Val Loss: 0.3849\n",
      "Epoch [1695/10000], Train Loss: 0.3234, Val Loss: 0.4056\n",
      "Epoch [1696/10000], Train Loss: 0.3236, Val Loss: 0.4479\n",
      "Epoch [1697/10000], Train Loss: 0.3234, Val Loss: 0.3901\n",
      "Epoch [1698/10000], Train Loss: 0.3231, Val Loss: 0.3903\n",
      "Epoch [1699/10000], Train Loss: 0.3234, Val Loss: 0.4046\n",
      "Epoch [1700/10000], Train Loss: 0.3230, Val Loss: 0.3940\n",
      "Epoch [1701/10000], Train Loss: 0.3235, Val Loss: 0.3968\n",
      "Epoch [1702/10000], Train Loss: 0.3233, Val Loss: 0.3845\n",
      "Epoch [1703/10000], Train Loss: 0.3238, Val Loss: 0.4247\n",
      "Epoch [1704/10000], Train Loss: 0.3242, Val Loss: 0.3842\n",
      "Epoch [1705/10000], Train Loss: 0.3238, Val Loss: 0.3986\n",
      "Epoch [1706/10000], Train Loss: 0.3237, Val Loss: 0.3933\n",
      "Epoch [1707/10000], Train Loss: 0.3240, Val Loss: 0.4002\n",
      "Epoch [1708/10000], Train Loss: 0.3233, Val Loss: 0.3963\n",
      "Epoch [1709/10000], Train Loss: 0.3230, Val Loss: 0.4045\n",
      "Epoch [1710/10000], Train Loss: 0.3236, Val Loss: 0.3931\n",
      "Epoch [1711/10000], Train Loss: 0.3232, Val Loss: 0.3848\n",
      "Epoch [1712/10000], Train Loss: 0.3229, Val Loss: 0.3902\n",
      "Epoch [1713/10000], Train Loss: 0.3231, Val Loss: 0.4613\n",
      "Epoch [1714/10000], Train Loss: 0.3234, Val Loss: 0.3938\n",
      "Epoch [1715/10000], Train Loss: 0.3234, Val Loss: 0.3779\n",
      "Epoch [1716/10000], Train Loss: 0.3230, Val Loss: 0.4450\n",
      "Epoch [1717/10000], Train Loss: 0.3233, Val Loss: 0.3887\n",
      "Epoch [1718/10000], Train Loss: 0.3227, Val Loss: 0.4392\n",
      "Epoch [1719/10000], Train Loss: 0.3233, Val Loss: 0.5152\n",
      "Epoch [1720/10000], Train Loss: 0.3237, Val Loss: 0.3853\n",
      "Epoch [1721/10000], Train Loss: 0.3231, Val Loss: 0.4886\n",
      "Epoch [1722/10000], Train Loss: 0.3234, Val Loss: 0.4678\n",
      "Epoch [1723/10000], Train Loss: 0.3230, Val Loss: 0.4306\n",
      "Epoch [1724/10000], Train Loss: 0.3229, Val Loss: 0.4018\n",
      "Epoch [1725/10000], Train Loss: 0.3226, Val Loss: 0.3901\n",
      "Epoch [1726/10000], Train Loss: 0.3232, Val Loss: 0.3875\n",
      "Epoch [1727/10000], Train Loss: 0.3229, Val Loss: 0.3986\n",
      "Epoch [1728/10000], Train Loss: 0.3233, Val Loss: 0.3898\n",
      "Epoch [1729/10000], Train Loss: 0.3233, Val Loss: 0.4293\n",
      "Epoch [1730/10000], Train Loss: 0.3233, Val Loss: 0.3894\n",
      "Epoch [1731/10000], Train Loss: 0.3232, Val Loss: 0.4044\n",
      "Epoch [1732/10000], Train Loss: 0.3226, Val Loss: 0.4009\n",
      "Epoch [1733/10000], Train Loss: 0.3228, Val Loss: 0.3843\n",
      "Epoch [1734/10000], Train Loss: 0.3228, Val Loss: 0.4092\n",
      "Epoch [1735/10000], Train Loss: 0.3230, Val Loss: 0.4008\n",
      "Epoch [1736/10000], Train Loss: 0.3230, Val Loss: 0.3886\n",
      "Epoch [1737/10000], Train Loss: 0.3226, Val Loss: 0.3944\n",
      "Epoch [1738/10000], Train Loss: 0.3230, Val Loss: 0.3913\n",
      "Epoch [1739/10000], Train Loss: 0.3223, Val Loss: 0.3947\n",
      "Epoch [1740/10000], Train Loss: 0.3226, Val Loss: 0.3829\n",
      "Epoch [1741/10000], Train Loss: 0.3227, Val Loss: 0.3963\n",
      "Epoch [1742/10000], Train Loss: 0.3226, Val Loss: 0.3918\n",
      "Epoch [1743/10000], Train Loss: 0.3224, Val Loss: 0.4183\n",
      "Epoch [1744/10000], Train Loss: 0.3226, Val Loss: 0.4190\n",
      "Epoch [1745/10000], Train Loss: 0.3227, Val Loss: 0.3915\n",
      "Epoch [1746/10000], Train Loss: 0.3222, Val Loss: 0.3899\n",
      "Epoch [1747/10000], Train Loss: 0.3228, Val Loss: 0.4106\n",
      "Epoch [1748/10000], Train Loss: 0.3225, Val Loss: 0.4495\n",
      "Epoch [1749/10000], Train Loss: 0.3227, Val Loss: 0.3993\n",
      "Epoch [1750/10000], Train Loss: 0.3228, Val Loss: 0.4026\n",
      "Epoch [1751/10000], Train Loss: 0.3229, Val Loss: 0.3938\n",
      "Epoch [1752/10000], Train Loss: 0.3224, Val Loss: 0.4000\n",
      "Epoch [1753/10000], Train Loss: 0.3220, Val Loss: 0.3946\n",
      "Epoch [1754/10000], Train Loss: 0.3224, Val Loss: 0.4138\n",
      "Epoch [1755/10000], Train Loss: 0.3225, Val Loss: 0.3924\n",
      "Epoch [1756/10000], Train Loss: 0.3224, Val Loss: 0.4192\n",
      "Epoch [1757/10000], Train Loss: 0.3221, Val Loss: 0.3921\n",
      "Epoch [1758/10000], Train Loss: 0.3221, Val Loss: 0.3942\n",
      "Epoch [1759/10000], Train Loss: 0.3223, Val Loss: 0.4430\n",
      "Epoch [1760/10000], Train Loss: 0.3217, Val Loss: 0.3982\n",
      "Epoch [1761/10000], Train Loss: 0.3221, Val Loss: 0.3919\n",
      "Epoch [1762/10000], Train Loss: 0.3225, Val Loss: 0.3919\n",
      "Epoch [1763/10000], Train Loss: 0.3223, Val Loss: 0.3939\n",
      "Epoch [1764/10000], Train Loss: 0.3220, Val Loss: 0.3996\n",
      "Epoch [1765/10000], Train Loss: 0.3226, Val Loss: 0.4045\n",
      "Epoch [1766/10000], Train Loss: 0.3222, Val Loss: 0.3986\n",
      "Epoch [1767/10000], Train Loss: 0.3223, Val Loss: 0.3814\n",
      "Epoch [1768/10000], Train Loss: 0.3221, Val Loss: 0.3814\n",
      "Epoch [1769/10000], Train Loss: 0.3221, Val Loss: 0.3870\n",
      "Epoch [1770/10000], Train Loss: 0.3221, Val Loss: 0.4268\n",
      "Epoch [1771/10000], Train Loss: 0.3222, Val Loss: 0.3901\n",
      "Epoch [1772/10000], Train Loss: 0.3217, Val Loss: 0.4252\n",
      "Epoch [1773/10000], Train Loss: 0.3220, Val Loss: 0.3954\n",
      "Epoch [1774/10000], Train Loss: 0.3220, Val Loss: 0.3903\n",
      "Epoch [1775/10000], Train Loss: 0.3219, Val Loss: 0.4105\n",
      "Epoch [1776/10000], Train Loss: 0.3219, Val Loss: 0.3820\n",
      "Epoch [1777/10000], Train Loss: 0.3217, Val Loss: 0.3928\n",
      "Epoch [1778/10000], Train Loss: 0.3224, Val Loss: 0.4135\n",
      "Epoch [1779/10000], Train Loss: 0.3223, Val Loss: 0.3941\n",
      "Epoch [1780/10000], Train Loss: 0.3221, Val Loss: 0.4014\n",
      "Epoch [1781/10000], Train Loss: 0.3223, Val Loss: 0.4220\n",
      "Epoch [1782/10000], Train Loss: 0.3216, Val Loss: 0.4002\n",
      "Epoch [1783/10000], Train Loss: 0.3221, Val Loss: 0.3810\n",
      "Epoch [1784/10000], Train Loss: 0.3217, Val Loss: 0.4100\n",
      "Epoch [1785/10000], Train Loss: 0.3219, Val Loss: 0.3963\n",
      "Epoch [1786/10000], Train Loss: 0.3217, Val Loss: 0.4089\n",
      "Epoch [1787/10000], Train Loss: 0.3218, Val Loss: 0.4719\n",
      "Epoch [1788/10000], Train Loss: 0.3220, Val Loss: 0.4084\n",
      "Epoch [1789/10000], Train Loss: 0.3220, Val Loss: 0.3957\n",
      "Epoch [1790/10000], Train Loss: 0.3217, Val Loss: 0.3944\n",
      "Epoch [1791/10000], Train Loss: 0.3219, Val Loss: 0.3921\n",
      "Epoch [1792/10000], Train Loss: 0.3215, Val Loss: 0.4414\n",
      "Epoch [1793/10000], Train Loss: 0.3216, Val Loss: 0.4032\n",
      "Epoch [1794/10000], Train Loss: 0.3217, Val Loss: 0.3945\n",
      "Epoch [1795/10000], Train Loss: 0.3221, Val Loss: 0.3963\n",
      "Epoch [1796/10000], Train Loss: 0.3219, Val Loss: 0.3844\n",
      "Epoch [1797/10000], Train Loss: 0.3216, Val Loss: 0.4163\n",
      "Epoch [1798/10000], Train Loss: 0.3214, Val Loss: 0.4192\n",
      "Epoch [1799/10000], Train Loss: 0.3213, Val Loss: 0.4097\n",
      "Epoch [1800/10000], Train Loss: 0.3219, Val Loss: 0.4178\n",
      "Epoch [1801/10000], Train Loss: 0.3216, Val Loss: 0.3920\n",
      "Epoch [1802/10000], Train Loss: 0.3218, Val Loss: 0.4258\n",
      "Epoch [1803/10000], Train Loss: 0.3220, Val Loss: 0.3886\n",
      "Epoch [1804/10000], Train Loss: 0.3218, Val Loss: 0.3784\n",
      "Epoch [1805/10000], Train Loss: 0.3218, Val Loss: 0.4035\n",
      "Epoch [1806/10000], Train Loss: 0.3213, Val Loss: 0.4160\n",
      "Epoch [1807/10000], Train Loss: 0.3219, Val Loss: 0.4459\n",
      "Epoch [1808/10000], Train Loss: 0.3212, Val Loss: 0.4070\n",
      "Epoch [1809/10000], Train Loss: 0.3221, Val Loss: 0.3817\n",
      "Epoch [1810/10000], Train Loss: 0.3217, Val Loss: 0.3923\n",
      "Epoch [1811/10000], Train Loss: 0.3218, Val Loss: 0.3817\n",
      "Epoch [1812/10000], Train Loss: 0.3215, Val Loss: 0.4029\n",
      "Epoch [1813/10000], Train Loss: 0.3218, Val Loss: 0.4286\n",
      "Epoch [1814/10000], Train Loss: 0.3215, Val Loss: 0.4191\n",
      "Epoch [1815/10000], Train Loss: 0.3216, Val Loss: 0.3812\n",
      "Epoch [1816/10000], Train Loss: 0.3211, Val Loss: 0.4176\n",
      "Epoch [1817/10000], Train Loss: 0.3215, Val Loss: 0.3896\n",
      "Epoch [1818/10000], Train Loss: 0.3213, Val Loss: 0.3879\n",
      "Epoch [1819/10000], Train Loss: 0.3212, Val Loss: 0.3862\n",
      "Epoch [1820/10000], Train Loss: 0.3212, Val Loss: 0.3942\n",
      "Epoch [1821/10000], Train Loss: 0.3225, Val Loss: 0.5140\n",
      "Epoch [1822/10000], Train Loss: 0.3216, Val Loss: 0.3903\n",
      "Epoch [1823/10000], Train Loss: 0.3211, Val Loss: 0.3918\n",
      "Epoch [1824/10000], Train Loss: 0.3212, Val Loss: 0.3896\n",
      "Epoch [1825/10000], Train Loss: 0.3213, Val Loss: 0.4416\n",
      "Epoch [1826/10000], Train Loss: 0.3219, Val Loss: 0.3840\n",
      "Epoch [1827/10000], Train Loss: 0.3214, Val Loss: 0.3810\n",
      "Epoch [1828/10000], Train Loss: 0.3217, Val Loss: 0.4181\n",
      "Epoch [1829/10000], Train Loss: 0.3217, Val Loss: 0.4654\n",
      "Epoch [1830/10000], Train Loss: 0.3213, Val Loss: 0.3836\n",
      "Epoch [1831/10000], Train Loss: 0.3216, Val Loss: 0.4015\n",
      "Epoch [1832/10000], Train Loss: 0.3212, Val Loss: 0.3865\n",
      "Epoch [1833/10000], Train Loss: 0.3216, Val Loss: 0.3881\n",
      "Epoch [1834/10000], Train Loss: 0.3213, Val Loss: 0.3842\n",
      "Epoch [1835/10000], Train Loss: 0.3218, Val Loss: 0.4053\n",
      "Epoch [1836/10000], Train Loss: 0.3211, Val Loss: 0.4067\n",
      "Epoch [1837/10000], Train Loss: 0.3213, Val Loss: 0.3928\n",
      "Epoch [1838/10000], Train Loss: 0.3212, Val Loss: 0.3906\n",
      "Epoch [1839/10000], Train Loss: 0.3213, Val Loss: 0.3827\n",
      "Epoch [1840/10000], Train Loss: 0.3214, Val Loss: 0.3873\n",
      "Epoch [1841/10000], Train Loss: 0.3214, Val Loss: 0.3875\n",
      "Epoch [1842/10000], Train Loss: 0.3211, Val Loss: 0.3849\n",
      "Epoch [1843/10000], Train Loss: 0.3214, Val Loss: 0.4381\n",
      "Epoch [1844/10000], Train Loss: 0.3214, Val Loss: 0.4203\n",
      "Epoch [1845/10000], Train Loss: 0.3214, Val Loss: 0.3872\n",
      "Epoch [1846/10000], Train Loss: 0.3214, Val Loss: 0.3994\n",
      "Epoch [1847/10000], Train Loss: 0.3216, Val Loss: 0.3907\n",
      "Epoch [1848/10000], Train Loss: 0.3216, Val Loss: 0.3833\n",
      "Epoch [1849/10000], Train Loss: 0.3212, Val Loss: 0.3943\n",
      "Epoch [1850/10000], Train Loss: 0.3214, Val Loss: 0.4272\n",
      "Epoch [1851/10000], Train Loss: 0.3218, Val Loss: 0.3809\n",
      "Epoch [1852/10000], Train Loss: 0.3211, Val Loss: 0.3967\n",
      "Epoch [1853/10000], Train Loss: 0.3214, Val Loss: 0.3904\n",
      "Epoch [1854/10000], Train Loss: 0.3212, Val Loss: 0.3788\n",
      "Epoch [1855/10000], Train Loss: 0.3212, Val Loss: 0.3991\n",
      "Epoch [1856/10000], Train Loss: 0.3213, Val Loss: 0.3814\n",
      "Epoch [1857/10000], Train Loss: 0.3219, Val Loss: 0.3954\n",
      "Epoch [1858/10000], Train Loss: 0.3213, Val Loss: 0.4178\n",
      "Epoch [1859/10000], Train Loss: 0.3215, Val Loss: 0.4023\n",
      "Epoch [1860/10000], Train Loss: 0.3214, Val Loss: 0.3858\n",
      "Epoch [1861/10000], Train Loss: 0.3214, Val Loss: 0.3820\n",
      "Epoch [1862/10000], Train Loss: 0.3211, Val Loss: 0.3882\n",
      "Epoch [1863/10000], Train Loss: 0.3212, Val Loss: 0.4311\n",
      "Epoch [1864/10000], Train Loss: 0.3215, Val Loss: 0.4014\n",
      "Epoch [1865/10000], Train Loss: 0.3211, Val Loss: 0.3900\n",
      "Epoch [1866/10000], Train Loss: 0.3211, Val Loss: 0.4085\n",
      "Epoch [1867/10000], Train Loss: 0.3216, Val Loss: 0.3792\n",
      "Epoch [1868/10000], Train Loss: 0.3210, Val Loss: 0.3920\n",
      "Epoch [1869/10000], Train Loss: 0.3213, Val Loss: 0.3923\n",
      "Epoch [1870/10000], Train Loss: 0.3218, Val Loss: 0.3883\n",
      "Epoch [1871/10000], Train Loss: 0.3215, Val Loss: 0.3821\n",
      "Epoch [1872/10000], Train Loss: 0.3213, Val Loss: 0.3807\n",
      "Epoch [1873/10000], Train Loss: 0.3214, Val Loss: 0.3891\n",
      "Epoch [1874/10000], Train Loss: 0.3212, Val Loss: 0.3990\n",
      "Epoch [1875/10000], Train Loss: 0.3212, Val Loss: 0.3816\n",
      "Epoch [1876/10000], Train Loss: 0.3211, Val Loss: 0.4733\n",
      "Epoch [1877/10000], Train Loss: 0.3211, Val Loss: 0.3800\n",
      "Epoch [1878/10000], Train Loss: 0.3217, Val Loss: 0.4308\n",
      "Epoch [1879/10000], Train Loss: 0.3214, Val Loss: 0.4095\n",
      "Epoch [1880/10000], Train Loss: 0.3211, Val Loss: 0.3901\n",
      "Epoch [1881/10000], Train Loss: 0.3214, Val Loss: 0.4380\n",
      "Epoch [1882/10000], Train Loss: 0.3212, Val Loss: 0.3904\n",
      "Epoch [1883/10000], Train Loss: 0.3209, Val Loss: 0.3818\n",
      "Epoch [1884/10000], Train Loss: 0.3215, Val Loss: 0.4136\n",
      "Epoch [1885/10000], Train Loss: 0.3210, Val Loss: 0.4049\n",
      "Epoch [1886/10000], Train Loss: 0.3214, Val Loss: 0.3808\n",
      "Epoch [1887/10000], Train Loss: 0.3213, Val Loss: 0.3933\n",
      "Epoch [1888/10000], Train Loss: 0.3209, Val Loss: 0.4030\n",
      "Epoch [1889/10000], Train Loss: 0.3211, Val Loss: 0.3999\n",
      "Epoch [1890/10000], Train Loss: 0.3211, Val Loss: 0.3778\n",
      "Validation loss improved from 0.3779 to 0.3778. Saving model...\n",
      "Epoch [1891/10000], Train Loss: 0.3209, Val Loss: 0.4089\n",
      "Epoch [1892/10000], Train Loss: 0.3213, Val Loss: 0.4080\n",
      "Epoch [1893/10000], Train Loss: 0.3210, Val Loss: 0.3847\n",
      "Epoch [1894/10000], Train Loss: 0.3212, Val Loss: 0.4401\n",
      "Epoch [1895/10000], Train Loss: 0.3210, Val Loss: 0.3856\n",
      "Epoch [1896/10000], Train Loss: 0.3209, Val Loss: 0.3846\n",
      "Epoch [1897/10000], Train Loss: 0.3209, Val Loss: 0.3948\n",
      "Epoch [1898/10000], Train Loss: 0.3210, Val Loss: 0.3838\n",
      "Epoch [1899/10000], Train Loss: 0.3213, Val Loss: 0.4671\n",
      "Epoch [1900/10000], Train Loss: 0.3211, Val Loss: 0.4132\n",
      "Epoch [1901/10000], Train Loss: 0.3212, Val Loss: 0.3847\n",
      "Epoch [1902/10000], Train Loss: 0.3208, Val Loss: 0.4467\n",
      "Epoch [1903/10000], Train Loss: 0.3213, Val Loss: 0.4079\n",
      "Epoch [1904/10000], Train Loss: 0.3209, Val Loss: 0.3926\n",
      "Epoch [1905/10000], Train Loss: 0.3210, Val Loss: 0.5991\n",
      "Epoch [1906/10000], Train Loss: 0.3213, Val Loss: 0.4109\n",
      "Epoch [1907/10000], Train Loss: 0.3212, Val Loss: 0.3806\n",
      "Epoch [1908/10000], Train Loss: 0.3212, Val Loss: 0.4063\n",
      "Epoch [1909/10000], Train Loss: 0.3211, Val Loss: 0.3976\n",
      "Epoch [1910/10000], Train Loss: 0.3215, Val Loss: 0.4227\n",
      "Epoch [1911/10000], Train Loss: 0.3214, Val Loss: 0.4240\n",
      "Epoch [1912/10000], Train Loss: 0.3210, Val Loss: 0.4007\n",
      "Epoch [1913/10000], Train Loss: 0.3209, Val Loss: 0.4177\n",
      "Epoch [1914/10000], Train Loss: 0.3211, Val Loss: 0.4336\n",
      "Epoch [1915/10000], Train Loss: 0.3213, Val Loss: 0.3971\n",
      "Epoch [1916/10000], Train Loss: 0.3210, Val Loss: 0.3974\n",
      "Epoch [1917/10000], Train Loss: 0.3209, Val Loss: 0.3805\n",
      "Epoch [1918/10000], Train Loss: 0.3208, Val Loss: 0.3841\n",
      "Epoch [1919/10000], Train Loss: 0.3212, Val Loss: 0.3810\n",
      "Epoch [1920/10000], Train Loss: 0.3210, Val Loss: 0.3854\n",
      "Epoch [1921/10000], Train Loss: 0.3208, Val Loss: 0.3929\n",
      "Epoch [1922/10000], Train Loss: 0.3210, Val Loss: 0.4277\n",
      "Epoch [1923/10000], Train Loss: 0.3210, Val Loss: 0.3820\n",
      "Epoch [1924/10000], Train Loss: 0.3210, Val Loss: 0.4062\n",
      "Epoch [1925/10000], Train Loss: 0.3208, Val Loss: 0.3873\n",
      "Epoch [1926/10000], Train Loss: 0.3210, Val Loss: 0.3788\n",
      "Epoch [1927/10000], Train Loss: 0.3207, Val Loss: 0.3920\n",
      "Epoch [1928/10000], Train Loss: 0.3212, Val Loss: 0.3842\n",
      "Epoch [1929/10000], Train Loss: 0.3212, Val Loss: 0.4008\n",
      "Epoch [1930/10000], Train Loss: 0.3208, Val Loss: 0.4574\n",
      "Epoch [1931/10000], Train Loss: 0.3212, Val Loss: 0.4830\n",
      "Epoch [1932/10000], Train Loss: 0.3211, Val Loss: 0.4051\n",
      "Epoch [1933/10000], Train Loss: 0.3217, Val Loss: 0.3996\n",
      "Epoch [1934/10000], Train Loss: 0.3214, Val Loss: 0.3876\n",
      "Epoch [1935/10000], Train Loss: 0.3210, Val Loss: 0.3876\n",
      "Epoch [1936/10000], Train Loss: 0.3213, Val Loss: 0.4050\n",
      "Epoch [1937/10000], Train Loss: 0.3209, Val Loss: 0.4076\n",
      "Epoch [1938/10000], Train Loss: 0.3213, Val Loss: 0.3899\n",
      "Epoch [1939/10000], Train Loss: 0.3211, Val Loss: 0.4392\n",
      "Epoch [1940/10000], Train Loss: 0.3212, Val Loss: 0.4017\n",
      "Epoch [1941/10000], Train Loss: 0.3207, Val Loss: 0.4116\n",
      "Epoch [1942/10000], Train Loss: 0.3214, Val Loss: 0.3918\n",
      "Epoch [1943/10000], Train Loss: 0.3209, Val Loss: 0.3933\n",
      "Epoch [1944/10000], Train Loss: 0.3207, Val Loss: 0.4204\n",
      "Epoch [1945/10000], Train Loss: 0.3210, Val Loss: 0.4150\n",
      "Epoch [1946/10000], Train Loss: 0.3211, Val Loss: 0.4175\n",
      "Epoch [1947/10000], Train Loss: 0.3211, Val Loss: 0.3997\n",
      "Epoch [1948/10000], Train Loss: 0.3213, Val Loss: 0.3904\n",
      "Epoch [1949/10000], Train Loss: 0.3209, Val Loss: 0.4032\n",
      "Epoch [1950/10000], Train Loss: 0.3211, Val Loss: 0.3919\n",
      "Epoch [1951/10000], Train Loss: 0.3210, Val Loss: 0.3807\n",
      "Epoch [1952/10000], Train Loss: 0.3212, Val Loss: 0.3937\n",
      "Epoch [1953/10000], Train Loss: 0.3217, Val Loss: 0.3845\n",
      "Epoch [1954/10000], Train Loss: 0.3213, Val Loss: 0.3793\n",
      "Epoch [1955/10000], Train Loss: 0.3207, Val Loss: 0.3913\n",
      "Epoch [1956/10000], Train Loss: 0.3214, Val Loss: 0.3834\n",
      "Epoch [1957/10000], Train Loss: 0.3211, Val Loss: 0.3903\n",
      "Epoch [1958/10000], Train Loss: 0.3211, Val Loss: 0.3847\n",
      "Epoch [1959/10000], Train Loss: 0.3213, Val Loss: 0.3991\n",
      "Epoch [1960/10000], Train Loss: 0.3210, Val Loss: 0.4199\n",
      "Epoch [1961/10000], Train Loss: 0.3213, Val Loss: 0.3774\n",
      "Validation loss improved from 0.3778 to 0.3774. Saving model...\n",
      "Epoch [1962/10000], Train Loss: 0.3214, Val Loss: 0.4267\n",
      "Epoch [1963/10000], Train Loss: 0.3215, Val Loss: 0.3938\n",
      "Epoch [1964/10000], Train Loss: 0.3211, Val Loss: 0.3929\n",
      "Epoch [1965/10000], Train Loss: 0.3207, Val Loss: 0.3892\n",
      "Epoch [1966/10000], Train Loss: 0.3211, Val Loss: 0.3786\n",
      "Epoch [1967/10000], Train Loss: 0.3210, Val Loss: 0.3853\n",
      "Epoch [1968/10000], Train Loss: 0.3212, Val Loss: 0.3836\n",
      "Epoch [1969/10000], Train Loss: 0.3215, Val Loss: 0.4151\n",
      "Epoch [1970/10000], Train Loss: 0.3213, Val Loss: 0.3985\n",
      "Epoch [1971/10000], Train Loss: 0.3210, Val Loss: 0.4895\n",
      "Epoch [1972/10000], Train Loss: 0.3213, Val Loss: 0.3840\n",
      "Epoch [1973/10000], Train Loss: 0.3212, Val Loss: 0.4114\n",
      "Epoch [1974/10000], Train Loss: 0.3211, Val Loss: 0.4017\n",
      "Epoch [1975/10000], Train Loss: 0.3209, Val Loss: 0.3787\n",
      "Epoch [1976/10000], Train Loss: 0.3207, Val Loss: 0.3870\n",
      "Epoch [1977/10000], Train Loss: 0.3206, Val Loss: 0.4444\n",
      "Epoch [1978/10000], Train Loss: 0.3217, Val Loss: 0.4058\n",
      "Epoch [1979/10000], Train Loss: 0.3211, Val Loss: 0.3844\n",
      "Epoch [1980/10000], Train Loss: 0.3212, Val Loss: 0.3872\n",
      "Epoch [1981/10000], Train Loss: 0.3212, Val Loss: 0.4069\n",
      "Epoch [1982/10000], Train Loss: 0.3214, Val Loss: 0.4063\n",
      "Epoch [1983/10000], Train Loss: 0.3213, Val Loss: 0.3776\n",
      "Epoch [1984/10000], Train Loss: 0.3210, Val Loss: 0.4752\n",
      "Epoch [1985/10000], Train Loss: 0.3216, Val Loss: 0.3874\n",
      "Epoch [1986/10000], Train Loss: 0.3219, Val Loss: 0.3839\n",
      "Epoch [1987/10000], Train Loss: 0.3211, Val Loss: 0.3852\n",
      "Epoch [1988/10000], Train Loss: 0.3207, Val Loss: 0.3918\n",
      "Epoch [1989/10000], Train Loss: 0.3212, Val Loss: 0.3863\n",
      "Epoch [1990/10000], Train Loss: 0.3209, Val Loss: 0.3790\n",
      "Epoch [1991/10000], Train Loss: 0.3210, Val Loss: 0.3797\n",
      "Epoch [1992/10000], Train Loss: 0.3212, Val Loss: 0.3883\n",
      "Epoch [1993/10000], Train Loss: 0.3214, Val Loss: 0.4035\n",
      "Epoch [1994/10000], Train Loss: 0.3207, Val Loss: 0.3985\n",
      "Epoch [1995/10000], Train Loss: 0.3211, Val Loss: 0.3951\n",
      "Epoch [1996/10000], Train Loss: 0.3212, Val Loss: 0.3974\n",
      "Epoch [1997/10000], Train Loss: 0.3208, Val Loss: 0.4140\n",
      "Epoch [1998/10000], Train Loss: 0.3212, Val Loss: 0.4259\n",
      "Epoch [1999/10000], Train Loss: 0.3206, Val Loss: 0.3813\n",
      "Epoch [2000/10000], Train Loss: 0.3212, Val Loss: 0.3961\n",
      "Epoch [2001/10000], Train Loss: 0.3208, Val Loss: 0.3825\n",
      "Epoch [2002/10000], Train Loss: 0.3210, Val Loss: 0.3872\n",
      "Epoch [2003/10000], Train Loss: 0.3210, Val Loss: 0.4007\n",
      "Epoch [2004/10000], Train Loss: 0.3210, Val Loss: 0.3821\n",
      "Epoch [2005/10000], Train Loss: 0.3209, Val Loss: 0.3853\n",
      "Epoch [2006/10000], Train Loss: 0.3210, Val Loss: 0.4149\n",
      "Epoch [2007/10000], Train Loss: 0.3210, Val Loss: 0.3943\n",
      "Epoch [2008/10000], Train Loss: 0.3212, Val Loss: 0.3975\n",
      "Epoch [2009/10000], Train Loss: 0.3208, Val Loss: 0.3838\n",
      "Epoch [2010/10000], Train Loss: 0.3213, Val Loss: 0.3938\n",
      "Epoch [2011/10000], Train Loss: 0.3214, Val Loss: 0.3923\n",
      "Epoch [2012/10000], Train Loss: 0.3210, Val Loss: 0.3820\n",
      "Epoch [2013/10000], Train Loss: 0.3210, Val Loss: 0.3791\n",
      "Epoch [2014/10000], Train Loss: 0.3214, Val Loss: 0.4194\n",
      "Epoch [2015/10000], Train Loss: 0.3210, Val Loss: 0.3855\n",
      "Epoch [2016/10000], Train Loss: 0.3213, Val Loss: 0.5126\n",
      "Epoch [2017/10000], Train Loss: 0.3209, Val Loss: 0.3813\n",
      "Epoch [2018/10000], Train Loss: 0.3208, Val Loss: 0.4946\n",
      "Epoch [2019/10000], Train Loss: 0.3210, Val Loss: 0.3870\n",
      "Epoch [2020/10000], Train Loss: 0.3212, Val Loss: 0.3925\n",
      "Epoch [2021/10000], Train Loss: 0.3211, Val Loss: 0.4022\n",
      "Epoch [2022/10000], Train Loss: 0.3208, Val Loss: 0.4048\n",
      "Epoch [2023/10000], Train Loss: 0.3211, Val Loss: 0.3929\n",
      "Epoch [2024/10000], Train Loss: 0.3212, Val Loss: 0.4856\n",
      "Epoch [2025/10000], Train Loss: 0.3210, Val Loss: 0.4650\n",
      "Epoch [2026/10000], Train Loss: 0.3217, Val Loss: 0.4400\n",
      "Epoch [2027/10000], Train Loss: 0.3212, Val Loss: 0.3833\n",
      "Epoch [2028/10000], Train Loss: 0.3205, Val Loss: 0.4201\n",
      "Epoch [2029/10000], Train Loss: 0.3211, Val Loss: 0.4144\n",
      "Epoch [2030/10000], Train Loss: 0.3207, Val Loss: 0.3839\n",
      "Epoch [2031/10000], Train Loss: 0.3211, Val Loss: 0.3797\n",
      "Epoch [2032/10000], Train Loss: 0.3209, Val Loss: 0.4037\n",
      "Epoch [2033/10000], Train Loss: 0.3213, Val Loss: 0.3908\n",
      "Epoch [2034/10000], Train Loss: 0.3213, Val Loss: 0.4081\n",
      "Epoch [2035/10000], Train Loss: 0.3209, Val Loss: 0.3844\n",
      "Epoch [2036/10000], Train Loss: 0.3212, Val Loss: 0.3814\n",
      "Epoch [2037/10000], Train Loss: 0.3208, Val Loss: 0.4285\n",
      "Epoch [2038/10000], Train Loss: 0.3206, Val Loss: 0.3876\n",
      "Epoch [2039/10000], Train Loss: 0.3212, Val Loss: 0.4501\n",
      "Epoch [2040/10000], Train Loss: 0.3214, Val Loss: 0.3801\n",
      "Epoch [2041/10000], Train Loss: 0.3209, Val Loss: 0.3795\n",
      "Epoch [2042/10000], Train Loss: 0.3214, Val Loss: 0.3918\n",
      "Epoch [2043/10000], Train Loss: 0.3207, Val Loss: 0.3860\n",
      "Epoch [2044/10000], Train Loss: 0.3211, Val Loss: 0.3791\n",
      "Epoch [2045/10000], Train Loss: 0.3210, Val Loss: 0.4193\n",
      "Epoch [2046/10000], Train Loss: 0.3214, Val Loss: 0.3898\n",
      "Epoch [2047/10000], Train Loss: 0.3208, Val Loss: 0.3946\n",
      "Epoch [2048/10000], Train Loss: 0.3209, Val Loss: 0.4062\n",
      "Epoch [2049/10000], Train Loss: 0.3209, Val Loss: 0.3859\n",
      "Epoch [2050/10000], Train Loss: 0.3212, Val Loss: 0.4474\n",
      "Epoch [2051/10000], Train Loss: 0.3212, Val Loss: 0.3783\n",
      "Epoch [2052/10000], Train Loss: 0.3208, Val Loss: 0.4022\n",
      "Epoch [2053/10000], Train Loss: 0.3210, Val Loss: 0.4319\n",
      "Epoch [2054/10000], Train Loss: 0.3210, Val Loss: 0.3847\n",
      "Epoch [2055/10000], Train Loss: 0.3208, Val Loss: 0.3905\n",
      "Epoch [2056/10000], Train Loss: 0.3211, Val Loss: 0.4284\n",
      "Epoch [2057/10000], Train Loss: 0.3209, Val Loss: 0.3845\n",
      "Epoch [2058/10000], Train Loss: 0.3211, Val Loss: 0.3909\n",
      "Epoch [2059/10000], Train Loss: 0.3217, Val Loss: 0.4270\n",
      "Epoch [2060/10000], Train Loss: 0.3201, Val Loss: 0.3934\n",
      "Epoch [2061/10000], Train Loss: 0.3206, Val Loss: 0.3974\n",
      "Epoch [2062/10000], Train Loss: 0.3210, Val Loss: 0.4053\n",
      "Epoch [2063/10000], Train Loss: 0.3209, Val Loss: 0.3904\n",
      "Epoch [2064/10000], Train Loss: 0.3211, Val Loss: 0.3855\n",
      "Epoch [2065/10000], Train Loss: 0.3210, Val Loss: 0.3960\n",
      "Epoch [2066/10000], Train Loss: 0.3214, Val Loss: 0.3901\n",
      "Epoch [2067/10000], Train Loss: 0.3210, Val Loss: 0.3845\n",
      "Epoch [2068/10000], Train Loss: 0.3210, Val Loss: 0.3906\n",
      "Epoch [2069/10000], Train Loss: 0.3211, Val Loss: 0.4104\n",
      "Epoch [2070/10000], Train Loss: 0.3203, Val Loss: 0.4179\n",
      "Epoch [2071/10000], Train Loss: 0.3207, Val Loss: 0.3859\n",
      "Epoch [2072/10000], Train Loss: 0.3209, Val Loss: 0.4867\n",
      "Epoch [2073/10000], Train Loss: 0.3214, Val Loss: 0.3772\n",
      "Validation loss improved from 0.3774 to 0.3772. Saving model...\n",
      "Epoch [2074/10000], Train Loss: 0.3209, Val Loss: 0.3829\n",
      "Epoch [2075/10000], Train Loss: 0.3210, Val Loss: 0.3797\n",
      "Epoch [2076/10000], Train Loss: 0.3210, Val Loss: 0.3957\n",
      "Epoch [2077/10000], Train Loss: 0.3205, Val Loss: 0.3809\n",
      "Epoch [2078/10000], Train Loss: 0.3209, Val Loss: 0.3782\n",
      "Epoch [2079/10000], Train Loss: 0.3207, Val Loss: 0.3892\n",
      "Epoch [2080/10000], Train Loss: 0.3209, Val Loss: 0.3951\n",
      "Epoch [2081/10000], Train Loss: 0.3213, Val Loss: 0.3875\n",
      "Epoch [2082/10000], Train Loss: 0.3210, Val Loss: 0.3836\n",
      "Epoch [2083/10000], Train Loss: 0.3208, Val Loss: 0.4095\n",
      "Epoch [2084/10000], Train Loss: 0.3212, Val Loss: 0.3930\n",
      "Epoch [2085/10000], Train Loss: 0.3215, Val Loss: 0.3927\n",
      "Epoch [2086/10000], Train Loss: 0.3209, Val Loss: 0.4244\n",
      "Epoch [2087/10000], Train Loss: 0.3210, Val Loss: 0.3766\n",
      "Validation loss improved from 0.3772 to 0.3766. Saving model...\n",
      "Epoch [2088/10000], Train Loss: 0.3208, Val Loss: 0.3803\n",
      "Epoch [2089/10000], Train Loss: 0.3211, Val Loss: 0.4179\n",
      "Epoch [2090/10000], Train Loss: 0.3208, Val Loss: 0.3888\n",
      "Epoch [2091/10000], Train Loss: 0.3211, Val Loss: 0.3808\n",
      "Epoch [2092/10000], Train Loss: 0.3206, Val Loss: 0.3803\n",
      "Epoch [2093/10000], Train Loss: 0.3206, Val Loss: 0.3900\n",
      "Epoch [2094/10000], Train Loss: 0.3213, Val Loss: 0.3839\n",
      "Epoch [2095/10000], Train Loss: 0.3213, Val Loss: 0.3825\n",
      "Epoch [2096/10000], Train Loss: 0.3210, Val Loss: 0.3898\n",
      "Epoch [2097/10000], Train Loss: 0.3213, Val Loss: 0.3878\n",
      "Epoch [2098/10000], Train Loss: 0.3210, Val Loss: 0.3844\n",
      "Epoch [2099/10000], Train Loss: 0.3208, Val Loss: 0.3883\n",
      "Epoch [2100/10000], Train Loss: 0.3210, Val Loss: 0.3767\n",
      "Epoch [2101/10000], Train Loss: 0.3214, Val Loss: 0.3906\n",
      "Epoch [2102/10000], Train Loss: 0.3215, Val Loss: 0.3885\n",
      "Epoch [2103/10000], Train Loss: 0.3208, Val Loss: 0.4356\n",
      "Epoch [2104/10000], Train Loss: 0.3205, Val Loss: 0.3908\n",
      "Epoch [2105/10000], Train Loss: 0.3210, Val Loss: 0.4134\n",
      "Epoch [2106/10000], Train Loss: 0.3210, Val Loss: 0.4213\n",
      "Epoch [2107/10000], Train Loss: 0.3209, Val Loss: 0.4049\n",
      "Epoch [2108/10000], Train Loss: 0.3213, Val Loss: 0.3787\n",
      "Epoch [2109/10000], Train Loss: 0.3209, Val Loss: 0.4138\n",
      "Epoch [2110/10000], Train Loss: 0.3211, Val Loss: 0.3791\n",
      "Epoch [2111/10000], Train Loss: 0.3215, Val Loss: 0.3767\n",
      "Epoch [2112/10000], Train Loss: 0.3213, Val Loss: 0.4036\n",
      "Epoch [2113/10000], Train Loss: 0.3208, Val Loss: 0.3948\n",
      "Epoch [2114/10000], Train Loss: 0.3211, Val Loss: 0.4010\n",
      "Epoch [2115/10000], Train Loss: 0.3211, Val Loss: 0.4039\n",
      "Epoch [2116/10000], Train Loss: 0.3209, Val Loss: 0.3790\n",
      "Epoch [2117/10000], Train Loss: 0.3209, Val Loss: 0.3802\n",
      "Epoch [2118/10000], Train Loss: 0.3209, Val Loss: 0.3813\n",
      "Epoch [2119/10000], Train Loss: 0.3210, Val Loss: 0.4154\n",
      "Epoch [2120/10000], Train Loss: 0.3212, Val Loss: 0.4242\n",
      "Epoch [2121/10000], Train Loss: 0.3210, Val Loss: 0.3920\n",
      "Epoch [2122/10000], Train Loss: 0.3205, Val Loss: 0.3906\n",
      "Epoch [2123/10000], Train Loss: 0.3206, Val Loss: 0.3861\n",
      "Epoch [2124/10000], Train Loss: 0.3211, Val Loss: 0.3954\n",
      "Epoch [2125/10000], Train Loss: 0.3208, Val Loss: 0.3987\n",
      "Epoch [2126/10000], Train Loss: 0.3210, Val Loss: 0.3867\n",
      "Epoch [2127/10000], Train Loss: 0.3211, Val Loss: 0.3880\n",
      "Epoch [2128/10000], Train Loss: 0.3207, Val Loss: 0.3800\n",
      "Epoch [2129/10000], Train Loss: 0.3209, Val Loss: 0.4732\n",
      "Epoch [2130/10000], Train Loss: 0.3211, Val Loss: 0.3812\n",
      "Epoch [2131/10000], Train Loss: 0.3207, Val Loss: 0.4317\n",
      "Epoch [2132/10000], Train Loss: 0.3209, Val Loss: 0.4666\n",
      "Epoch [2133/10000], Train Loss: 0.3211, Val Loss: 0.3819\n",
      "Epoch [2134/10000], Train Loss: 0.3210, Val Loss: 0.4132\n",
      "Epoch [2135/10000], Train Loss: 0.3209, Val Loss: 0.3814\n",
      "Epoch [2136/10000], Train Loss: 0.3207, Val Loss: 0.3843\n",
      "Epoch [2137/10000], Train Loss: 0.3204, Val Loss: 0.4094\n",
      "Epoch [2138/10000], Train Loss: 0.3212, Val Loss: 0.3866\n",
      "Epoch [2139/10000], Train Loss: 0.3208, Val Loss: 0.4087\n",
      "Epoch [2140/10000], Train Loss: 0.3208, Val Loss: 0.4361\n",
      "Epoch [2141/10000], Train Loss: 0.3209, Val Loss: 0.3838\n",
      "Epoch [2142/10000], Train Loss: 0.3208, Val Loss: 0.4197\n",
      "Epoch [2143/10000], Train Loss: 0.3211, Val Loss: 0.3795\n",
      "Epoch [2144/10000], Train Loss: 0.3208, Val Loss: 0.3830\n",
      "Epoch [2145/10000], Train Loss: 0.3211, Val Loss: 0.4167\n",
      "Epoch [2146/10000], Train Loss: 0.3211, Val Loss: 0.3800\n",
      "Epoch [2147/10000], Train Loss: 0.3210, Val Loss: 0.3929\n",
      "Epoch [2148/10000], Train Loss: 0.3206, Val Loss: 0.3879\n",
      "Epoch [2149/10000], Train Loss: 0.3211, Val Loss: 0.3779\n",
      "Epoch [2150/10000], Train Loss: 0.3210, Val Loss: 0.4036\n",
      "Epoch [2151/10000], Train Loss: 0.3209, Val Loss: 0.4622\n",
      "Epoch [2152/10000], Train Loss: 0.3213, Val Loss: 0.4124\n",
      "Epoch [2153/10000], Train Loss: 0.3208, Val Loss: 0.3929\n",
      "Epoch [2154/10000], Train Loss: 0.3207, Val Loss: 0.4221\n",
      "Epoch [2155/10000], Train Loss: 0.3210, Val Loss: 0.3836\n",
      "Epoch [2156/10000], Train Loss: 0.3211, Val Loss: 0.4049\n",
      "Epoch [2157/10000], Train Loss: 0.3206, Val Loss: 0.3906\n",
      "Epoch [2158/10000], Train Loss: 0.3208, Val Loss: 0.3800\n",
      "Epoch [2159/10000], Train Loss: 0.3206, Val Loss: 0.3876\n",
      "Epoch [2160/10000], Train Loss: 0.3213, Val Loss: 0.3883\n",
      "Epoch [2161/10000], Train Loss: 0.3212, Val Loss: 0.3839\n",
      "Epoch [2162/10000], Train Loss: 0.3206, Val Loss: 0.3882\n",
      "Epoch [2163/10000], Train Loss: 0.3210, Val Loss: 0.3891\n",
      "Epoch [2164/10000], Train Loss: 0.3209, Val Loss: 0.3865\n",
      "Epoch [2165/10000], Train Loss: 0.3211, Val Loss: 0.3964\n",
      "Epoch [2166/10000], Train Loss: 0.3212, Val Loss: 0.4271\n",
      "Epoch [2167/10000], Train Loss: 0.3207, Val Loss: 0.3951\n",
      "Epoch [2168/10000], Train Loss: 0.3204, Val Loss: 0.3858\n",
      "Epoch [2169/10000], Train Loss: 0.3207, Val Loss: 0.4286\n",
      "Epoch [2170/10000], Train Loss: 0.3205, Val Loss: 0.3977\n",
      "Epoch [2171/10000], Train Loss: 0.3210, Val Loss: 0.3885\n",
      "Epoch [2172/10000], Train Loss: 0.3207, Val Loss: 0.3977\n",
      "Epoch [2173/10000], Train Loss: 0.3208, Val Loss: 0.3884\n",
      "Epoch [2174/10000], Train Loss: 0.3209, Val Loss: 0.3985\n",
      "Epoch [2175/10000], Train Loss: 0.3208, Val Loss: 0.3826\n",
      "Epoch [2176/10000], Train Loss: 0.3210, Val Loss: 0.3854\n",
      "Epoch [2177/10000], Train Loss: 0.3208, Val Loss: 0.3975\n",
      "Epoch [2178/10000], Train Loss: 0.3213, Val Loss: 0.3901\n",
      "Epoch [2179/10000], Train Loss: 0.3209, Val Loss: 0.3940\n",
      "Epoch [2180/10000], Train Loss: 0.3214, Val Loss: 0.4235\n",
      "Epoch [2181/10000], Train Loss: 0.3207, Val Loss: 0.3892\n",
      "Epoch [2182/10000], Train Loss: 0.3210, Val Loss: 0.3917\n",
      "Epoch [2183/10000], Train Loss: 0.3208, Val Loss: 0.3778\n",
      "Epoch [2184/10000], Train Loss: 0.3209, Val Loss: 0.3879\n",
      "Epoch [2185/10000], Train Loss: 0.3212, Val Loss: 0.3822\n",
      "Epoch [2186/10000], Train Loss: 0.3210, Val Loss: 0.3821\n",
      "Epoch [2187/10000], Train Loss: 0.3206, Val Loss: 0.3963\n",
      "Epoch [2188/10000], Train Loss: 0.3209, Val Loss: 0.4298\n",
      "Epoch [2189/10000], Train Loss: 0.3207, Val Loss: 0.3841\n",
      "Epoch [2190/10000], Train Loss: 0.3207, Val Loss: 0.3752\n",
      "Validation loss improved from 0.3766 to 0.3752. Saving model...\n",
      "Epoch [2191/10000], Train Loss: 0.3210, Val Loss: 0.4167\n",
      "Epoch [2192/10000], Train Loss: 0.3208, Val Loss: 0.4269\n",
      "Epoch [2193/10000], Train Loss: 0.3207, Val Loss: 0.3836\n",
      "Epoch [2194/10000], Train Loss: 0.3211, Val Loss: 0.3853\n",
      "Epoch [2195/10000], Train Loss: 0.3206, Val Loss: 0.3912\n",
      "Epoch [2196/10000], Train Loss: 0.3210, Val Loss: 0.5028\n",
      "Epoch [2197/10000], Train Loss: 0.3207, Val Loss: 0.3872\n",
      "Epoch [2198/10000], Train Loss: 0.3211, Val Loss: 0.3973\n",
      "Epoch [2199/10000], Train Loss: 0.3209, Val Loss: 0.3931\n",
      "Epoch [2200/10000], Train Loss: 0.3208, Val Loss: 0.4115\n",
      "Epoch [2201/10000], Train Loss: 0.3206, Val Loss: 0.3830\n",
      "Epoch [2202/10000], Train Loss: 0.3211, Val Loss: 0.3809\n",
      "Epoch [2203/10000], Train Loss: 0.3207, Val Loss: 0.3872\n",
      "Epoch [2204/10000], Train Loss: 0.3208, Val Loss: 0.3891\n",
      "Epoch [2205/10000], Train Loss: 0.3206, Val Loss: 0.3783\n",
      "Epoch [2206/10000], Train Loss: 0.3205, Val Loss: 0.3961\n",
      "Epoch [2207/10000], Train Loss: 0.3207, Val Loss: 0.3865\n",
      "Epoch [2208/10000], Train Loss: 0.3207, Val Loss: 0.3893\n",
      "Epoch [2209/10000], Train Loss: 0.3209, Val Loss: 0.3786\n",
      "Epoch [2210/10000], Train Loss: 0.3208, Val Loss: 0.4003\n",
      "Epoch [2211/10000], Train Loss: 0.3209, Val Loss: 0.3787\n",
      "Epoch [2212/10000], Train Loss: 0.3205, Val Loss: 0.3898\n",
      "Epoch [2213/10000], Train Loss: 0.3209, Val Loss: 0.3823\n",
      "Epoch [2214/10000], Train Loss: 0.3211, Val Loss: 0.3877\n",
      "Epoch [2215/10000], Train Loss: 0.3205, Val Loss: 0.3802\n",
      "Epoch [2216/10000], Train Loss: 0.3206, Val Loss: 0.4221\n",
      "Epoch [2217/10000], Train Loss: 0.3210, Val Loss: 0.3841\n",
      "Epoch [2218/10000], Train Loss: 0.3208, Val Loss: 0.4007\n",
      "Epoch [2219/10000], Train Loss: 0.3211, Val Loss: 0.3904\n",
      "Epoch [2220/10000], Train Loss: 0.3208, Val Loss: 0.3812\n",
      "Epoch [2221/10000], Train Loss: 0.3207, Val Loss: 0.3804\n",
      "Epoch [2222/10000], Train Loss: 0.3208, Val Loss: 0.3842\n",
      "Epoch [2223/10000], Train Loss: 0.3210, Val Loss: 0.3902\n",
      "Epoch [2224/10000], Train Loss: 0.3209, Val Loss: 0.3898\n",
      "Epoch [2225/10000], Train Loss: 0.3213, Val Loss: 0.3984\n",
      "Epoch [2226/10000], Train Loss: 0.3208, Val Loss: 0.3845\n",
      "Epoch [2227/10000], Train Loss: 0.6028, Val Loss: 3.5726\n",
      "Epoch [2228/10000], Train Loss: 0.6595, Val Loss: 3.1485\n",
      "Epoch [2229/10000], Train Loss: 0.5997, Val Loss: 2.6309\n",
      "Epoch [2230/10000], Train Loss: 0.5793, Val Loss: 2.6310\n",
      "Epoch [2231/10000], Train Loss: 0.5487, Val Loss: 2.5088\n",
      "Epoch [2232/10000], Train Loss: 0.4925, Val Loss: 2.0471\n",
      "Epoch [2233/10000], Train Loss: 0.4058, Val Loss: 0.7475\n",
      "Epoch [2234/10000], Train Loss: 0.3510, Val Loss: 0.5026\n",
      "Epoch [2235/10000], Train Loss: 0.3306, Val Loss: 0.4576\n",
      "Epoch [2236/10000], Train Loss: 0.3275, Val Loss: 0.4365\n",
      "Epoch [2237/10000], Train Loss: 0.3247, Val Loss: 0.4071\n",
      "Epoch [2238/10000], Train Loss: 0.3217, Val Loss: 0.3799\n",
      "Epoch [2239/10000], Train Loss: 0.3209, Val Loss: 0.4137\n",
      "Epoch [2240/10000], Train Loss: 0.3206, Val Loss: 0.3851\n",
      "Epoch [2241/10000], Train Loss: 0.3209, Val Loss: 0.4024\n",
      "Epoch [2242/10000], Train Loss: 0.3214, Val Loss: 0.4061\n",
      "Epoch [2243/10000], Train Loss: 0.3213, Val Loss: 0.3921\n",
      "Epoch [2244/10000], Train Loss: 0.3208, Val Loss: 0.3988\n",
      "Epoch [2245/10000], Train Loss: 0.3209, Val Loss: 0.3949\n",
      "Epoch [2246/10000], Train Loss: 0.3211, Val Loss: 0.3849\n",
      "Epoch [2247/10000], Train Loss: 0.3211, Val Loss: 0.3860\n",
      "Epoch [2248/10000], Train Loss: 0.3212, Val Loss: 0.3820\n",
      "Epoch [2249/10000], Train Loss: 0.3213, Val Loss: 0.3807\n",
      "Epoch [2250/10000], Train Loss: 0.3212, Val Loss: 0.3941\n",
      "Epoch [2251/10000], Train Loss: 0.3209, Val Loss: 0.3788\n",
      "Epoch [2252/10000], Train Loss: 0.3212, Val Loss: 0.3761\n",
      "Epoch [2253/10000], Train Loss: 0.3210, Val Loss: 0.3817\n",
      "Epoch [2254/10000], Train Loss: 0.3205, Val Loss: 0.3794\n",
      "Epoch [2255/10000], Train Loss: 0.3205, Val Loss: 0.3791\n",
      "Epoch [2256/10000], Train Loss: 0.3204, Val Loss: 0.4025\n",
      "Epoch [2257/10000], Train Loss: 0.3212, Val Loss: 0.3941\n",
      "Epoch [2258/10000], Train Loss: 0.3209, Val Loss: 0.4377\n",
      "Epoch [2259/10000], Train Loss: 0.3211, Val Loss: 0.3815\n",
      "Epoch [2260/10000], Train Loss: 0.3211, Val Loss: 0.3919\n",
      "Epoch [2261/10000], Train Loss: 0.3205, Val Loss: 0.4006\n",
      "Epoch [2262/10000], Train Loss: 0.3208, Val Loss: 0.3909\n",
      "Epoch [2263/10000], Train Loss: 0.3204, Val Loss: 0.3836\n",
      "Epoch [2264/10000], Train Loss: 0.3211, Val Loss: 0.3829\n",
      "Epoch [2265/10000], Train Loss: 0.3211, Val Loss: 0.4114\n",
      "Epoch [2266/10000], Train Loss: 0.3209, Val Loss: 0.3844\n",
      "Epoch [2267/10000], Train Loss: 0.3210, Val Loss: 0.3804\n",
      "Epoch [2268/10000], Train Loss: 0.3210, Val Loss: 0.3914\n",
      "Epoch [2269/10000], Train Loss: 0.3209, Val Loss: 0.3882\n",
      "Epoch [2270/10000], Train Loss: 0.3208, Val Loss: 0.3879\n",
      "Epoch [2271/10000], Train Loss: 0.3207, Val Loss: 0.3889\n",
      "Epoch [2272/10000], Train Loss: 0.3206, Val Loss: 0.3817\n",
      "Epoch [2273/10000], Train Loss: 0.3212, Val Loss: 0.3851\n",
      "Epoch [2274/10000], Train Loss: 0.3206, Val Loss: 0.4186\n",
      "Epoch [2275/10000], Train Loss: 0.3209, Val Loss: 0.4059\n",
      "Epoch [2276/10000], Train Loss: 0.3211, Val Loss: 0.3944\n",
      "Epoch [2277/10000], Train Loss: 0.3208, Val Loss: 0.3864\n",
      "Epoch [2278/10000], Train Loss: 0.3206, Val Loss: 0.3783\n",
      "Epoch [2279/10000], Train Loss: 0.3210, Val Loss: 0.3924\n",
      "Epoch [2280/10000], Train Loss: 0.3207, Val Loss: 0.3798\n",
      "Epoch [2281/10000], Train Loss: 0.3210, Val Loss: 0.3895\n",
      "Epoch [2282/10000], Train Loss: 0.3211, Val Loss: 0.3950\n",
      "Epoch [2283/10000], Train Loss: 0.3211, Val Loss: 0.3908\n",
      "Epoch [2284/10000], Train Loss: 0.3208, Val Loss: 0.5022\n",
      "Epoch [2285/10000], Train Loss: 0.3209, Val Loss: 0.3858\n",
      "Epoch [2286/10000], Train Loss: 0.3206, Val Loss: 0.3805\n",
      "Epoch [2287/10000], Train Loss: 0.3207, Val Loss: 0.4554\n",
      "Epoch [2288/10000], Train Loss: 0.3211, Val Loss: 0.3797\n",
      "Epoch [2289/10000], Train Loss: 0.3206, Val Loss: 0.4159\n",
      "Epoch [2290/10000], Train Loss: 0.3209, Val Loss: 0.4135\n",
      "Epoch [2291/10000], Train Loss: 0.3211, Val Loss: 0.3912\n",
      "Epoch [2292/10000], Train Loss: 0.3208, Val Loss: 0.3835\n",
      "Epoch [2293/10000], Train Loss: 0.3208, Val Loss: 0.3787\n",
      "Epoch [2294/10000], Train Loss: 0.3208, Val Loss: 0.4017\n",
      "Epoch [2295/10000], Train Loss: 0.3210, Val Loss: 0.4466\n",
      "Epoch [2296/10000], Train Loss: 0.3209, Val Loss: 0.4304\n",
      "Epoch [2297/10000], Train Loss: 0.3209, Val Loss: 0.3797\n",
      "Epoch [2298/10000], Train Loss: 0.3212, Val Loss: 0.3859\n",
      "Epoch [2299/10000], Train Loss: 0.3209, Val Loss: 0.4220\n",
      "Epoch [2300/10000], Train Loss: 0.3211, Val Loss: 0.4435\n",
      "Epoch [2301/10000], Train Loss: 0.3209, Val Loss: 0.3757\n",
      "Epoch [2302/10000], Train Loss: 0.3207, Val Loss: 0.3858\n",
      "Epoch [2303/10000], Train Loss: 0.3207, Val Loss: 0.3956\n",
      "Epoch [2304/10000], Train Loss: 0.3210, Val Loss: 0.3867\n",
      "Epoch [2305/10000], Train Loss: 0.3213, Val Loss: 0.3960\n",
      "Epoch [2306/10000], Train Loss: 0.3212, Val Loss: 0.4113\n",
      "Epoch [2307/10000], Train Loss: 0.3207, Val Loss: 0.3823\n",
      "Epoch [2308/10000], Train Loss: 0.3205, Val Loss: 0.4290\n",
      "Epoch [2309/10000], Train Loss: 0.3211, Val Loss: 0.4166\n",
      "Epoch [2310/10000], Train Loss: 0.3208, Val Loss: 0.3768\n",
      "Epoch [2311/10000], Train Loss: 0.3204, Val Loss: 0.4376\n",
      "Epoch [2312/10000], Train Loss: 0.3211, Val Loss: 0.4327\n",
      "Epoch [2313/10000], Train Loss: 0.3209, Val Loss: 0.3760\n",
      "Epoch [2314/10000], Train Loss: 0.3210, Val Loss: 0.4315\n",
      "Epoch [2315/10000], Train Loss: 0.3209, Val Loss: 0.3865\n",
      "Epoch [2316/10000], Train Loss: 0.3207, Val Loss: 0.3927\n",
      "Epoch [2317/10000], Train Loss: 0.3207, Val Loss: 0.3760\n",
      "Epoch [2318/10000], Train Loss: 0.3212, Val Loss: 0.3848\n",
      "Epoch [2319/10000], Train Loss: 0.3212, Val Loss: 0.3874\n",
      "Epoch [2320/10000], Train Loss: 0.3210, Val Loss: 0.3949\n",
      "Epoch [2321/10000], Train Loss: 0.3212, Val Loss: 0.4584\n",
      "Epoch [2322/10000], Train Loss: 0.3208, Val Loss: 0.3862\n",
      "Epoch [2323/10000], Train Loss: 0.3209, Val Loss: 0.4006\n",
      "Epoch [2324/10000], Train Loss: 0.3210, Val Loss: 0.3791\n",
      "Epoch [2325/10000], Train Loss: 0.3209, Val Loss: 0.4191\n",
      "Epoch [2326/10000], Train Loss: 0.3212, Val Loss: 0.3893\n",
      "Epoch [2327/10000], Train Loss: 0.3204, Val Loss: 0.4347\n",
      "Epoch [2328/10000], Train Loss: 0.3206, Val Loss: 0.3898\n",
      "Epoch [2329/10000], Train Loss: 0.3206, Val Loss: 0.3861\n",
      "Epoch [2330/10000], Train Loss: 0.3203, Val Loss: 0.3802\n",
      "Epoch [2331/10000], Train Loss: 0.3205, Val Loss: 0.4011\n",
      "Epoch [2332/10000], Train Loss: 0.3207, Val Loss: 0.3818\n",
      "Epoch [2333/10000], Train Loss: 0.3207, Val Loss: 0.3952\n",
      "Epoch [2334/10000], Train Loss: 0.3206, Val Loss: 0.3959\n",
      "Epoch [2335/10000], Train Loss: 0.3210, Val Loss: 0.3831\n",
      "Epoch [2336/10000], Train Loss: 0.3208, Val Loss: 0.3848\n",
      "Epoch [2337/10000], Train Loss: 0.3212, Val Loss: 0.3900\n",
      "Epoch [2338/10000], Train Loss: 0.3211, Val Loss: 0.4290\n",
      "Epoch [2339/10000], Train Loss: 0.3207, Val Loss: 0.3792\n",
      "Epoch [2340/10000], Train Loss: 0.3207, Val Loss: 0.4153\n",
      "Epoch [2341/10000], Train Loss: 0.3210, Val Loss: 0.3775\n",
      "Epoch [2342/10000], Train Loss: 0.3212, Val Loss: 0.4101\n",
      "Epoch [2343/10000], Train Loss: 0.3206, Val Loss: 0.3809\n",
      "Epoch [2344/10000], Train Loss: 0.3212, Val Loss: 0.4167\n",
      "Epoch [2345/10000], Train Loss: 0.3209, Val Loss: 0.3875\n",
      "Epoch [2346/10000], Train Loss: 0.3207, Val Loss: 0.5127\n",
      "Epoch [2347/10000], Train Loss: 0.3210, Val Loss: 0.4430\n",
      "Epoch [2348/10000], Train Loss: 0.3208, Val Loss: 0.4223\n",
      "Epoch [2349/10000], Train Loss: 0.3208, Val Loss: 0.3926\n",
      "Epoch [2350/10000], Train Loss: 0.3210, Val Loss: 0.3988\n",
      "Epoch [2351/10000], Train Loss: 0.3212, Val Loss: 0.3935\n",
      "Epoch [2352/10000], Train Loss: 0.3210, Val Loss: 0.4167\n",
      "Epoch [2353/10000], Train Loss: 0.3208, Val Loss: 0.3948\n",
      "Epoch [2354/10000], Train Loss: 0.3208, Val Loss: 0.3877\n",
      "Epoch [2355/10000], Train Loss: 0.3205, Val Loss: 0.3912\n",
      "Epoch [2356/10000], Train Loss: 0.3213, Val Loss: 0.3860\n",
      "Epoch [2357/10000], Train Loss: 0.3214, Val Loss: 0.3857\n",
      "Epoch [2358/10000], Train Loss: 0.3207, Val Loss: 0.3920\n",
      "Epoch [2359/10000], Train Loss: 0.3206, Val Loss: 0.3866\n",
      "Epoch [2360/10000], Train Loss: 0.3211, Val Loss: 0.3830\n",
      "Epoch [2361/10000], Train Loss: 0.3204, Val Loss: 0.4053\n",
      "Epoch [2362/10000], Train Loss: 0.3208, Val Loss: 0.4243\n",
      "Epoch [2363/10000], Train Loss: 0.3210, Val Loss: 0.3787\n",
      "Epoch [2364/10000], Train Loss: 0.3206, Val Loss: 0.4976\n",
      "Epoch [2365/10000], Train Loss: 0.3211, Val Loss: 0.4203\n",
      "Epoch [2366/10000], Train Loss: 0.3205, Val Loss: 0.4308\n",
      "Epoch [2367/10000], Train Loss: 0.3208, Val Loss: 0.3918\n",
      "Epoch [2368/10000], Train Loss: 0.3208, Val Loss: 0.3918\n",
      "Epoch [2369/10000], Train Loss: 0.3214, Val Loss: 0.3867\n",
      "Epoch [2370/10000], Train Loss: 0.3208, Val Loss: 0.4021\n",
      "Epoch [2371/10000], Train Loss: 0.3211, Val Loss: 0.3933\n",
      "Epoch [2372/10000], Train Loss: 0.3207, Val Loss: 0.4380\n",
      "Epoch [2373/10000], Train Loss: 0.3208, Val Loss: 0.3968\n",
      "Epoch [2374/10000], Train Loss: 0.3212, Val Loss: 0.3839\n",
      "Epoch [2375/10000], Train Loss: 0.3212, Val Loss: 0.4018\n",
      "Epoch [2376/10000], Train Loss: 0.3206, Val Loss: 0.3923\n",
      "Epoch [2377/10000], Train Loss: 0.3208, Val Loss: 0.4039\n",
      "Epoch [2378/10000], Train Loss: 0.3211, Val Loss: 0.3937\n",
      "Epoch [2379/10000], Train Loss: 0.3209, Val Loss: 0.3791\n",
      "Epoch [2380/10000], Train Loss: 0.3208, Val Loss: 0.3776\n",
      "Epoch [2381/10000], Train Loss: 0.3212, Val Loss: 0.3860\n",
      "Epoch [2382/10000], Train Loss: 0.3214, Val Loss: 0.4244\n",
      "Epoch [2383/10000], Train Loss: 0.3206, Val Loss: 0.3817\n",
      "Epoch [2384/10000], Train Loss: 0.3209, Val Loss: 0.4111\n",
      "Epoch [2385/10000], Train Loss: 0.3206, Val Loss: 0.3810\n",
      "Epoch [2386/10000], Train Loss: 0.3208, Val Loss: 0.4129\n",
      "Epoch [2387/10000], Train Loss: 0.3210, Val Loss: 0.3961\n",
      "Epoch [2388/10000], Train Loss: 0.3207, Val Loss: 0.4781\n",
      "Epoch [2389/10000], Train Loss: 0.3207, Val Loss: 0.4190\n",
      "Epoch [2390/10000], Train Loss: 0.3208, Val Loss: 0.4246\n",
      "Epoch [2391/10000], Train Loss: 0.3205, Val Loss: 0.4014\n",
      "Epoch [2392/10000], Train Loss: 0.3208, Val Loss: 0.3824\n",
      "Epoch [2393/10000], Train Loss: 0.3204, Val Loss: 0.3824\n",
      "Epoch [2394/10000], Train Loss: 0.3208, Val Loss: 0.4263\n",
      "Epoch [2395/10000], Train Loss: 0.3208, Val Loss: 0.3906\n",
      "Epoch [2396/10000], Train Loss: 0.3207, Val Loss: 0.3883\n",
      "Epoch [2397/10000], Train Loss: 0.3206, Val Loss: 0.4004\n",
      "Epoch [2398/10000], Train Loss: 0.3208, Val Loss: 0.4073\n",
      "Epoch [2399/10000], Train Loss: 0.3210, Val Loss: 0.3911\n",
      "Epoch [2400/10000], Train Loss: 0.3210, Val Loss: 0.3853\n",
      "Epoch [2401/10000], Train Loss: 0.3209, Val Loss: 0.3783\n",
      "Epoch [2402/10000], Train Loss: 0.3211, Val Loss: 0.3821\n",
      "Epoch [2403/10000], Train Loss: 0.3209, Val Loss: 0.3955\n",
      "Epoch [2404/10000], Train Loss: 0.3208, Val Loss: 0.3887\n",
      "Epoch [2405/10000], Train Loss: 0.3211, Val Loss: 0.3811\n",
      "Epoch [2406/10000], Train Loss: 0.3210, Val Loss: 0.3803\n",
      "Epoch [2407/10000], Train Loss: 0.3210, Val Loss: 0.3985\n",
      "Epoch [2408/10000], Train Loss: 0.3214, Val Loss: 0.3859\n",
      "Epoch [2409/10000], Train Loss: 0.3208, Val Loss: 0.3988\n",
      "Epoch [2410/10000], Train Loss: 0.3204, Val Loss: 0.3921\n",
      "Epoch [2411/10000], Train Loss: 0.3205, Val Loss: 0.3836\n",
      "Epoch [2412/10000], Train Loss: 0.3208, Val Loss: 0.3826\n",
      "Epoch [2413/10000], Train Loss: 0.3211, Val Loss: 0.3794\n",
      "Epoch [2414/10000], Train Loss: 0.3208, Val Loss: 0.4791\n",
      "Epoch [2415/10000], Train Loss: 0.3207, Val Loss: 0.3957\n",
      "Epoch [2416/10000], Train Loss: 0.3207, Val Loss: 0.3770\n",
      "Epoch [2417/10000], Train Loss: 0.3210, Val Loss: 0.3870\n",
      "Epoch [2418/10000], Train Loss: 0.3211, Val Loss: 0.3835\n",
      "Epoch [2419/10000], Train Loss: 0.3207, Val Loss: 0.4081\n",
      "Epoch [2420/10000], Train Loss: 0.3209, Val Loss: 0.3816\n",
      "Epoch [2421/10000], Train Loss: 0.3207, Val Loss: 0.3854\n",
      "Epoch [2422/10000], Train Loss: 0.3205, Val Loss: 0.4143\n",
      "Epoch [2423/10000], Train Loss: 0.3209, Val Loss: 0.4029\n",
      "Epoch [2424/10000], Train Loss: 0.3211, Val Loss: 0.3794\n",
      "Epoch [2425/10000], Train Loss: 0.3208, Val Loss: 0.3768\n",
      "Epoch [2426/10000], Train Loss: 0.3205, Val Loss: 0.3869\n",
      "Epoch [2427/10000], Train Loss: 0.3210, Val Loss: 0.4142\n",
      "Epoch [2428/10000], Train Loss: 0.3209, Val Loss: 0.3998\n",
      "Epoch [2429/10000], Train Loss: 0.3209, Val Loss: 0.4039\n",
      "Epoch [2430/10000], Train Loss: 0.3209, Val Loss: 0.4450\n",
      "Epoch [2431/10000], Train Loss: 0.3209, Val Loss: 0.3891\n",
      "Epoch [2432/10000], Train Loss: 0.3205, Val Loss: 0.3833\n",
      "Epoch [2433/10000], Train Loss: 0.3206, Val Loss: 0.4009\n",
      "Epoch [2434/10000], Train Loss: 0.3207, Val Loss: 0.3861\n",
      "Epoch [2435/10000], Train Loss: 0.3211, Val Loss: 0.4019\n",
      "Epoch [2436/10000], Train Loss: 0.3211, Val Loss: 0.3806\n",
      "Epoch [2437/10000], Train Loss: 0.3210, Val Loss: 0.3909\n",
      "Epoch [2438/10000], Train Loss: 0.3205, Val Loss: 0.4219\n",
      "Epoch [2439/10000], Train Loss: 0.3213, Val Loss: 0.3827\n",
      "Epoch [2440/10000], Train Loss: 0.3210, Val Loss: 0.3919\n",
      "Epoch [2441/10000], Train Loss: 0.3208, Val Loss: 0.4410\n",
      "Epoch [2442/10000], Train Loss: 0.3208, Val Loss: 0.3869\n",
      "Epoch [2443/10000], Train Loss: 0.3213, Val Loss: 0.3843\n",
      "Epoch [2444/10000], Train Loss: 0.3207, Val Loss: 0.3824\n",
      "Epoch [2445/10000], Train Loss: 0.3205, Val Loss: 0.3960\n",
      "Epoch [2446/10000], Train Loss: 0.3210, Val Loss: 0.4014\n",
      "Epoch [2447/10000], Train Loss: 0.3206, Val Loss: 0.3806\n",
      "Epoch [2448/10000], Train Loss: 0.3207, Val Loss: 0.3974\n",
      "Epoch [2449/10000], Train Loss: 0.3210, Val Loss: 0.4127\n",
      "Epoch [2450/10000], Train Loss: 0.3208, Val Loss: 0.3814\n",
      "Epoch [2451/10000], Train Loss: 0.3208, Val Loss: 0.4436\n",
      "Epoch [2452/10000], Train Loss: 0.3208, Val Loss: 0.4097\n",
      "Epoch [2453/10000], Train Loss: 0.3206, Val Loss: 0.3836\n",
      "Epoch [2454/10000], Train Loss: 0.3209, Val Loss: 0.3881\n",
      "Epoch [2455/10000], Train Loss: 0.3205, Val Loss: 0.4307\n",
      "Epoch [2456/10000], Train Loss: 0.3207, Val Loss: 0.4056\n",
      "Epoch [2457/10000], Train Loss: 0.3205, Val Loss: 0.4158\n",
      "Epoch [2458/10000], Train Loss: 0.3208, Val Loss: 0.4236\n",
      "Epoch [2459/10000], Train Loss: 0.3211, Val Loss: 0.3892\n",
      "Epoch [2460/10000], Train Loss: 0.3208, Val Loss: 0.3764\n",
      "Epoch [2461/10000], Train Loss: 0.3205, Val Loss: 0.3918\n",
      "Epoch [2462/10000], Train Loss: 0.3206, Val Loss: 0.3890\n",
      "Epoch [2463/10000], Train Loss: 0.3203, Val Loss: 0.3934\n",
      "Epoch [2464/10000], Train Loss: 0.3208, Val Loss: 0.3776\n",
      "Epoch [2465/10000], Train Loss: 0.3208, Val Loss: 0.4029\n",
      "Epoch [2466/10000], Train Loss: 0.3208, Val Loss: 0.4134\n",
      "Epoch [2467/10000], Train Loss: 0.3214, Val Loss: 0.4041\n",
      "Epoch [2468/10000], Train Loss: 0.3209, Val Loss: 0.4097\n",
      "Epoch [2469/10000], Train Loss: 0.3207, Val Loss: 0.3919\n",
      "Epoch [2470/10000], Train Loss: 0.3210, Val Loss: 0.4029\n",
      "Epoch [2471/10000], Train Loss: 0.3208, Val Loss: 0.3833\n",
      "Epoch [2472/10000], Train Loss: 0.3211, Val Loss: 0.3968\n",
      "Epoch [2473/10000], Train Loss: 0.3207, Val Loss: 0.3833\n",
      "Epoch [2474/10000], Train Loss: 0.3208, Val Loss: 0.4097\n",
      "Epoch [2475/10000], Train Loss: 0.3210, Val Loss: 0.5262\n",
      "Epoch [2476/10000], Train Loss: 0.3212, Val Loss: 0.3915\n",
      "Epoch [2477/10000], Train Loss: 0.3208, Val Loss: 0.3908\n",
      "Epoch [2478/10000], Train Loss: 0.3205, Val Loss: 0.3783\n",
      "Epoch [2479/10000], Train Loss: 0.3209, Val Loss: 0.3845\n",
      "Epoch [2480/10000], Train Loss: 0.3205, Val Loss: 0.4165\n",
      "Epoch [2481/10000], Train Loss: 0.3210, Val Loss: 0.3779\n",
      "Epoch [2482/10000], Train Loss: 0.3205, Val Loss: 0.4067\n",
      "Epoch [2483/10000], Train Loss: 0.3230, Val Loss: 0.4221\n",
      "Epoch [2484/10000], Train Loss: 0.3206, Val Loss: 0.4116\n",
      "Epoch [2485/10000], Train Loss: 0.3205, Val Loss: 0.3966\n",
      "Epoch [2486/10000], Train Loss: 0.3205, Val Loss: 0.3879\n",
      "Epoch [2487/10000], Train Loss: 0.3205, Val Loss: 0.4410\n",
      "Epoch [2488/10000], Train Loss: 0.3208, Val Loss: 0.4580\n",
      "Epoch [2489/10000], Train Loss: 0.3207, Val Loss: 0.3791\n",
      "Epoch [2490/10000], Train Loss: 0.3206, Val Loss: 0.3849\n",
      "Epoch [2491/10000], Train Loss: 0.3206, Val Loss: 0.4701\n",
      "Epoch [2492/10000], Train Loss: 0.3207, Val Loss: 0.4153\n",
      "Epoch [2493/10000], Train Loss: 0.3212, Val Loss: 0.3806\n",
      "Epoch [2494/10000], Train Loss: 0.3207, Val Loss: 0.3821\n",
      "Epoch [2495/10000], Train Loss: 0.3209, Val Loss: 0.4165\n",
      "Epoch [2496/10000], Train Loss: 0.3212, Val Loss: 0.3940\n",
      "Epoch [2497/10000], Train Loss: 0.3208, Val Loss: 0.4521\n",
      "Epoch [2498/10000], Train Loss: 0.3208, Val Loss: 0.3849\n",
      "Epoch [2499/10000], Train Loss: 0.3205, Val Loss: 0.4844\n",
      "Epoch [2500/10000], Train Loss: 0.3214, Val Loss: 0.4276\n",
      "Epoch [2501/10000], Train Loss: 0.3209, Val Loss: 0.4213\n",
      "Epoch [2502/10000], Train Loss: 0.3207, Val Loss: 0.3900\n",
      "Epoch [2503/10000], Train Loss: 0.3207, Val Loss: 0.3793\n",
      "Epoch [2504/10000], Train Loss: 0.3209, Val Loss: 0.4402\n",
      "Epoch [2505/10000], Train Loss: 0.3213, Val Loss: 0.3800\n",
      "Epoch [2506/10000], Train Loss: 0.3208, Val Loss: 0.4373\n",
      "Epoch [2507/10000], Train Loss: 0.3206, Val Loss: 0.3992\n",
      "Epoch [2508/10000], Train Loss: 0.3210, Val Loss: 0.3901\n",
      "Epoch [2509/10000], Train Loss: 0.3208, Val Loss: 0.4065\n",
      "Epoch [2510/10000], Train Loss: 0.3205, Val Loss: 0.3892\n",
      "Epoch [2511/10000], Train Loss: 0.3206, Val Loss: 0.3988\n",
      "Epoch [2512/10000], Train Loss: 0.3210, Val Loss: 0.3812\n",
      "Epoch [2513/10000], Train Loss: 0.3208, Val Loss: 0.3809\n",
      "Epoch [2514/10000], Train Loss: 0.3207, Val Loss: 0.3972\n",
      "Epoch [2515/10000], Train Loss: 0.3208, Val Loss: 0.3812\n",
      "Epoch [2516/10000], Train Loss: 0.3209, Val Loss: 0.3855\n",
      "Epoch [2517/10000], Train Loss: 0.3208, Val Loss: 0.4171\n",
      "Epoch [2518/10000], Train Loss: 0.3208, Val Loss: 0.4035\n",
      "Epoch [2519/10000], Train Loss: 0.3205, Val Loss: 0.3863\n",
      "Epoch [2520/10000], Train Loss: 0.3206, Val Loss: 0.4408\n",
      "Epoch [2521/10000], Train Loss: 0.3206, Val Loss: 0.4216\n",
      "Epoch [2522/10000], Train Loss: 0.3210, Val Loss: 0.3977\n",
      "Epoch [2523/10000], Train Loss: 0.3208, Val Loss: 0.4003\n",
      "Epoch [2524/10000], Train Loss: 0.3208, Val Loss: 0.3965\n",
      "Epoch [2525/10000], Train Loss: 0.3206, Val Loss: 0.3914\n",
      "Epoch [2526/10000], Train Loss: 0.3206, Val Loss: 0.3918\n",
      "Epoch [2527/10000], Train Loss: 0.3208, Val Loss: 0.4215\n",
      "Epoch [2528/10000], Train Loss: 0.3206, Val Loss: 0.3791\n",
      "Epoch [2529/10000], Train Loss: 0.3207, Val Loss: 0.3849\n",
      "Epoch [2530/10000], Train Loss: 0.3208, Val Loss: 0.3813\n",
      "Epoch [2531/10000], Train Loss: 0.3208, Val Loss: 0.3977\n",
      "Epoch [2532/10000], Train Loss: 0.3207, Val Loss: 0.4245\n",
      "Epoch [2533/10000], Train Loss: 0.3210, Val Loss: 0.3895\n",
      "Epoch [2534/10000], Train Loss: 0.3207, Val Loss: 0.4094\n",
      "Epoch [2535/10000], Train Loss: 0.3208, Val Loss: 0.3851\n",
      "Epoch [2536/10000], Train Loss: 0.3205, Val Loss: 0.4049\n",
      "Epoch [2537/10000], Train Loss: 0.3209, Val Loss: 0.3877\n",
      "Epoch [2538/10000], Train Loss: 0.3208, Val Loss: 0.3800\n",
      "Epoch [2539/10000], Train Loss: 0.3205, Val Loss: 0.4523\n",
      "Epoch [2540/10000], Train Loss: 0.3211, Val Loss: 0.3867\n",
      "Epoch [2541/10000], Train Loss: 0.3209, Val Loss: 0.4009\n",
      "Epoch [2542/10000], Train Loss: 0.3205, Val Loss: 0.4225\n",
      "Epoch [2543/10000], Train Loss: 0.3205, Val Loss: 0.3783\n",
      "Epoch [2544/10000], Train Loss: 0.3207, Val Loss: 0.3972\n",
      "Epoch [2545/10000], Train Loss: 0.3207, Val Loss: 0.3774\n",
      "Epoch [2546/10000], Train Loss: 0.3207, Val Loss: 0.3986\n",
      "Epoch [2547/10000], Train Loss: 0.3207, Val Loss: 0.4394\n",
      "Epoch [2548/10000], Train Loss: 0.3206, Val Loss: 0.3950\n",
      "Epoch [2549/10000], Train Loss: 0.3203, Val Loss: 0.4092\n",
      "Epoch [2550/10000], Train Loss: 0.3207, Val Loss: 0.3815\n",
      "Epoch [2551/10000], Train Loss: 0.3209, Val Loss: 0.3962\n",
      "Epoch [2552/10000], Train Loss: 0.3208, Val Loss: 0.3816\n",
      "Epoch [2553/10000], Train Loss: 0.3210, Val Loss: 0.3831\n",
      "Epoch [2554/10000], Train Loss: 0.3209, Val Loss: 0.5065\n",
      "Epoch [2555/10000], Train Loss: 0.3206, Val Loss: 0.4387\n",
      "Epoch [2556/10000], Train Loss: 0.3209, Val Loss: 0.4021\n",
      "Epoch [2557/10000], Train Loss: 0.3208, Val Loss: 0.3896\n",
      "Epoch [2558/10000], Train Loss: 0.3208, Val Loss: 0.3843\n",
      "Epoch [2559/10000], Train Loss: 0.3208, Val Loss: 0.3836\n",
      "Epoch [2560/10000], Train Loss: 0.3208, Val Loss: 0.3822\n",
      "Epoch [2561/10000], Train Loss: 0.3202, Val Loss: 0.3842\n",
      "Epoch [2562/10000], Train Loss: 0.3207, Val Loss: 0.3856\n",
      "Epoch [2563/10000], Train Loss: 0.3209, Val Loss: 0.3794\n",
      "Epoch [2564/10000], Train Loss: 0.3202, Val Loss: 0.3804\n",
      "Epoch [2565/10000], Train Loss: 0.3205, Val Loss: 0.4044\n",
      "Epoch [2566/10000], Train Loss: 0.3208, Val Loss: 0.3849\n",
      "Epoch [2567/10000], Train Loss: 0.3212, Val Loss: 0.3849\n",
      "Epoch [2568/10000], Train Loss: 0.3203, Val Loss: 0.3862\n",
      "Epoch [2569/10000], Train Loss: 0.3205, Val Loss: 0.4222\n",
      "Epoch [2570/10000], Train Loss: 0.3206, Val Loss: 0.3815\n",
      "Epoch [2571/10000], Train Loss: 0.3207, Val Loss: 0.3951\n",
      "Epoch [2572/10000], Train Loss: 0.3206, Val Loss: 0.3920\n",
      "Epoch [2573/10000], Train Loss: 0.3211, Val Loss: 0.3816\n",
      "Epoch [2574/10000], Train Loss: 0.3205, Val Loss: 0.3920\n",
      "Epoch [2575/10000], Train Loss: 0.3209, Val Loss: 0.4127\n",
      "Epoch [2576/10000], Train Loss: 0.3209, Val Loss: 0.4101\n",
      "Epoch [2577/10000], Train Loss: 0.3211, Val Loss: 0.3962\n",
      "Epoch [2578/10000], Train Loss: 0.3209, Val Loss: 0.3878\n",
      "Epoch [2579/10000], Train Loss: 0.3209, Val Loss: 0.3758\n",
      "Epoch [2580/10000], Train Loss: 0.3212, Val Loss: 0.3958\n",
      "Epoch [2581/10000], Train Loss: 0.3208, Val Loss: 0.3834\n",
      "Epoch [2582/10000], Train Loss: 0.3207, Val Loss: 0.3874\n",
      "Epoch [2583/10000], Train Loss: 0.3209, Val Loss: 0.4329\n",
      "Epoch [2584/10000], Train Loss: 0.3207, Val Loss: 0.3856\n",
      "Epoch [2585/10000], Train Loss: 0.3203, Val Loss: 0.4154\n",
      "Epoch [2586/10000], Train Loss: 0.3208, Val Loss: 0.3931\n",
      "Epoch [2587/10000], Train Loss: 0.3209, Val Loss: 0.3872\n",
      "Epoch [2588/10000], Train Loss: 0.3207, Val Loss: 0.3866\n",
      "Epoch [2589/10000], Train Loss: 3.1250, Val Loss: 9.8631\n",
      "Epoch [2590/10000], Train Loss: 2.7386, Val Loss: 4.7389\n",
      "Epoch [2591/10000], Train Loss: 1.8299, Val Loss: 2.5547\n",
      "Epoch [2592/10000], Train Loss: 1.4810, Val Loss: 1.8185\n",
      "Epoch [2593/10000], Train Loss: 1.3065, Val Loss: 1.4599\n",
      "Epoch [2594/10000], Train Loss: 1.0562, Val Loss: 1.5148\n",
      "Epoch [2595/10000], Train Loss: 1.0512, Val Loss: 1.3454\n",
      "Epoch [2596/10000], Train Loss: 1.0637, Val Loss: 2.0035\n",
      "Epoch [2597/10000], Train Loss: 0.9216, Val Loss: 1.0429\n",
      "Epoch [2598/10000], Train Loss: 0.6682, Val Loss: 0.7247\n",
      "Epoch [2599/10000], Train Loss: 0.5535, Val Loss: 0.5976\n",
      "Epoch [2600/10000], Train Loss: 0.5054, Val Loss: 0.5396\n",
      "Epoch [2601/10000], Train Loss: 0.4811, Val Loss: 0.5113\n",
      "Epoch [2602/10000], Train Loss: 0.4621, Val Loss: 0.5606\n",
      "Epoch [2603/10000], Train Loss: 0.4477, Val Loss: 0.5602\n",
      "Epoch [2604/10000], Train Loss: 0.4314, Val Loss: 0.6454\n",
      "Epoch [2605/10000], Train Loss: 0.4057, Val Loss: 0.4778\n",
      "Epoch [2606/10000], Train Loss: 0.3780, Val Loss: 0.4325\n",
      "Epoch [2607/10000], Train Loss: 0.3518, Val Loss: 0.4300\n",
      "Epoch [2608/10000], Train Loss: 0.3415, Val Loss: 0.4242\n",
      "Epoch [2609/10000], Train Loss: 0.3378, Val Loss: 0.4484\n",
      "Epoch [2610/10000], Train Loss: 0.3349, Val Loss: 0.4049\n",
      "Epoch [2611/10000], Train Loss: 0.3332, Val Loss: 0.4623\n",
      "Epoch [2612/10000], Train Loss: 0.3280, Val Loss: 0.3931\n",
      "Epoch [2613/10000], Train Loss: 0.3237, Val Loss: 0.4134\n",
      "Epoch [2614/10000], Train Loss: 0.3230, Val Loss: 0.3962\n",
      "Epoch [2615/10000], Train Loss: 0.3227, Val Loss: 0.3969\n",
      "Epoch [2616/10000], Train Loss: 0.3218, Val Loss: 0.3866\n",
      "Epoch [2617/10000], Train Loss: 0.3216, Val Loss: 0.3972\n",
      "Epoch [2618/10000], Train Loss: 0.3215, Val Loss: 0.4089\n",
      "Epoch [2619/10000], Train Loss: 0.3215, Val Loss: 0.3928\n",
      "Epoch [2620/10000], Train Loss: 0.3214, Val Loss: 0.3823\n",
      "Epoch [2621/10000], Train Loss: 0.3214, Val Loss: 0.3851\n",
      "Epoch [2622/10000], Train Loss: 0.3208, Val Loss: 0.4303\n",
      "Epoch [2623/10000], Train Loss: 0.3213, Val Loss: 0.3900\n",
      "Epoch [2624/10000], Train Loss: 0.3208, Val Loss: 0.3991\n",
      "Epoch [2625/10000], Train Loss: 0.3210, Val Loss: 0.4012\n",
      "Epoch [2626/10000], Train Loss: 0.3212, Val Loss: 0.4020\n",
      "Epoch [2627/10000], Train Loss: 0.3210, Val Loss: 0.4127\n",
      "Epoch [2628/10000], Train Loss: 0.3209, Val Loss: 0.4114\n",
      "Epoch [2629/10000], Train Loss: 0.3208, Val Loss: 0.4724\n",
      "Epoch [2630/10000], Train Loss: 0.3208, Val Loss: 0.4013\n",
      "Epoch [2631/10000], Train Loss: 0.3208, Val Loss: 0.3958\n",
      "Epoch [2632/10000], Train Loss: 0.3210, Val Loss: 0.3893\n",
      "Epoch [2633/10000], Train Loss: 0.3208, Val Loss: 0.4047\n",
      "Epoch [2634/10000], Train Loss: 0.3209, Val Loss: 0.3876\n",
      "Epoch [2635/10000], Train Loss: 0.3206, Val Loss: 0.3800\n",
      "Epoch [2636/10000], Train Loss: 0.3208, Val Loss: 0.4082\n",
      "Epoch [2637/10000], Train Loss: 0.3209, Val Loss: 0.3909\n",
      "Epoch [2638/10000], Train Loss: 0.3207, Val Loss: 0.4021\n",
      "Epoch [2639/10000], Train Loss: 0.3207, Val Loss: 0.3882\n",
      "Epoch [2640/10000], Train Loss: 0.3208, Val Loss: 0.3997\n",
      "Epoch [2641/10000], Train Loss: 0.3207, Val Loss: 0.4049\n",
      "Epoch [2642/10000], Train Loss: 0.3213, Val Loss: 0.3970\n",
      "Epoch [2643/10000], Train Loss: 0.3208, Val Loss: 0.4133\n",
      "Epoch [2644/10000], Train Loss: 0.3212, Val Loss: 0.4366\n",
      "Epoch [2645/10000], Train Loss: 0.3206, Val Loss: 0.3990\n",
      "Epoch [2646/10000], Train Loss: 0.3206, Val Loss: 0.4224\n",
      "Epoch [2647/10000], Train Loss: 0.3211, Val Loss: 0.3847\n",
      "Epoch [2648/10000], Train Loss: 0.3206, Val Loss: 0.3885\n",
      "Epoch [2649/10000], Train Loss: 0.3209, Val Loss: 0.3973\n",
      "Epoch [2650/10000], Train Loss: 0.3211, Val Loss: 0.4082\n",
      "Epoch [2651/10000], Train Loss: 0.3209, Val Loss: 0.3882\n",
      "Epoch [2652/10000], Train Loss: 0.3207, Val Loss: 0.3864\n",
      "Epoch [2653/10000], Train Loss: 0.3210, Val Loss: 0.3955\n",
      "Epoch [2654/10000], Train Loss: 0.3204, Val Loss: 0.4170\n",
      "Epoch [2655/10000], Train Loss: 0.3205, Val Loss: 0.3967\n",
      "Epoch [2656/10000], Train Loss: 0.3207, Val Loss: 0.3948\n",
      "Epoch [2657/10000], Train Loss: 0.3211, Val Loss: 0.3957\n",
      "Epoch [2658/10000], Train Loss: 0.3206, Val Loss: 0.3824\n",
      "Epoch [2659/10000], Train Loss: 0.3208, Val Loss: 0.4083\n",
      "Epoch [2660/10000], Train Loss: 0.3207, Val Loss: 0.3807\n",
      "Epoch [2661/10000], Train Loss: 0.3209, Val Loss: 0.4089\n",
      "Epoch [2662/10000], Train Loss: 0.3210, Val Loss: 0.3893\n",
      "Epoch [2663/10000], Train Loss: 0.3209, Val Loss: 0.4043\n",
      "Epoch [2664/10000], Train Loss: 0.3208, Val Loss: 0.4023\n",
      "Epoch [2665/10000], Train Loss: 0.3208, Val Loss: 0.4200\n",
      "Epoch [2666/10000], Train Loss: 0.3214, Val Loss: 0.3827\n",
      "Epoch [2667/10000], Train Loss: 0.3208, Val Loss: 0.3985\n",
      "Epoch [2668/10000], Train Loss: 0.3211, Val Loss: 0.3962\n",
      "Epoch [2669/10000], Train Loss: 0.3201, Val Loss: 0.3974\n",
      "Epoch [2670/10000], Train Loss: 0.3209, Val Loss: 0.3860\n",
      "Epoch [2671/10000], Train Loss: 0.3205, Val Loss: 0.3891\n",
      "Epoch [2672/10000], Train Loss: 0.3207, Val Loss: 0.4652\n",
      "Epoch [2673/10000], Train Loss: 0.3210, Val Loss: 0.4648\n",
      "Epoch [2674/10000], Train Loss: 0.3207, Val Loss: 0.3815\n",
      "Epoch [2675/10000], Train Loss: 0.3209, Val Loss: 0.3957\n",
      "Epoch [2676/10000], Train Loss: 0.3208, Val Loss: 0.3911\n",
      "Epoch [2677/10000], Train Loss: 0.3210, Val Loss: 0.4009\n",
      "Epoch [2678/10000], Train Loss: 0.3206, Val Loss: 0.3919\n",
      "Epoch [2679/10000], Train Loss: 0.3207, Val Loss: 0.4030\n",
      "Epoch [2680/10000], Train Loss: 0.3210, Val Loss: 0.3797\n",
      "Epoch [2681/10000], Train Loss: 0.3208, Val Loss: 0.4018\n",
      "Epoch [2682/10000], Train Loss: 0.3207, Val Loss: 0.4758\n",
      "Epoch [2683/10000], Train Loss: 0.3206, Val Loss: 0.3784\n",
      "Epoch [2684/10000], Train Loss: 0.3208, Val Loss: 0.3768\n",
      "Epoch [2685/10000], Train Loss: 0.3208, Val Loss: 0.3958\n",
      "Epoch [2686/10000], Train Loss: 0.3208, Val Loss: 0.4312\n",
      "Epoch [2687/10000], Train Loss: 0.3209, Val Loss: 0.3834\n",
      "Epoch [2688/10000], Train Loss: 0.3209, Val Loss: 0.3985\n",
      "Epoch [2689/10000], Train Loss: 0.3206, Val Loss: 0.3850\n",
      "Epoch [2690/10000], Train Loss: 0.3208, Val Loss: 0.3803\n",
      "Epoch [2691/10000], Train Loss: 0.3213, Val Loss: 0.3826\n",
      "Epoch [2692/10000], Train Loss: 0.3209, Val Loss: 0.3823\n",
      "Epoch [2693/10000], Train Loss: 0.3213, Val Loss: 0.3819\n",
      "Epoch [2694/10000], Train Loss: 0.3205, Val Loss: 0.3798\n",
      "Epoch [2695/10000], Train Loss: 0.3208, Val Loss: 0.4124\n",
      "Epoch [2696/10000], Train Loss: 0.3205, Val Loss: 0.3923\n",
      "Epoch [2697/10000], Train Loss: 0.3204, Val Loss: 0.3860\n",
      "Epoch [2698/10000], Train Loss: 0.3205, Val Loss: 0.4123\n",
      "Epoch [2699/10000], Train Loss: 0.3208, Val Loss: 0.3904\n",
      "Epoch [2700/10000], Train Loss: 0.3210, Val Loss: 0.4464\n",
      "Epoch [2701/10000], Train Loss: 0.3209, Val Loss: 0.3862\n",
      "Epoch [2702/10000], Train Loss: 0.3206, Val Loss: 0.3787\n",
      "Epoch [2703/10000], Train Loss: 0.3202, Val Loss: 0.3803\n",
      "Epoch [2704/10000], Train Loss: 0.3210, Val Loss: 0.3782\n",
      "Epoch [2705/10000], Train Loss: 0.3207, Val Loss: 0.5167\n",
      "Epoch [2706/10000], Train Loss: 0.3204, Val Loss: 0.3777\n",
      "Epoch [2707/10000], Train Loss: 0.3206, Val Loss: 0.4528\n",
      "Epoch [2708/10000], Train Loss: 0.3205, Val Loss: 0.3916\n",
      "Epoch [2709/10000], Train Loss: 0.3205, Val Loss: 0.3902\n",
      "Epoch [2710/10000], Train Loss: 0.3206, Val Loss: 0.3975\n",
      "Epoch [2711/10000], Train Loss: 0.3206, Val Loss: 0.4251\n",
      "Epoch [2712/10000], Train Loss: 0.3205, Val Loss: 0.3792\n",
      "Epoch [2713/10000], Train Loss: 0.3210, Val Loss: 0.3845\n",
      "Epoch [2714/10000], Train Loss: 0.3204, Val Loss: 0.3827\n",
      "Epoch [2715/10000], Train Loss: 0.3206, Val Loss: 0.4059\n",
      "Epoch [2716/10000], Train Loss: 0.3206, Val Loss: 0.3836\n",
      "Epoch [2717/10000], Train Loss: 0.3214, Val Loss: 0.3813\n",
      "Epoch [2718/10000], Train Loss: 0.3216, Val Loss: 0.3994\n",
      "Epoch [2719/10000], Train Loss: 0.3208, Val Loss: 0.3911\n",
      "Epoch [2720/10000], Train Loss: 0.3209, Val Loss: 0.3899\n",
      "Epoch [2721/10000], Train Loss: 0.3209, Val Loss: 0.3911\n",
      "Epoch [2722/10000], Train Loss: 0.3206, Val Loss: 0.3886\n",
      "Epoch [2723/10000], Train Loss: 0.3209, Val Loss: 0.3925\n",
      "Epoch [2724/10000], Train Loss: 0.3207, Val Loss: 0.3827\n",
      "Epoch [2725/10000], Train Loss: 0.3204, Val Loss: 0.3780\n",
      "Epoch [2726/10000], Train Loss: 0.3208, Val Loss: 0.3817\n",
      "Epoch [2727/10000], Train Loss: 0.3213, Val Loss: 0.3917\n",
      "Epoch [2728/10000], Train Loss: 0.3206, Val Loss: 0.3962\n",
      "Epoch [2729/10000], Train Loss: 0.3206, Val Loss: 0.3987\n",
      "Epoch [2730/10000], Train Loss: 0.3204, Val Loss: 0.3818\n",
      "Epoch [2731/10000], Train Loss: 0.3206, Val Loss: 0.4267\n",
      "Epoch [2732/10000], Train Loss: 0.3207, Val Loss: 0.3816\n",
      "Epoch [2733/10000], Train Loss: 0.3204, Val Loss: 0.3798\n",
      "Epoch [2734/10000], Train Loss: 0.3203, Val Loss: 0.3844\n",
      "Epoch [2735/10000], Train Loss: 0.3208, Val Loss: 0.4499\n",
      "Epoch [2736/10000], Train Loss: 0.3210, Val Loss: 0.4363\n",
      "Epoch [2737/10000], Train Loss: 0.3210, Val Loss: 0.4406\n",
      "Epoch [2738/10000], Train Loss: 0.3203, Val Loss: 0.3783\n",
      "Epoch [2739/10000], Train Loss: 0.3204, Val Loss: 0.3842\n",
      "Epoch [2740/10000], Train Loss: 0.3206, Val Loss: 0.3984\n",
      "Epoch [2741/10000], Train Loss: 0.3206, Val Loss: 0.3808\n",
      "Epoch [2742/10000], Train Loss: 0.3206, Val Loss: 0.3832\n",
      "Epoch [2743/10000], Train Loss: 0.3204, Val Loss: 0.3767\n",
      "Epoch [2744/10000], Train Loss: 0.3210, Val Loss: 0.4067\n",
      "Epoch [2745/10000], Train Loss: 0.3202, Val Loss: 0.3800\n",
      "Epoch [2746/10000], Train Loss: 0.3208, Val Loss: 0.4008\n",
      "Epoch [2747/10000], Train Loss: 0.3207, Val Loss: 0.3933\n",
      "Epoch [2748/10000], Train Loss: 0.3208, Val Loss: 0.4091\n",
      "Epoch [2749/10000], Train Loss: 0.3210, Val Loss: 0.3825\n",
      "Epoch [2750/10000], Train Loss: 0.3205, Val Loss: 0.4000\n",
      "Epoch [2751/10000], Train Loss: 0.3208, Val Loss: 0.3887\n",
      "Epoch [2752/10000], Train Loss: 0.3207, Val Loss: 0.4018\n",
      "Epoch [2753/10000], Train Loss: 0.3213, Val Loss: 0.3936\n",
      "Epoch [2754/10000], Train Loss: 0.3203, Val Loss: 0.3972\n",
      "Epoch [2755/10000], Train Loss: 0.3206, Val Loss: 0.3820\n",
      "Epoch [2756/10000], Train Loss: 0.3205, Val Loss: 0.3943\n",
      "Epoch [2757/10000], Train Loss: 0.3211, Val Loss: 0.4036\n",
      "Epoch [2758/10000], Train Loss: 0.3220, Val Loss: 0.3958\n",
      "Epoch [2759/10000], Train Loss: 0.3203, Val Loss: 0.3945\n",
      "Epoch [2760/10000], Train Loss: 0.3206, Val Loss: 0.4062\n",
      "Epoch [2761/10000], Train Loss: 0.3204, Val Loss: 0.4065\n",
      "Epoch [2762/10000], Train Loss: 0.3209, Val Loss: 0.3821\n",
      "Epoch [2763/10000], Train Loss: 0.3206, Val Loss: 0.3858\n",
      "Epoch [2764/10000], Train Loss: 0.3210, Val Loss: 0.3884\n",
      "Epoch [2765/10000], Train Loss: 0.3208, Val Loss: 0.3983\n",
      "Epoch [2766/10000], Train Loss: 0.3207, Val Loss: 0.3800\n",
      "Epoch [2767/10000], Train Loss: 0.3204, Val Loss: 0.3889\n",
      "Epoch [2768/10000], Train Loss: 0.3209, Val Loss: 0.3797\n",
      "Epoch [2769/10000], Train Loss: 0.3204, Val Loss: 0.4954\n",
      "Epoch [2770/10000], Train Loss: 0.3209, Val Loss: 0.3919\n",
      "Epoch [2771/10000], Train Loss: 0.3206, Val Loss: 0.3824\n",
      "Epoch [2772/10000], Train Loss: 0.3207, Val Loss: 0.4227\n",
      "Epoch [2773/10000], Train Loss: 0.3205, Val Loss: 0.3797\n",
      "Epoch [2774/10000], Train Loss: 0.3203, Val Loss: 0.3907\n",
      "Epoch [2775/10000], Train Loss: 0.3207, Val Loss: 0.4142\n",
      "Epoch [2776/10000], Train Loss: 0.3207, Val Loss: 0.3775\n",
      "Epoch [2777/10000], Train Loss: 0.3208, Val Loss: 0.3924\n",
      "Epoch [2778/10000], Train Loss: 0.3206, Val Loss: 0.3916\n",
      "Epoch [2779/10000], Train Loss: 0.3205, Val Loss: 0.4129\n",
      "Epoch [2780/10000], Train Loss: 0.3205, Val Loss: 0.3825\n",
      "Epoch [2781/10000], Train Loss: 0.3205, Val Loss: 0.3902\n",
      "Epoch [2782/10000], Train Loss: 0.3207, Val Loss: 0.3867\n",
      "Epoch [2783/10000], Train Loss: 0.3209, Val Loss: 0.3859\n",
      "Epoch [2784/10000], Train Loss: 0.3206, Val Loss: 0.3899\n",
      "Epoch [2785/10000], Train Loss: 0.3207, Val Loss: 0.3742\n",
      "Validation loss improved from 0.3752 to 0.3742. Saving model...\n",
      "Epoch [2786/10000], Train Loss: 0.3210, Val Loss: 0.3842\n",
      "Epoch [2787/10000], Train Loss: 0.3211, Val Loss: 0.3857\n",
      "Epoch [2788/10000], Train Loss: 0.3209, Val Loss: 0.3799\n",
      "Epoch [2789/10000], Train Loss: 0.3207, Val Loss: 0.4092\n",
      "Epoch [2790/10000], Train Loss: 0.3208, Val Loss: 0.3928\n",
      "Epoch [2791/10000], Train Loss: 0.3206, Val Loss: 0.3816\n",
      "Epoch [2792/10000], Train Loss: 0.3208, Val Loss: 0.3888\n",
      "Epoch [2793/10000], Train Loss: 0.3205, Val Loss: 0.3891\n",
      "Epoch [2794/10000], Train Loss: 0.3206, Val Loss: 0.3929\n",
      "Epoch [2795/10000], Train Loss: 0.3208, Val Loss: 0.4112\n",
      "Epoch [2796/10000], Train Loss: 0.3208, Val Loss: 0.3874\n",
      "Epoch [2797/10000], Train Loss: 0.3206, Val Loss: 0.3974\n",
      "Epoch [2798/10000], Train Loss: 0.3208, Val Loss: 0.3777\n",
      "Epoch [2799/10000], Train Loss: 0.3207, Val Loss: 0.3851\n",
      "Epoch [2800/10000], Train Loss: 0.3206, Val Loss: 0.4474\n",
      "Epoch [2801/10000], Train Loss: 0.3206, Val Loss: 0.3864\n",
      "Epoch [2802/10000], Train Loss: 0.3206, Val Loss: 0.3836\n",
      "Epoch [2803/10000], Train Loss: 0.3206, Val Loss: 0.4079\n",
      "Epoch [2804/10000], Train Loss: 0.3205, Val Loss: 0.3876\n",
      "Epoch [2805/10000], Train Loss: 0.3206, Val Loss: 0.3844\n",
      "Epoch [2806/10000], Train Loss: 0.3206, Val Loss: 0.3787\n",
      "Epoch [2807/10000], Train Loss: 0.3206, Val Loss: 0.3877\n",
      "Epoch [2808/10000], Train Loss: 0.3205, Val Loss: 0.4037\n",
      "Epoch [2809/10000], Train Loss: 0.3208, Val Loss: 0.3971\n",
      "Epoch [2810/10000], Train Loss: 0.3207, Val Loss: 0.4384\n",
      "Epoch [2811/10000], Train Loss: 0.3212, Val Loss: 0.3775\n",
      "Epoch [2812/10000], Train Loss: 0.3207, Val Loss: 0.3801\n",
      "Epoch [2813/10000], Train Loss: 0.3205, Val Loss: 0.3987\n",
      "Epoch [2814/10000], Train Loss: 0.3207, Val Loss: 0.3826\n",
      "Epoch [2815/10000], Train Loss: 0.3205, Val Loss: 0.4008\n",
      "Epoch [2816/10000], Train Loss: 0.3206, Val Loss: 0.3836\n",
      "Epoch [2817/10000], Train Loss: 0.3201, Val Loss: 0.3791\n",
      "Epoch [2818/10000], Train Loss: 0.3206, Val Loss: 0.3875\n",
      "Epoch [2819/10000], Train Loss: 0.3207, Val Loss: 0.3936\n",
      "Epoch [2820/10000], Train Loss: 0.3211, Val Loss: 0.3870\n",
      "Epoch [2821/10000], Train Loss: 0.3205, Val Loss: 0.3857\n",
      "Epoch [2822/10000], Train Loss: 0.3206, Val Loss: 0.4130\n",
      "Epoch [2823/10000], Train Loss: 0.3205, Val Loss: 0.4060\n",
      "Epoch [2824/10000], Train Loss: 0.3202, Val Loss: 0.3772\n",
      "Epoch [2825/10000], Train Loss: 0.3209, Val Loss: 0.3770\n",
      "Epoch [2826/10000], Train Loss: 0.3207, Val Loss: 0.3847\n",
      "Epoch [2827/10000], Train Loss: 0.3205, Val Loss: 0.3826\n",
      "Epoch [2828/10000], Train Loss: 0.3210, Val Loss: 0.3825\n",
      "Epoch [2829/10000], Train Loss: 0.3208, Val Loss: 0.4286\n",
      "Epoch [2830/10000], Train Loss: 0.3206, Val Loss: 0.4014\n",
      "Epoch [2831/10000], Train Loss: 0.3205, Val Loss: 0.3826\n",
      "Epoch [2832/10000], Train Loss: 0.3209, Val Loss: 0.3830\n",
      "Epoch [2833/10000], Train Loss: 0.3210, Val Loss: 0.3778\n",
      "Epoch [2834/10000], Train Loss: 0.3208, Val Loss: 0.3966\n",
      "Epoch [2835/10000], Train Loss: 0.3207, Val Loss: 0.3951\n",
      "Epoch [2836/10000], Train Loss: 0.3205, Val Loss: 0.3851\n",
      "Epoch [2837/10000], Train Loss: 0.3210, Val Loss: 0.3817\n",
      "Epoch [2838/10000], Train Loss: 0.3201, Val Loss: 0.3768\n",
      "Epoch [2839/10000], Train Loss: 0.3208, Val Loss: 0.3830\n",
      "Epoch [2840/10000], Train Loss: 0.3208, Val Loss: 0.3871\n",
      "Epoch [2841/10000], Train Loss: 0.3210, Val Loss: 0.3812\n",
      "Epoch [2842/10000], Train Loss: 0.3206, Val Loss: 0.3806\n",
      "Epoch [2843/10000], Train Loss: 0.3208, Val Loss: 0.3918\n",
      "Epoch [2844/10000], Train Loss: 0.3205, Val Loss: 0.3785\n",
      "Epoch [2845/10000], Train Loss: 0.3206, Val Loss: 0.3890\n",
      "Epoch [2846/10000], Train Loss: 0.3208, Val Loss: 0.4013\n",
      "Epoch [2847/10000], Train Loss: 0.3210, Val Loss: 0.4340\n",
      "Epoch [2848/10000], Train Loss: 0.3205, Val Loss: 0.3982\n",
      "Epoch [2849/10000], Train Loss: 0.3203, Val Loss: 0.3865\n",
      "Epoch [2850/10000], Train Loss: 0.3205, Val Loss: 0.3920\n",
      "Epoch [2851/10000], Train Loss: 0.3203, Val Loss: 0.4035\n",
      "Epoch [2852/10000], Train Loss: 0.3207, Val Loss: 0.3945\n",
      "Epoch [2853/10000], Train Loss: 0.3208, Val Loss: 0.3875\n",
      "Epoch [2854/10000], Train Loss: 0.3207, Val Loss: 0.3912\n",
      "Epoch [2855/10000], Train Loss: 0.3207, Val Loss: 0.3842\n",
      "Epoch [2856/10000], Train Loss: 0.3203, Val Loss: 0.3806\n",
      "Epoch [2857/10000], Train Loss: 0.3204, Val Loss: 0.3823\n",
      "Epoch [2858/10000], Train Loss: 0.3206, Val Loss: 0.4071\n",
      "Epoch [2859/10000], Train Loss: 0.3205, Val Loss: 0.3828\n",
      "Epoch [2860/10000], Train Loss: 0.3206, Val Loss: 0.4093\n",
      "Epoch [2861/10000], Train Loss: 0.3206, Val Loss: 0.4342\n",
      "Epoch [2862/10000], Train Loss: 0.3205, Val Loss: 0.3854\n",
      "Epoch [2863/10000], Train Loss: 0.3208, Val Loss: 0.3856\n",
      "Epoch [2864/10000], Train Loss: 0.3210, Val Loss: 0.3956\n",
      "Epoch [2865/10000], Train Loss: 0.3207, Val Loss: 0.4155\n",
      "Epoch [2866/10000], Train Loss: 0.3205, Val Loss: 0.3890\n",
      "Epoch [2867/10000], Train Loss: 0.3210, Val Loss: 0.3852\n",
      "Epoch [2868/10000], Train Loss: 0.3206, Val Loss: 0.4045\n",
      "Epoch [2869/10000], Train Loss: 0.3205, Val Loss: 0.3868\n",
      "Epoch [2870/10000], Train Loss: 0.3204, Val Loss: 0.3983\n",
      "Epoch [2871/10000], Train Loss: 0.3205, Val Loss: 0.4077\n",
      "Epoch [2872/10000], Train Loss: 0.3207, Val Loss: 0.3960\n",
      "Epoch [2873/10000], Train Loss: 0.3210, Val Loss: 0.3858\n",
      "Epoch [2874/10000], Train Loss: 0.3205, Val Loss: 0.4073\n",
      "Epoch [2875/10000], Train Loss: 0.3207, Val Loss: 0.3804\n",
      "Epoch [2876/10000], Train Loss: 0.3205, Val Loss: 0.4014\n",
      "Epoch [2877/10000], Train Loss: 0.3208, Val Loss: 0.3832\n",
      "Epoch [2878/10000], Train Loss: 0.3206, Val Loss: 0.4048\n",
      "Epoch [2879/10000], Train Loss: 0.3205, Val Loss: 0.4009\n",
      "Epoch [2880/10000], Train Loss: 0.3205, Val Loss: 0.3809\n",
      "Epoch [2881/10000], Train Loss: 0.3207, Val Loss: 0.3926\n",
      "Epoch [2882/10000], Train Loss: 0.3207, Val Loss: 0.5250\n",
      "Epoch [2883/10000], Train Loss: 0.3205, Val Loss: 0.3817\n",
      "Epoch [2884/10000], Train Loss: 0.3211, Val Loss: 0.3860\n",
      "Epoch [2885/10000], Train Loss: 0.3207, Val Loss: 0.3980\n",
      "Epoch [2886/10000], Train Loss: 0.3209, Val Loss: 0.3924\n",
      "Epoch [2887/10000], Train Loss: 0.3207, Val Loss: 0.3811\n",
      "Epoch [2888/10000], Train Loss: 0.3207, Val Loss: 0.3818\n",
      "Epoch [2889/10000], Train Loss: 0.3207, Val Loss: 0.3848\n",
      "Epoch [2890/10000], Train Loss: 0.3205, Val Loss: 0.3820\n",
      "Epoch [2891/10000], Train Loss: 0.3210, Val Loss: 0.3792\n",
      "Epoch [2892/10000], Train Loss: 0.3207, Val Loss: 0.3773\n",
      "Epoch [2893/10000], Train Loss: 0.3206, Val Loss: 0.4148\n",
      "Epoch [2894/10000], Train Loss: 0.3206, Val Loss: 0.3942\n",
      "Epoch [2895/10000], Train Loss: 0.3205, Val Loss: 0.3979\n",
      "Epoch [2896/10000], Train Loss: 0.3207, Val Loss: 0.3820\n",
      "Epoch [2897/10000], Train Loss: 0.3206, Val Loss: 0.4038\n",
      "Epoch [2898/10000], Train Loss: 0.3209, Val Loss: 0.4190\n",
      "Epoch [2899/10000], Train Loss: 0.3205, Val Loss: 0.3738\n",
      "Validation loss improved from 0.3742 to 0.3738. Saving model...\n",
      "Epoch [2900/10000], Train Loss: 0.3204, Val Loss: 0.3856\n",
      "Epoch [2901/10000], Train Loss: 0.3207, Val Loss: 0.4114\n",
      "Epoch [2902/10000], Train Loss: 0.3207, Val Loss: 0.3787\n",
      "Epoch [2903/10000], Train Loss: 0.3207, Val Loss: 0.3907\n",
      "Epoch [2904/10000], Train Loss: 0.3204, Val Loss: 0.3798\n",
      "Epoch [2905/10000], Train Loss: 0.3206, Val Loss: 0.4201\n",
      "Epoch [2906/10000], Train Loss: 0.3206, Val Loss: 0.3848\n",
      "Epoch [2907/10000], Train Loss: 0.3209, Val Loss: 0.3775\n",
      "Epoch [2908/10000], Train Loss: 0.3204, Val Loss: 0.3783\n",
      "Epoch [2909/10000], Train Loss: 0.3206, Val Loss: 0.3828\n",
      "Epoch [2910/10000], Train Loss: 0.3202, Val Loss: 0.3996\n",
      "Epoch [2911/10000], Train Loss: 0.3204, Val Loss: 0.3987\n",
      "Epoch [2912/10000], Train Loss: 0.3207, Val Loss: 0.3834\n",
      "Epoch [2913/10000], Train Loss: 0.3204, Val Loss: 0.3941\n",
      "Epoch [2914/10000], Train Loss: 0.3202, Val Loss: 0.3973\n",
      "Epoch [2915/10000], Train Loss: 0.3209, Val Loss: 0.3847\n",
      "Epoch [2916/10000], Train Loss: 0.3210, Val Loss: 0.3887\n",
      "Epoch [2917/10000], Train Loss: 0.3206, Val Loss: 0.3896\n",
      "Epoch [2918/10000], Train Loss: 0.3206, Val Loss: 0.3929\n",
      "Epoch [2919/10000], Train Loss: 0.3208, Val Loss: 0.3815\n",
      "Epoch [2920/10000], Train Loss: 0.3205, Val Loss: 0.3841\n",
      "Epoch [2921/10000], Train Loss: 0.3210, Val Loss: 0.3780\n",
      "Epoch [2922/10000], Train Loss: 0.3206, Val Loss: 0.3951\n",
      "Epoch [2923/10000], Train Loss: 0.3204, Val Loss: 0.4489\n",
      "Epoch [2924/10000], Train Loss: 0.3208, Val Loss: 0.4931\n",
      "Epoch [2925/10000], Train Loss: 0.3207, Val Loss: 0.3900\n",
      "Epoch [2926/10000], Train Loss: 0.3205, Val Loss: 0.3960\n",
      "Epoch [2927/10000], Train Loss: 0.3204, Val Loss: 0.3997\n",
      "Epoch [2928/10000], Train Loss: 0.3203, Val Loss: 0.3855\n",
      "Epoch [2929/10000], Train Loss: 0.3205, Val Loss: 0.3862\n",
      "Epoch [2930/10000], Train Loss: 0.3208, Val Loss: 0.4179\n",
      "Epoch [2931/10000], Train Loss: 0.3207, Val Loss: 0.3741\n",
      "Epoch [2932/10000], Train Loss: 0.3201, Val Loss: 0.4348\n",
      "Epoch [2933/10000], Train Loss: 0.3210, Val Loss: 0.3922\n",
      "Epoch [2934/10000], Train Loss: 0.3208, Val Loss: 0.3844\n",
      "Epoch [2935/10000], Train Loss: 0.3205, Val Loss: 0.3781\n",
      "Epoch [2936/10000], Train Loss: 0.3201, Val Loss: 0.3855\n",
      "Epoch [2937/10000], Train Loss: 0.3209, Val Loss: 0.3896\n",
      "Epoch [2938/10000], Train Loss: 0.3207, Val Loss: 0.4275\n",
      "Epoch [2939/10000], Train Loss: 0.3205, Val Loss: 0.4121\n",
      "Epoch [2940/10000], Train Loss: 0.3208, Val Loss: 0.4720\n",
      "Epoch [2941/10000], Train Loss: 0.3209, Val Loss: 0.3960\n",
      "Epoch [2942/10000], Train Loss: 0.3204, Val Loss: 0.4399\n",
      "Epoch [2943/10000], Train Loss: 0.3204, Val Loss: 0.3785\n",
      "Epoch [2944/10000], Train Loss: 0.3203, Val Loss: 0.4550\n",
      "Epoch [2945/10000], Train Loss: 0.3205, Val Loss: 0.4113\n",
      "Epoch [2946/10000], Train Loss: 0.3207, Val Loss: 0.3865\n",
      "Epoch [2947/10000], Train Loss: 0.3206, Val Loss: 0.3791\n",
      "Epoch [2948/10000], Train Loss: 0.3205, Val Loss: 0.3916\n",
      "Epoch [2949/10000], Train Loss: 0.3206, Val Loss: 0.3980\n",
      "Epoch [2950/10000], Train Loss: 0.3206, Val Loss: 0.4053\n",
      "Epoch [2951/10000], Train Loss: 0.3207, Val Loss: 0.4106\n",
      "Epoch [2952/10000], Train Loss: 0.3210, Val Loss: 0.3920\n",
      "Epoch [2953/10000], Train Loss: 0.3204, Val Loss: 0.4119\n",
      "Epoch [2954/10000], Train Loss: 0.3205, Val Loss: 0.3881\n",
      "Epoch [2955/10000], Train Loss: 0.3211, Val Loss: 0.4051\n",
      "Epoch [2956/10000], Train Loss: 0.3207, Val Loss: 0.4220\n",
      "Epoch [2957/10000], Train Loss: 0.3204, Val Loss: 0.4442\n",
      "Epoch [2958/10000], Train Loss: 0.3206, Val Loss: 0.3779\n",
      "Epoch [2959/10000], Train Loss: 0.3207, Val Loss: 0.4326\n",
      "Epoch [2960/10000], Train Loss: 0.3208, Val Loss: 0.3798\n",
      "Epoch [2961/10000], Train Loss: 0.3206, Val Loss: 0.4165\n",
      "Epoch [2962/10000], Train Loss: 0.3205, Val Loss: 0.3856\n",
      "Epoch [2963/10000], Train Loss: 0.3208, Val Loss: 0.4013\n",
      "Epoch [2964/10000], Train Loss: 0.3208, Val Loss: 0.3901\n",
      "Epoch [2965/10000], Train Loss: 0.3204, Val Loss: 0.4163\n",
      "Epoch [2966/10000], Train Loss: 0.3202, Val Loss: 0.3982\n",
      "Epoch [2967/10000], Train Loss: 0.3205, Val Loss: 0.3819\n",
      "Epoch [2968/10000], Train Loss: 0.3207, Val Loss: 0.3878\n",
      "Epoch [2969/10000], Train Loss: 0.3204, Val Loss: 0.4100\n",
      "Epoch [2970/10000], Train Loss: 0.3209, Val Loss: 0.4207\n",
      "Epoch [2971/10000], Train Loss: 0.3211, Val Loss: 0.3962\n",
      "Epoch [2972/10000], Train Loss: 0.3206, Val Loss: 0.3799\n",
      "Epoch [2973/10000], Train Loss: 0.3203, Val Loss: 0.4061\n",
      "Epoch [2974/10000], Train Loss: 0.3205, Val Loss: 0.4313\n",
      "Epoch [2975/10000], Train Loss: 0.3206, Val Loss: 0.3858\n",
      "Epoch [2976/10000], Train Loss: 0.3209, Val Loss: 0.3891\n",
      "Epoch [2977/10000], Train Loss: 0.3205, Val Loss: 0.4037\n",
      "Epoch [2978/10000], Train Loss: 0.3206, Val Loss: 0.3799\n",
      "Epoch [2979/10000], Train Loss: 0.3204, Val Loss: 0.4331\n",
      "Epoch [2980/10000], Train Loss: 0.3208, Val Loss: 0.3886\n",
      "Epoch [2981/10000], Train Loss: 0.3205, Val Loss: 0.3799\n",
      "Epoch [2982/10000], Train Loss: 0.3208, Val Loss: 0.3933\n",
      "Epoch [2983/10000], Train Loss: 0.3212, Val Loss: 0.3838\n",
      "Epoch [2984/10000], Train Loss: 0.3209, Val Loss: 0.4074\n",
      "Epoch [2985/10000], Train Loss: 0.3205, Val Loss: 0.4598\n",
      "Epoch [2986/10000], Train Loss: 0.3207, Val Loss: 0.4076\n",
      "Epoch [2987/10000], Train Loss: 0.3206, Val Loss: 0.4891\n",
      "Epoch [2988/10000], Train Loss: 0.3204, Val Loss: 0.3821\n",
      "Epoch [2989/10000], Train Loss: 0.3206, Val Loss: 0.3884\n",
      "Epoch [2990/10000], Train Loss: 0.3206, Val Loss: 0.3908\n",
      "Epoch [2991/10000], Train Loss: 0.3207, Val Loss: 0.3801\n",
      "Epoch [2992/10000], Train Loss: 0.3206, Val Loss: 0.3952\n",
      "Epoch [2993/10000], Train Loss: 0.3207, Val Loss: 0.3761\n",
      "Epoch [2994/10000], Train Loss: 0.3202, Val Loss: 0.4269\n",
      "Epoch [2995/10000], Train Loss: 0.3210, Val Loss: 0.3816\n",
      "Epoch [2996/10000], Train Loss: 0.3208, Val Loss: 0.3957\n",
      "Epoch [2997/10000], Train Loss: 0.3203, Val Loss: 0.3840\n",
      "Epoch [2998/10000], Train Loss: 0.3206, Val Loss: 0.4035\n",
      "Epoch [2999/10000], Train Loss: 0.3203, Val Loss: 0.4038\n",
      "Epoch [3000/10000], Train Loss: 0.3209, Val Loss: 0.3995\n",
      "Epoch [3001/10000], Train Loss: 0.3205, Val Loss: 0.3805\n",
      "Epoch [3002/10000], Train Loss: 0.3206, Val Loss: 0.3798\n",
      "Epoch [3003/10000], Train Loss: 0.3207, Val Loss: 0.4052\n",
      "Epoch [3004/10000], Train Loss: 0.3210, Val Loss: 0.3983\n",
      "Epoch [3005/10000], Train Loss: 0.3206, Val Loss: 0.4024\n",
      "Epoch [3006/10000], Train Loss: 0.3205, Val Loss: 0.3774\n",
      "Epoch [3007/10000], Train Loss: 0.3207, Val Loss: 0.3778\n",
      "Epoch [3008/10000], Train Loss: 0.3202, Val Loss: 0.3821\n",
      "Epoch [3009/10000], Train Loss: 0.3204, Val Loss: 0.3909\n",
      "Epoch [3010/10000], Train Loss: 0.3207, Val Loss: 0.4078\n",
      "Epoch [3011/10000], Train Loss: 0.3209, Val Loss: 0.4276\n",
      "Epoch [3012/10000], Train Loss: 0.3207, Val Loss: 0.4140\n",
      "Epoch [3013/10000], Train Loss: 0.3207, Val Loss: 0.3867\n",
      "Epoch [3014/10000], Train Loss: 0.3209, Val Loss: 0.4468\n",
      "Epoch [3015/10000], Train Loss: 0.3207, Val Loss: 0.3965\n",
      "Epoch [3016/10000], Train Loss: 0.3206, Val Loss: 0.4812\n",
      "Epoch [3017/10000], Train Loss: 0.3208, Val Loss: 0.3952\n",
      "Epoch [3018/10000], Train Loss: 0.3208, Val Loss: 0.3880\n",
      "Epoch [3019/10000], Train Loss: 0.3202, Val Loss: 0.3985\n",
      "Epoch [3020/10000], Train Loss: 0.3202, Val Loss: 0.3756\n",
      "Epoch [3021/10000], Train Loss: 0.3210, Val Loss: 0.3936\n",
      "Epoch [3022/10000], Train Loss: 0.3204, Val Loss: 0.3817\n",
      "Epoch [3023/10000], Train Loss: 0.3203, Val Loss: 0.4031\n",
      "Epoch [3024/10000], Train Loss: 0.3208, Val Loss: 0.3849\n",
      "Epoch [3025/10000], Train Loss: 0.3206, Val Loss: 0.3826\n",
      "Epoch [3026/10000], Train Loss: 0.3209, Val Loss: 0.3802\n",
      "Epoch [3027/10000], Train Loss: 0.3202, Val Loss: 0.3761\n",
      "Epoch [3028/10000], Train Loss: 0.3207, Val Loss: 0.3923\n",
      "Epoch [3029/10000], Train Loss: 0.3208, Val Loss: 0.3758\n",
      "Epoch [3030/10000], Train Loss: 0.3206, Val Loss: 0.3791\n",
      "Epoch [3031/10000], Train Loss: 0.3204, Val Loss: 0.4011\n",
      "Epoch [3032/10000], Train Loss: 0.3208, Val Loss: 0.3771\n",
      "Epoch [3033/10000], Train Loss: 0.3208, Val Loss: 0.3960\n",
      "Epoch [3034/10000], Train Loss: 0.3210, Val Loss: 0.3770\n",
      "Epoch [3035/10000], Train Loss: 0.3204, Val Loss: 0.3871\n",
      "Epoch [3036/10000], Train Loss: 0.3206, Val Loss: 0.3810\n",
      "Epoch [3037/10000], Train Loss: 0.3207, Val Loss: 0.4288\n",
      "Epoch [3038/10000], Train Loss: 0.3206, Val Loss: 0.3798\n",
      "Epoch [3039/10000], Train Loss: 0.3204, Val Loss: 0.3881\n",
      "Epoch [3040/10000], Train Loss: 0.3208, Val Loss: 0.5746\n",
      "Epoch [3041/10000], Train Loss: 0.3208, Val Loss: 0.3986\n",
      "Epoch [3042/10000], Train Loss: 0.3205, Val Loss: 0.4902\n",
      "Epoch [3043/10000], Train Loss: 0.3207, Val Loss: 0.3782\n",
      "Epoch [3044/10000], Train Loss: 0.3206, Val Loss: 0.3775\n",
      "Epoch [3045/10000], Train Loss: 0.3206, Val Loss: 0.4810\n",
      "Epoch [3046/10000], Train Loss: 0.3206, Val Loss: 0.3833\n",
      "Epoch [3047/10000], Train Loss: 0.3204, Val Loss: 0.3941\n",
      "Epoch [3048/10000], Train Loss: 0.3208, Val Loss: 0.3846\n",
      "Epoch [3049/10000], Train Loss: 0.3207, Val Loss: 0.3820\n",
      "Epoch [3050/10000], Train Loss: 0.3208, Val Loss: 0.3811\n",
      "Epoch [3051/10000], Train Loss: 0.3205, Val Loss: 0.3832\n",
      "Epoch [3052/10000], Train Loss: 0.3205, Val Loss: 0.4029\n",
      "Epoch [3053/10000], Train Loss: 0.3207, Val Loss: 0.3958\n",
      "Epoch [3054/10000], Train Loss: 0.3208, Val Loss: 0.3954\n",
      "Epoch [3055/10000], Train Loss: 0.3208, Val Loss: 0.4151\n",
      "Epoch [3056/10000], Train Loss: 0.3211, Val Loss: 0.3889\n",
      "Epoch [3057/10000], Train Loss: 0.3206, Val Loss: 0.3935\n",
      "Epoch [3058/10000], Train Loss: 0.3207, Val Loss: 0.3840\n",
      "Epoch [3059/10000], Train Loss: 0.3203, Val Loss: 0.3903\n",
      "Epoch [3060/10000], Train Loss: 0.3208, Val Loss: 0.3794\n",
      "Epoch [3061/10000], Train Loss: 0.3206, Val Loss: 0.3930\n",
      "Epoch [3062/10000], Train Loss: 0.3205, Val Loss: 0.3831\n",
      "Epoch [3063/10000], Train Loss: 0.3205, Val Loss: 0.3783\n",
      "Epoch [3064/10000], Train Loss: 0.3206, Val Loss: 0.4827\n",
      "Epoch [3065/10000], Train Loss: 0.3207, Val Loss: 0.3957\n",
      "Epoch [3066/10000], Train Loss: 0.3208, Val Loss: 0.4214\n",
      "Epoch [3067/10000], Train Loss: 0.3214, Val Loss: 0.3756\n",
      "Epoch [3068/10000], Train Loss: 0.3205, Val Loss: 0.4146\n",
      "Epoch [3069/10000], Train Loss: 0.3203, Val Loss: 0.4180\n",
      "Epoch [3070/10000], Train Loss: 0.3207, Val Loss: 0.4225\n",
      "Epoch [3071/10000], Train Loss: 0.3204, Val Loss: 0.3807\n",
      "Epoch [3072/10000], Train Loss: 0.3205, Val Loss: 0.3797\n",
      "Epoch [3073/10000], Train Loss: 0.3208, Val Loss: 0.3760\n",
      "Epoch [3074/10000], Train Loss: 0.3206, Val Loss: 0.4325\n",
      "Epoch [3075/10000], Train Loss: 0.3206, Val Loss: 0.3997\n",
      "Epoch [3076/10000], Train Loss: 0.3206, Val Loss: 0.4052\n",
      "Epoch [3077/10000], Train Loss: 0.3207, Val Loss: 0.4454\n",
      "Epoch [3078/10000], Train Loss: 0.3205, Val Loss: 0.3954\n",
      "Epoch [3079/10000], Train Loss: 0.3205, Val Loss: 0.3875\n",
      "Epoch [3080/10000], Train Loss: 0.3208, Val Loss: 0.3839\n",
      "Epoch [3081/10000], Train Loss: 0.3201, Val Loss: 0.3758\n",
      "Epoch [3082/10000], Train Loss: 0.3207, Val Loss: 0.3874\n",
      "Epoch [3083/10000], Train Loss: 0.3206, Val Loss: 0.4098\n",
      "Epoch [3084/10000], Train Loss: 0.3206, Val Loss: 0.3777\n",
      "Epoch [3085/10000], Train Loss: 0.3204, Val Loss: 0.3784\n",
      "Epoch [3086/10000], Train Loss: 0.3204, Val Loss: 0.3997\n",
      "Epoch [3087/10000], Train Loss: 0.3202, Val Loss: 0.3898\n",
      "Epoch [3088/10000], Train Loss: 0.3204, Val Loss: 0.3822\n",
      "Epoch [3089/10000], Train Loss: 0.3202, Val Loss: 0.3907\n",
      "Epoch [3090/10000], Train Loss: 0.3209, Val Loss: 0.3966\n",
      "Epoch [3091/10000], Train Loss: 0.3205, Val Loss: 0.4108\n",
      "Epoch [3092/10000], Train Loss: 0.3208, Val Loss: 0.4446\n",
      "Epoch [3093/10000], Train Loss: 0.3204, Val Loss: 0.4052\n",
      "Epoch [3094/10000], Train Loss: 0.3212, Val Loss: 0.3838\n",
      "Epoch [3095/10000], Train Loss: 0.3205, Val Loss: 0.3908\n",
      "Epoch [3096/10000], Train Loss: 0.3205, Val Loss: 0.3946\n",
      "Epoch [3097/10000], Train Loss: 0.3210, Val Loss: 0.3850\n",
      "Epoch [3098/10000], Train Loss: 0.3202, Val Loss: 0.3971\n",
      "Epoch [3099/10000], Train Loss: 0.3206, Val Loss: 0.3845\n",
      "Epoch [3100/10000], Train Loss: 0.3207, Val Loss: 0.4492\n",
      "Epoch [3101/10000], Train Loss: 0.3206, Val Loss: 0.3794\n",
      "Epoch [3102/10000], Train Loss: 0.3207, Val Loss: 0.3839\n",
      "Epoch [3103/10000], Train Loss: 0.3207, Val Loss: 0.3942\n",
      "Epoch [3104/10000], Train Loss: 0.3207, Val Loss: 0.4115\n",
      "Epoch [3105/10000], Train Loss: 0.3207, Val Loss: 0.3809\n",
      "Epoch [3106/10000], Train Loss: 0.3206, Val Loss: 0.3890\n",
      "Epoch [3107/10000], Train Loss: 0.3207, Val Loss: 0.3774\n",
      "Epoch [3108/10000], Train Loss: 0.3208, Val Loss: 0.3879\n",
      "Epoch [3109/10000], Train Loss: 0.3206, Val Loss: 0.3851\n",
      "Epoch [3110/10000], Train Loss: 0.3205, Val Loss: 0.3949\n",
      "Epoch [3111/10000], Train Loss: 0.3205, Val Loss: 0.4083\n",
      "Epoch [3112/10000], Train Loss: 0.3206, Val Loss: 0.3988\n",
      "Epoch [3113/10000], Train Loss: 0.3207, Val Loss: 0.4010\n",
      "Epoch [3114/10000], Train Loss: 0.3206, Val Loss: 0.3771\n",
      "Epoch [3115/10000], Train Loss: 0.3205, Val Loss: 0.3940\n",
      "Epoch [3116/10000], Train Loss: 0.3206, Val Loss: 0.3764\n",
      "Epoch [3117/10000], Train Loss: 0.3201, Val Loss: 0.3953\n",
      "Epoch [3118/10000], Train Loss: 0.3205, Val Loss: 0.3969\n",
      "Epoch [3119/10000], Train Loss: 0.3208, Val Loss: 0.3791\n",
      "Epoch [3120/10000], Train Loss: 0.3206, Val Loss: 0.3985\n",
      "Epoch [3121/10000], Train Loss: 0.3206, Val Loss: 0.3837\n",
      "Epoch [3122/10000], Train Loss: 0.3206, Val Loss: 0.3798\n",
      "Epoch [3123/10000], Train Loss: 0.3208, Val Loss: 0.5054\n",
      "Epoch [3124/10000], Train Loss: 0.3204, Val Loss: 0.3844\n",
      "Epoch [3125/10000], Train Loss: 0.3208, Val Loss: 0.3809\n",
      "Epoch [3126/10000], Train Loss: 0.3209, Val Loss: 0.4722\n",
      "Epoch [3127/10000], Train Loss: 0.3208, Val Loss: 0.3850\n",
      "Epoch [3128/10000], Train Loss: 0.3207, Val Loss: 0.3743\n",
      "Epoch [3129/10000], Train Loss: 0.3209, Val Loss: 0.3915\n",
      "Epoch [3130/10000], Train Loss: 0.3208, Val Loss: 0.3776\n",
      "Epoch [3131/10000], Train Loss: 0.3206, Val Loss: 0.3813\n",
      "Epoch [3132/10000], Train Loss: 0.3205, Val Loss: 0.4085\n",
      "Epoch [3133/10000], Train Loss: 0.3207, Val Loss: 0.3864\n",
      "Epoch [3134/10000], Train Loss: 0.3208, Val Loss: 0.3916\n",
      "Epoch [3135/10000], Train Loss: 0.3204, Val Loss: 0.3951\n",
      "Epoch [3136/10000], Train Loss: 0.3206, Val Loss: 0.3834\n",
      "Epoch [3137/10000], Train Loss: 0.3204, Val Loss: 0.3771\n",
      "Epoch [3138/10000], Train Loss: 0.3206, Val Loss: 0.4251\n",
      "Epoch [3139/10000], Train Loss: 0.3208, Val Loss: 0.3991\n",
      "Epoch [3140/10000], Train Loss: 0.3202, Val Loss: 0.3802\n",
      "Epoch [3141/10000], Train Loss: 0.3204, Val Loss: 0.4025\n",
      "Epoch [3142/10000], Train Loss: 0.3208, Val Loss: 0.5085\n",
      "Epoch [3143/10000], Train Loss: 0.3205, Val Loss: 0.3815\n",
      "Epoch [3144/10000], Train Loss: 0.3206, Val Loss: 0.3788\n",
      "Epoch [3145/10000], Train Loss: 0.3202, Val Loss: 0.4018\n",
      "Epoch [3146/10000], Train Loss: 0.3202, Val Loss: 0.3962\n",
      "Epoch [3147/10000], Train Loss: 0.3207, Val Loss: 0.3800\n",
      "Epoch [3148/10000], Train Loss: 0.3204, Val Loss: 0.4154\n",
      "Epoch [3149/10000], Train Loss: 0.3205, Val Loss: 0.4137\n",
      "Epoch [3150/10000], Train Loss: 0.3205, Val Loss: 0.3890\n",
      "Epoch [3151/10000], Train Loss: 0.3206, Val Loss: 0.3894\n",
      "Epoch [3152/10000], Train Loss: 0.3206, Val Loss: 0.3797\n",
      "Epoch [3153/10000], Train Loss: 0.3198, Val Loss: 0.3893\n",
      "Epoch [3154/10000], Train Loss: 0.3208, Val Loss: 0.3764\n",
      "Epoch [3155/10000], Train Loss: 0.3205, Val Loss: 0.4060\n",
      "Epoch [3156/10000], Train Loss: 0.3205, Val Loss: 0.3802\n",
      "Epoch [3157/10000], Train Loss: 0.3206, Val Loss: 0.3840\n",
      "Epoch [3158/10000], Train Loss: 0.3205, Val Loss: 0.3983\n",
      "Epoch [3159/10000], Train Loss: 0.3202, Val Loss: 0.3908\n",
      "Epoch [3160/10000], Train Loss: 0.3206, Val Loss: 0.3815\n",
      "Epoch [3161/10000], Train Loss: 0.3206, Val Loss: 0.3822\n",
      "Epoch [3162/10000], Train Loss: 0.3205, Val Loss: 0.3914\n",
      "Epoch [3163/10000], Train Loss: 0.3206, Val Loss: 0.3830\n",
      "Epoch [3164/10000], Train Loss: 0.3203, Val Loss: 0.4033\n",
      "Epoch [3165/10000], Train Loss: 0.3210, Val Loss: 0.4123\n",
      "Epoch [3166/10000], Train Loss: 0.3204, Val Loss: 0.3848\n",
      "Epoch [3167/10000], Train Loss: 0.3209, Val Loss: 0.3898\n",
      "Epoch [3168/10000], Train Loss: 0.3206, Val Loss: 0.3999\n",
      "Epoch [3169/10000], Train Loss: 0.3208, Val Loss: 0.3906\n",
      "Epoch [3170/10000], Train Loss: 0.3204, Val Loss: 0.3952\n",
      "Epoch [3171/10000], Train Loss: 0.3204, Val Loss: 0.4158\n",
      "Epoch [3172/10000], Train Loss: 0.3207, Val Loss: 0.3997\n",
      "Epoch [3173/10000], Train Loss: 0.3205, Val Loss: 0.4526\n",
      "Epoch [3174/10000], Train Loss: 0.3211, Val Loss: 0.3799\n",
      "Epoch [3175/10000], Train Loss: 0.3204, Val Loss: 0.3860\n",
      "Epoch [3176/10000], Train Loss: 0.3205, Val Loss: 0.3749\n",
      "Epoch [3177/10000], Train Loss: 0.3204, Val Loss: 0.3883\n",
      "Epoch [3178/10000], Train Loss: 0.3204, Val Loss: 0.3888\n",
      "Epoch [3179/10000], Train Loss: 0.3206, Val Loss: 0.3813\n",
      "Epoch [3180/10000], Train Loss: 0.3205, Val Loss: 0.3867\n",
      "Epoch [3181/10000], Train Loss: 0.3206, Val Loss: 0.3997\n",
      "Epoch [3182/10000], Train Loss: 0.3206, Val Loss: 0.3857\n",
      "Epoch [3183/10000], Train Loss: 0.3204, Val Loss: 0.3901\n",
      "Epoch [3184/10000], Train Loss: 0.3207, Val Loss: 0.3956\n",
      "Epoch [3185/10000], Train Loss: 0.3206, Val Loss: 0.4182\n",
      "Epoch [3186/10000], Train Loss: 0.3208, Val Loss: 0.4090\n",
      "Epoch [3187/10000], Train Loss: 0.3208, Val Loss: 0.3810\n",
      "Epoch [3188/10000], Train Loss: 0.3206, Val Loss: 0.4062\n",
      "Epoch [3189/10000], Train Loss: 0.3207, Val Loss: 0.4249\n",
      "Epoch [3190/10000], Train Loss: 0.3205, Val Loss: 0.3858\n",
      "Epoch [3191/10000], Train Loss: 0.3205, Val Loss: 0.3937\n",
      "Epoch [3192/10000], Train Loss: 0.3203, Val Loss: 0.3912\n",
      "Epoch [3193/10000], Train Loss: 0.3206, Val Loss: 0.3913\n",
      "Epoch [3194/10000], Train Loss: 0.3209, Val Loss: 0.3809\n",
      "Epoch [3195/10000], Train Loss: 0.3210, Val Loss: 0.3934\n",
      "Epoch [3196/10000], Train Loss: 0.3208, Val Loss: 0.4248\n",
      "Epoch [3197/10000], Train Loss: 0.3206, Val Loss: 0.4231\n",
      "Epoch [3198/10000], Train Loss: 0.3206, Val Loss: 0.4021\n",
      "Epoch [3199/10000], Train Loss: 0.3204, Val Loss: 0.4304\n",
      "Epoch [3200/10000], Train Loss: 0.3209, Val Loss: 0.6346\n",
      "Epoch [3201/10000], Train Loss: 0.3203, Val Loss: 0.3947\n",
      "Epoch [3202/10000], Train Loss: 0.3210, Val Loss: 0.3871\n",
      "Epoch [3203/10000], Train Loss: 0.3206, Val Loss: 0.3823\n",
      "Epoch [3204/10000], Train Loss: 0.3206, Val Loss: 0.4252\n",
      "Epoch [3205/10000], Train Loss: 0.3206, Val Loss: 0.4069\n",
      "Epoch [3206/10000], Train Loss: 0.3208, Val Loss: 0.3849\n",
      "Epoch [3207/10000], Train Loss: 0.3207, Val Loss: 0.3858\n",
      "Epoch [3208/10000], Train Loss: 0.3209, Val Loss: 0.4661\n",
      "Epoch [3209/10000], Train Loss: 0.3204, Val Loss: 0.4631\n",
      "Epoch [3210/10000], Train Loss: 0.3206, Val Loss: 0.4329\n",
      "Epoch [3211/10000], Train Loss: 0.3205, Val Loss: 0.3962\n",
      "Epoch [3212/10000], Train Loss: 0.3208, Val Loss: 0.3888\n",
      "Epoch [3213/10000], Train Loss: 0.3206, Val Loss: 0.3955\n",
      "Epoch [3214/10000], Train Loss: 0.3205, Val Loss: 0.3925\n",
      "Epoch [3215/10000], Train Loss: 0.3203, Val Loss: 0.3817\n",
      "Epoch [3216/10000], Train Loss: 0.3206, Val Loss: 0.4443\n",
      "Epoch [3217/10000], Train Loss: 0.3204, Val Loss: 0.3938\n",
      "Epoch [3218/10000], Train Loss: 0.3205, Val Loss: 0.3865\n",
      "Epoch [3219/10000], Train Loss: 0.3202, Val Loss: 0.3844\n",
      "Epoch [3220/10000], Train Loss: 0.3203, Val Loss: 0.3783\n",
      "Epoch [3221/10000], Train Loss: 0.3209, Val Loss: 0.4432\n",
      "Epoch [3222/10000], Train Loss: 0.3212, Val Loss: 0.3892\n",
      "Epoch [3223/10000], Train Loss: 0.3204, Val Loss: 0.3848\n",
      "Epoch [3224/10000], Train Loss: 0.3209, Val Loss: 0.3888\n",
      "Epoch [3225/10000], Train Loss: 0.3200, Val Loss: 0.3815\n",
      "Epoch [3226/10000], Train Loss: 0.3206, Val Loss: 0.3847\n",
      "Epoch [3227/10000], Train Loss: 0.3207, Val Loss: 0.3960\n",
      "Epoch [3228/10000], Train Loss: 0.3206, Val Loss: 0.4287\n",
      "Epoch [3229/10000], Train Loss: 0.3204, Val Loss: 0.3799\n",
      "Epoch [3230/10000], Train Loss: 0.3208, Val Loss: 0.3928\n",
      "Epoch [3231/10000], Train Loss: 0.3204, Val Loss: 0.3887\n",
      "Epoch [3232/10000], Train Loss: 0.3206, Val Loss: 0.4330\n",
      "Epoch [3233/10000], Train Loss: 0.3206, Val Loss: 0.3931\n",
      "Epoch [3234/10000], Train Loss: 0.3207, Val Loss: 0.3855\n",
      "Epoch [3235/10000], Train Loss: 0.3210, Val Loss: 0.3960\n",
      "Epoch [3236/10000], Train Loss: 0.3205, Val Loss: 0.4431\n",
      "Epoch [3237/10000], Train Loss: 0.3206, Val Loss: 0.3833\n",
      "Epoch [3238/10000], Train Loss: 0.3203, Val Loss: 0.3911\n",
      "Epoch [3239/10000], Train Loss: 0.3205, Val Loss: 0.3772\n",
      "Epoch [3240/10000], Train Loss: 0.3206, Val Loss: 0.3794\n",
      "Epoch [3241/10000], Train Loss: 0.3204, Val Loss: 0.4190\n",
      "Epoch [3242/10000], Train Loss: 0.3203, Val Loss: 0.3792\n",
      "Epoch [3243/10000], Train Loss: 0.3210, Val Loss: 0.4210\n",
      "Epoch [3244/10000], Train Loss: 0.3206, Val Loss: 0.3914\n",
      "Epoch [3245/10000], Train Loss: 0.3205, Val Loss: 0.3768\n",
      "Epoch [3246/10000], Train Loss: 0.3205, Val Loss: 0.3860\n",
      "Epoch [3247/10000], Train Loss: 0.3202, Val Loss: 0.3906\n",
      "Epoch [3248/10000], Train Loss: 0.3201, Val Loss: 0.3930\n",
      "Epoch [3249/10000], Train Loss: 0.3208, Val Loss: 0.3921\n",
      "Epoch [3250/10000], Train Loss: 0.3202, Val Loss: 0.3887\n",
      "Epoch [3251/10000], Train Loss: 0.3206, Val Loss: 0.3803\n",
      "Epoch [3252/10000], Train Loss: 0.3206, Val Loss: 0.3919\n",
      "Epoch [3253/10000], Train Loss: 0.3205, Val Loss: 0.3956\n",
      "Epoch [3254/10000], Train Loss: 0.3205, Val Loss: 0.4062\n",
      "Epoch [3255/10000], Train Loss: 0.3202, Val Loss: 0.4030\n",
      "Epoch [3256/10000], Train Loss: 0.3204, Val Loss: 0.3819\n",
      "Epoch [3257/10000], Train Loss: 0.3206, Val Loss: 0.3854\n",
      "Epoch [3258/10000], Train Loss: 0.3204, Val Loss: 0.3908\n",
      "Epoch [3259/10000], Train Loss: 0.3209, Val Loss: 0.4485\n",
      "Epoch [3260/10000], Train Loss: 0.3204, Val Loss: 0.4148\n",
      "Epoch [3261/10000], Train Loss: 0.3203, Val Loss: 0.3780\n",
      "Epoch [3262/10000], Train Loss: 0.3206, Val Loss: 0.3759\n",
      "Epoch [3263/10000], Train Loss: 0.3205, Val Loss: 0.4093\n",
      "Epoch [3264/10000], Train Loss: 0.3205, Val Loss: 0.3864\n",
      "Epoch [3265/10000], Train Loss: 0.3207, Val Loss: 0.3882\n",
      "Epoch [3266/10000], Train Loss: 0.3211, Val Loss: 0.4052\n",
      "Epoch [3267/10000], Train Loss: 0.3208, Val Loss: 0.3820\n",
      "Epoch [3268/10000], Train Loss: 0.3207, Val Loss: 0.3829\n",
      "Epoch [3269/10000], Train Loss: 0.3205, Val Loss: 0.3796\n",
      "Epoch [3270/10000], Train Loss: 0.3208, Val Loss: 0.3898\n",
      "Epoch [3271/10000], Train Loss: 0.3205, Val Loss: 0.3827\n",
      "Epoch [3272/10000], Train Loss: 0.3209, Val Loss: 0.3918\n",
      "Epoch [3273/10000], Train Loss: 0.3205, Val Loss: 0.4070\n",
      "Epoch [3274/10000], Train Loss: 0.3206, Val Loss: 0.4118\n",
      "Epoch [3275/10000], Train Loss: 0.3202, Val Loss: 0.4882\n",
      "Epoch [3276/10000], Train Loss: 0.3204, Val Loss: 0.4025\n",
      "Epoch [3277/10000], Train Loss: 0.3204, Val Loss: 0.3931\n",
      "Epoch [3278/10000], Train Loss: 0.3209, Val Loss: 0.3800\n",
      "Epoch [3279/10000], Train Loss: 0.3204, Val Loss: 0.3883\n",
      "Epoch [3280/10000], Train Loss: 0.3209, Val Loss: 0.3914\n",
      "Epoch [3281/10000], Train Loss: 0.3206, Val Loss: 0.3960\n",
      "Epoch [3282/10000], Train Loss: 0.3205, Val Loss: 0.3829\n",
      "Epoch [3283/10000], Train Loss: 0.3208, Val Loss: 0.3840\n",
      "Epoch [3284/10000], Train Loss: 0.3205, Val Loss: 0.3813\n",
      "Epoch [3285/10000], Train Loss: 0.3205, Val Loss: 0.3916\n",
      "Epoch [3286/10000], Train Loss: 0.3207, Val Loss: 0.3970\n",
      "Epoch [3287/10000], Train Loss: 0.3207, Val Loss: 0.4025\n",
      "Epoch [3288/10000], Train Loss: 0.3202, Val Loss: 0.3888\n",
      "Epoch [3289/10000], Train Loss: 0.3201, Val Loss: 0.3959\n",
      "Epoch [3290/10000], Train Loss: 0.3206, Val Loss: 0.3756\n",
      "Epoch [3291/10000], Train Loss: 0.3201, Val Loss: 0.3864\n",
      "Epoch [3292/10000], Train Loss: 0.3206, Val Loss: 0.3896\n",
      "Epoch [3293/10000], Train Loss: 0.3206, Val Loss: 0.4669\n",
      "Epoch [3294/10000], Train Loss: 0.3204, Val Loss: 0.4048\n",
      "Epoch [3295/10000], Train Loss: 0.3205, Val Loss: 0.3768\n",
      "Epoch [3296/10000], Train Loss: 0.3209, Val Loss: 0.4197\n",
      "Epoch [3297/10000], Train Loss: 0.3205, Val Loss: 0.3839\n",
      "Epoch [3298/10000], Train Loss: 0.3210, Val Loss: 0.3834\n",
      "Epoch [3299/10000], Train Loss: 0.3206, Val Loss: 0.4163\n",
      "Epoch [3300/10000], Train Loss: 0.3203, Val Loss: 0.3835\n",
      "Epoch [3301/10000], Train Loss: 0.3205, Val Loss: 0.3806\n",
      "Epoch [3302/10000], Train Loss: 0.3210, Val Loss: 0.3948\n",
      "Epoch [3303/10000], Train Loss: 0.3206, Val Loss: 0.3944\n",
      "Epoch [3304/10000], Train Loss: 0.3206, Val Loss: 0.4057\n",
      "Epoch [3305/10000], Train Loss: 0.3204, Val Loss: 0.4204\n",
      "Epoch [3306/10000], Train Loss: 0.3204, Val Loss: 0.3930\n",
      "Epoch [3307/10000], Train Loss: 0.3211, Val Loss: 0.3782\n",
      "Epoch [3308/10000], Train Loss: 0.3204, Val Loss: 0.3909\n",
      "Epoch [3309/10000], Train Loss: 0.3200, Val Loss: 0.4347\n",
      "Epoch [3310/10000], Train Loss: 0.3209, Val Loss: 0.4217\n",
      "Epoch [3311/10000], Train Loss: 0.3205, Val Loss: 0.4153\n",
      "Epoch [3312/10000], Train Loss: 0.3207, Val Loss: 0.3986\n",
      "Epoch [3313/10000], Train Loss: 0.3204, Val Loss: 0.3903\n",
      "Epoch [3314/10000], Train Loss: 0.3207, Val Loss: 0.3918\n",
      "Epoch [3315/10000], Train Loss: 0.3202, Val Loss: 0.4046\n",
      "Epoch [3316/10000], Train Loss: 0.3210, Val Loss: 0.4150\n",
      "Epoch [3317/10000], Train Loss: 0.3204, Val Loss: 0.3924\n",
      "Epoch [3318/10000], Train Loss: 0.3209, Val Loss: 0.3961\n",
      "Epoch [3319/10000], Train Loss: 0.3205, Val Loss: 0.3851\n",
      "Epoch [3320/10000], Train Loss: 0.3206, Val Loss: 0.3876\n",
      "Epoch [3321/10000], Train Loss: 0.3204, Val Loss: 0.4029\n",
      "Epoch [3322/10000], Train Loss: 0.3206, Val Loss: 0.3980\n",
      "Epoch [3323/10000], Train Loss: 0.3203, Val Loss: 0.4052\n",
      "Epoch [3324/10000], Train Loss: 0.3202, Val Loss: 0.3949\n",
      "Epoch [3325/10000], Train Loss: 0.3205, Val Loss: 0.3869\n",
      "Epoch [3326/10000], Train Loss: 0.3205, Val Loss: 0.3801\n",
      "Epoch [3327/10000], Train Loss: 0.3209, Val Loss: 0.3914\n",
      "Epoch [3328/10000], Train Loss: 0.3204, Val Loss: 0.3830\n",
      "Epoch [3329/10000], Train Loss: 0.3205, Val Loss: 0.3816\n",
      "Epoch [3330/10000], Train Loss: 0.3205, Val Loss: 0.3961\n",
      "Epoch [3331/10000], Train Loss: 0.3202, Val Loss: 0.3777\n",
      "Epoch [3332/10000], Train Loss: 0.3206, Val Loss: 0.3887\n",
      "Epoch [3333/10000], Train Loss: 0.3206, Val Loss: 0.3877\n",
      "Epoch [3334/10000], Train Loss: 0.3209, Val Loss: 0.3985\n",
      "Epoch [3335/10000], Train Loss: 0.3207, Val Loss: 0.4538\n",
      "Epoch [3336/10000], Train Loss: 0.3210, Val Loss: 0.3866\n",
      "Epoch [3337/10000], Train Loss: 0.3203, Val Loss: 0.3801\n",
      "Epoch [3338/10000], Train Loss: 0.3205, Val Loss: 0.3772\n",
      "Epoch [3339/10000], Train Loss: 0.3203, Val Loss: 0.4136\n",
      "Epoch [3340/10000], Train Loss: 0.3205, Val Loss: 0.3735\n",
      "Validation loss improved from 0.3738 to 0.3735. Saving model...\n",
      "Epoch [3341/10000], Train Loss: 0.3208, Val Loss: 0.3874\n",
      "Epoch [3342/10000], Train Loss: 0.3205, Val Loss: 0.3940\n",
      "Epoch [3343/10000], Train Loss: 0.3204, Val Loss: 0.3789\n",
      "Epoch [3344/10000], Train Loss: 0.3205, Val Loss: 0.4345\n",
      "Epoch [3345/10000], Train Loss: 0.3202, Val Loss: 0.4247\n",
      "Epoch [3346/10000], Train Loss: 0.3203, Val Loss: 0.3988\n",
      "Epoch [3347/10000], Train Loss: 0.3202, Val Loss: 0.3847\n",
      "Epoch [3348/10000], Train Loss: 0.3204, Val Loss: 0.3886\n",
      "Epoch [3349/10000], Train Loss: 0.3207, Val Loss: 0.3883\n",
      "Epoch [3350/10000], Train Loss: 0.3203, Val Loss: 0.3909\n",
      "Epoch [3351/10000], Train Loss: 0.3207, Val Loss: 0.4012\n",
      "Epoch [3352/10000], Train Loss: 0.3207, Val Loss: 0.4192\n",
      "Epoch [3353/10000], Train Loss: 0.3207, Val Loss: 0.3845\n",
      "Epoch [3354/10000], Train Loss: 0.3206, Val Loss: 0.3897\n",
      "Epoch [3355/10000], Train Loss: 0.3204, Val Loss: 0.3910\n",
      "Epoch [3356/10000], Train Loss: 0.3212, Val Loss: 0.3776\n",
      "Epoch [3357/10000], Train Loss: 0.3204, Val Loss: 0.3926\n",
      "Epoch [3358/10000], Train Loss: 0.3205, Val Loss: 0.3794\n",
      "Epoch [3359/10000], Train Loss: 0.3203, Val Loss: 0.4241\n",
      "Epoch [3360/10000], Train Loss: 0.3208, Val Loss: 0.3820\n",
      "Epoch [3361/10000], Train Loss: 0.3204, Val Loss: 0.3777\n",
      "Epoch [3362/10000], Train Loss: 0.3203, Val Loss: 0.3894\n",
      "Epoch [3363/10000], Train Loss: 0.3203, Val Loss: 0.3904\n",
      "Epoch [3364/10000], Train Loss: 0.3204, Val Loss: 0.3828\n",
      "Epoch [3365/10000], Train Loss: 0.3206, Val Loss: 0.3793\n",
      "Epoch [3366/10000], Train Loss: 0.3208, Val Loss: 0.3814\n",
      "Epoch [3367/10000], Train Loss: 0.3206, Val Loss: 0.3762\n",
      "Epoch [3368/10000], Train Loss: 0.3207, Val Loss: 0.3809\n",
      "Epoch [3369/10000], Train Loss: 0.3206, Val Loss: 0.3899\n",
      "Epoch [3370/10000], Train Loss: 0.3202, Val Loss: 0.4010\n",
      "Epoch [3371/10000], Train Loss: 0.3204, Val Loss: 0.4043\n",
      "Epoch [3372/10000], Train Loss: 0.3204, Val Loss: 0.4573\n",
      "Epoch [3373/10000], Train Loss: 0.5396, Val Loss: 1.5868\n",
      "Epoch [3374/10000], Train Loss: 0.5563, Val Loss: 1.4777\n",
      "Epoch [3375/10000], Train Loss: 0.5376, Val Loss: 1.3412\n",
      "Epoch [3376/10000], Train Loss: 0.4927, Val Loss: 1.0498\n",
      "Epoch [3377/10000], Train Loss: 0.4394, Val Loss: 0.8333\n",
      "Epoch [3378/10000], Train Loss: 0.3857, Val Loss: 0.4398\n",
      "Epoch [3379/10000], Train Loss: 0.3259, Val Loss: 0.3896\n",
      "Epoch [3380/10000], Train Loss: 0.3238, Val Loss: 0.3872\n",
      "Epoch [3381/10000], Train Loss: 0.3236, Val Loss: 0.3863\n",
      "Epoch [3382/10000], Train Loss: 0.3228, Val Loss: 0.3982\n",
      "Epoch [3383/10000], Train Loss: 0.3212, Val Loss: 0.3999\n",
      "Epoch [3384/10000], Train Loss: 0.3208, Val Loss: 0.3954\n",
      "Epoch [3385/10000], Train Loss: 0.3205, Val Loss: 0.3853\n",
      "Epoch [3386/10000], Train Loss: 0.3209, Val Loss: 0.3809\n",
      "Epoch [3387/10000], Train Loss: 0.3202, Val Loss: 0.4116\n",
      "Epoch [3388/10000], Train Loss: 0.3208, Val Loss: 0.3978\n",
      "Epoch [3389/10000], Train Loss: 0.3202, Val Loss: 0.4319\n",
      "Epoch [3390/10000], Train Loss: 0.3208, Val Loss: 0.3857\n",
      "Epoch [3391/10000], Train Loss: 0.3206, Val Loss: 0.3806\n",
      "Epoch [3392/10000], Train Loss: 0.3204, Val Loss: 0.3892\n",
      "Epoch [3393/10000], Train Loss: 0.3207, Val Loss: 0.4237\n",
      "Epoch [3394/10000], Train Loss: 0.3210, Val Loss: 0.4174\n",
      "Epoch [3395/10000], Train Loss: 0.3209, Val Loss: 0.3808\n",
      "Epoch [3396/10000], Train Loss: 0.3205, Val Loss: 0.3955\n",
      "Epoch [3397/10000], Train Loss: 0.3207, Val Loss: 0.3815\n",
      "Epoch [3398/10000], Train Loss: 0.3208, Val Loss: 0.3799\n",
      "Epoch [3399/10000], Train Loss: 0.3202, Val Loss: 0.3844\n",
      "Epoch [3400/10000], Train Loss: 0.3205, Val Loss: 0.3900\n",
      "Epoch [3401/10000], Train Loss: 0.3206, Val Loss: 0.4280\n",
      "Epoch [3402/10000], Train Loss: 0.3202, Val Loss: 0.3799\n",
      "Epoch [3403/10000], Train Loss: 0.3204, Val Loss: 0.4233\n",
      "Epoch [3404/10000], Train Loss: 0.3200, Val Loss: 0.4146\n",
      "Epoch [3405/10000], Train Loss: 0.3203, Val Loss: 0.3915\n",
      "Epoch [3406/10000], Train Loss: 0.3206, Val Loss: 0.3748\n",
      "Epoch [3407/10000], Train Loss: 0.3206, Val Loss: 0.4479\n",
      "Epoch [3408/10000], Train Loss: 0.3204, Val Loss: 0.4436\n",
      "Epoch [3409/10000], Train Loss: 0.3206, Val Loss: 0.3951\n",
      "Epoch [3410/10000], Train Loss: 0.3209, Val Loss: 0.3836\n",
      "Epoch [3411/10000], Train Loss: 0.3207, Val Loss: 0.3828\n",
      "Epoch [3412/10000], Train Loss: 0.3206, Val Loss: 0.4075\n",
      "Epoch [3413/10000], Train Loss: 0.3211, Val Loss: 0.4102\n",
      "Epoch [3414/10000], Train Loss: 0.3207, Val Loss: 0.3914\n",
      "Epoch [3415/10000], Train Loss: 0.3209, Val Loss: 0.3953\n",
      "Epoch [3416/10000], Train Loss: 0.3205, Val Loss: 0.3826\n",
      "Epoch [3417/10000], Train Loss: 0.3208, Val Loss: 0.3817\n",
      "Epoch [3418/10000], Train Loss: 0.3205, Val Loss: 0.3874\n",
      "Epoch [3419/10000], Train Loss: 0.3205, Val Loss: 0.4036\n",
      "Epoch [3420/10000], Train Loss: 0.3202, Val Loss: 0.4758\n",
      "Epoch [3421/10000], Train Loss: 0.3206, Val Loss: 0.4185\n",
      "Epoch [3422/10000], Train Loss: 0.3206, Val Loss: 0.3797\n",
      "Epoch [3423/10000], Train Loss: 0.3201, Val Loss: 0.4157\n",
      "Epoch [3424/10000], Train Loss: 0.3207, Val Loss: 0.3774\n",
      "Epoch [3425/10000], Train Loss: 0.3206, Val Loss: 0.3818\n",
      "Epoch [3426/10000], Train Loss: 0.3282, Val Loss: 0.4643\n",
      "Epoch [3427/10000], Train Loss: 0.3255, Val Loss: 0.4254\n",
      "Epoch [3428/10000], Train Loss: 0.3213, Val Loss: 0.3880\n",
      "Epoch [3429/10000], Train Loss: 0.3204, Val Loss: 0.3828\n",
      "Epoch [3430/10000], Train Loss: 0.3208, Val Loss: 0.4063\n",
      "Epoch [3431/10000], Train Loss: 0.3205, Val Loss: 0.3821\n",
      "Epoch [3432/10000], Train Loss: 0.3202, Val Loss: 0.3901\n",
      "Epoch [3433/10000], Train Loss: 0.3205, Val Loss: 0.4163\n",
      "Epoch [3434/10000], Train Loss: 0.3210, Val Loss: 0.4415\n",
      "Epoch [3435/10000], Train Loss: 0.3211, Val Loss: 0.3799\n",
      "Epoch [3436/10000], Train Loss: 0.3205, Val Loss: 0.3775\n",
      "Epoch [3437/10000], Train Loss: 0.3204, Val Loss: 0.4032\n",
      "Epoch [3438/10000], Train Loss: 0.3206, Val Loss: 0.3838\n",
      "Epoch [3439/10000], Train Loss: 0.3209, Val Loss: 0.3819\n",
      "Epoch [3440/10000], Train Loss: 0.3208, Val Loss: 0.3796\n",
      "Epoch [3441/10000], Train Loss: 0.3205, Val Loss: 0.3852\n",
      "Epoch [3442/10000], Train Loss: 0.3205, Val Loss: 0.4412\n",
      "Epoch [3443/10000], Train Loss: 0.3203, Val Loss: 0.3844\n",
      "Epoch [3444/10000], Train Loss: 0.3546, Val Loss: 1.1536\n",
      "Epoch [3445/10000], Train Loss: 0.3734, Val Loss: 0.9008\n",
      "Epoch [3446/10000], Train Loss: 0.3572, Val Loss: 0.7457\n",
      "Epoch [3447/10000], Train Loss: 0.3493, Val Loss: 0.6922\n",
      "Epoch [3448/10000], Train Loss: 0.3451, Val Loss: 0.6341\n",
      "Epoch [3449/10000], Train Loss: 0.3403, Val Loss: 0.5708\n",
      "Epoch [3450/10000], Train Loss: 0.3330, Val Loss: 0.4883\n",
      "Epoch [3451/10000], Train Loss: 0.3258, Val Loss: 0.4397\n",
      "Epoch [3452/10000], Train Loss: 0.3233, Val Loss: 0.4000\n",
      "Epoch [3453/10000], Train Loss: 0.3213, Val Loss: 0.3825\n",
      "Epoch [3454/10000], Train Loss: 0.3202, Val Loss: 0.3805\n",
      "Epoch [3455/10000], Train Loss: 0.3201, Val Loss: 0.3861\n",
      "Epoch [3456/10000], Train Loss: 0.3205, Val Loss: 0.3989\n",
      "Epoch [3457/10000], Train Loss: 0.3209, Val Loss: 0.3922\n",
      "Epoch [3458/10000], Train Loss: 0.3202, Val Loss: 0.3905\n",
      "Epoch [3459/10000], Train Loss: 0.3209, Val Loss: 0.3848\n",
      "Epoch [3460/10000], Train Loss: 0.3208, Val Loss: 0.3868\n",
      "Epoch [3461/10000], Train Loss: 0.3207, Val Loss: 0.3847\n",
      "Epoch [3462/10000], Train Loss: 0.3208, Val Loss: 0.3918\n",
      "Epoch [3463/10000], Train Loss: 0.3209, Val Loss: 0.3834\n",
      "Epoch [3464/10000], Train Loss: 0.3212, Val Loss: 0.3759\n",
      "Epoch [3465/10000], Train Loss: 0.3210, Val Loss: 0.3869\n",
      "Epoch [3466/10000], Train Loss: 0.3206, Val Loss: 0.3807\n",
      "Epoch [3467/10000], Train Loss: 0.3207, Val Loss: 0.3840\n",
      "Epoch [3468/10000], Train Loss: 0.3212, Val Loss: 0.3812\n",
      "Epoch [3469/10000], Train Loss: 0.3207, Val Loss: 0.3892\n",
      "Epoch [3470/10000], Train Loss: 0.3203, Val Loss: 0.4105\n",
      "Epoch [3471/10000], Train Loss: 0.3205, Val Loss: 0.3847\n",
      "Epoch [3472/10000], Train Loss: 0.3206, Val Loss: 0.4301\n",
      "Epoch [3473/10000], Train Loss: 0.3205, Val Loss: 0.3830\n",
      "Epoch [3474/10000], Train Loss: 0.3209, Val Loss: 0.4299\n",
      "Epoch [3475/10000], Train Loss: 0.3203, Val Loss: 0.3792\n",
      "Epoch [3476/10000], Train Loss: 0.3206, Val Loss: 0.3848\n",
      "Epoch [3477/10000], Train Loss: 0.3209, Val Loss: 0.3905\n",
      "Epoch [3478/10000], Train Loss: 0.3202, Val Loss: 0.3890\n",
      "Epoch [3479/10000], Train Loss: 0.3203, Val Loss: 0.3788\n",
      "Epoch [3480/10000], Train Loss: 0.3205, Val Loss: 0.3891\n",
      "Epoch [3481/10000], Train Loss: 0.3205, Val Loss: 0.4059\n",
      "Epoch [3482/10000], Train Loss: 0.3203, Val Loss: 0.3833\n",
      "Epoch [3483/10000], Train Loss: 0.3209, Val Loss: 0.3794\n",
      "Epoch [3484/10000], Train Loss: 0.3205, Val Loss: 0.3845\n",
      "Epoch [3485/10000], Train Loss: 0.3205, Val Loss: 0.3884\n",
      "Epoch [3486/10000], Train Loss: 0.3208, Val Loss: 0.4144\n",
      "Epoch [3487/10000], Train Loss: 0.3202, Val Loss: 0.3961\n",
      "Epoch [3488/10000], Train Loss: 0.3205, Val Loss: 0.4578\n",
      "Epoch [3489/10000], Train Loss: 0.3208, Val Loss: 0.3764\n",
      "Epoch [3490/10000], Train Loss: 0.3208, Val Loss: 0.3803\n",
      "Epoch [3491/10000], Train Loss: 0.3212, Val Loss: 0.3861\n",
      "Epoch [3492/10000], Train Loss: 0.3203, Val Loss: 0.3836\n",
      "Epoch [3493/10000], Train Loss: 0.3205, Val Loss: 0.3958\n",
      "Epoch [3494/10000], Train Loss: 0.3207, Val Loss: 0.3793\n",
      "Epoch [3495/10000], Train Loss: 0.3207, Val Loss: 0.3854\n",
      "Epoch [3496/10000], Train Loss: 0.3206, Val Loss: 0.3907\n",
      "Epoch [3497/10000], Train Loss: 0.3210, Val Loss: 0.4003\n",
      "Epoch [3498/10000], Train Loss: 0.3206, Val Loss: 0.4111\n",
      "Epoch [3499/10000], Train Loss: 0.3208, Val Loss: 0.4325\n",
      "Epoch [3500/10000], Train Loss: 0.3212, Val Loss: 0.3789\n",
      "Epoch [3501/10000], Train Loss: 0.3206, Val Loss: 0.3806\n",
      "Epoch [3502/10000], Train Loss: 0.3203, Val Loss: 0.3835\n",
      "Epoch [3503/10000], Train Loss: 0.3205, Val Loss: 0.3942\n",
      "Epoch [3504/10000], Train Loss: 0.3204, Val Loss: 0.4094\n",
      "Epoch [3505/10000], Train Loss: 0.3203, Val Loss: 0.3874\n",
      "Epoch [3506/10000], Train Loss: 0.3205, Val Loss: 0.4033\n",
      "Epoch [3507/10000], Train Loss: 0.3204, Val Loss: 0.4079\n",
      "Epoch [3508/10000], Train Loss: 0.3205, Val Loss: 0.3754\n",
      "Epoch [3509/10000], Train Loss: 0.3202, Val Loss: 0.3939\n",
      "Epoch [3510/10000], Train Loss: 0.3210, Val Loss: 0.3933\n",
      "Epoch [3511/10000], Train Loss: 0.3207, Val Loss: 0.3900\n",
      "Epoch [3512/10000], Train Loss: 0.3207, Val Loss: 0.3926\n",
      "Epoch [3513/10000], Train Loss: 0.3202, Val Loss: 0.3941\n",
      "Epoch [3514/10000], Train Loss: 0.3209, Val Loss: 0.4398\n",
      "Epoch [3515/10000], Train Loss: 0.3207, Val Loss: 0.3842\n",
      "Epoch [3516/10000], Train Loss: 0.3204, Val Loss: 0.3876\n",
      "Epoch [3517/10000], Train Loss: 0.3208, Val Loss: 0.4169\n",
      "Epoch [3518/10000], Train Loss: 0.3782, Val Loss: 3.3611\n",
      "Epoch [3519/10000], Train Loss: 0.3917, Val Loss: 0.7665\n",
      "Epoch [3520/10000], Train Loss: 0.3328, Val Loss: 0.5369\n",
      "Epoch [3521/10000], Train Loss: 0.3265, Val Loss: 0.4383\n",
      "Epoch [3522/10000], Train Loss: 0.3234, Val Loss: 0.3883\n",
      "Epoch [3523/10000], Train Loss: 0.3219, Val Loss: 0.3848\n",
      "Epoch [3524/10000], Train Loss: 0.3214, Val Loss: 0.4035\n",
      "Epoch [3525/10000], Train Loss: 0.3205, Val Loss: 0.3862\n",
      "Epoch [3526/10000], Train Loss: 0.3204, Val Loss: 0.3804\n",
      "Epoch [3527/10000], Train Loss: 0.3208, Val Loss: 0.3931\n",
      "Epoch [3528/10000], Train Loss: 0.3207, Val Loss: 0.3863\n",
      "Epoch [3529/10000], Train Loss: 0.3207, Val Loss: 0.4361\n",
      "Epoch [3530/10000], Train Loss: 0.3207, Val Loss: 0.3785\n",
      "Epoch [3531/10000], Train Loss: 0.3205, Val Loss: 0.4099\n",
      "Epoch [3532/10000], Train Loss: 0.3204, Val Loss: 0.3811\n",
      "Epoch [3533/10000], Train Loss: 0.3205, Val Loss: 0.3868\n",
      "Epoch [3534/10000], Train Loss: 0.3204, Val Loss: 0.3812\n",
      "Epoch [3535/10000], Train Loss: 0.3207, Val Loss: 0.3972\n",
      "Epoch [3536/10000], Train Loss: 0.3203, Val Loss: 0.3903\n",
      "Epoch [3537/10000], Train Loss: 0.3206, Val Loss: 0.3774\n",
      "Epoch [3538/10000], Train Loss: 0.3206, Val Loss: 0.4132\n",
      "Epoch [3539/10000], Train Loss: 0.3205, Val Loss: 0.3774\n",
      "Epoch [3540/10000], Train Loss: 0.3205, Val Loss: 0.3890\n",
      "Epoch [3541/10000], Train Loss: 0.3204, Val Loss: 0.4566\n",
      "Epoch [3542/10000], Train Loss: 0.3205, Val Loss: 0.3828\n",
      "Epoch [3543/10000], Train Loss: 0.3204, Val Loss: 0.4027\n",
      "Epoch [3544/10000], Train Loss: 0.4062, Val Loss: 1.0986\n",
      "Epoch [3545/10000], Train Loss: 0.4766, Val Loss: 1.0826\n",
      "Epoch [3546/10000], Train Loss: 0.4652, Val Loss: 1.0595\n",
      "Epoch [3547/10000], Train Loss: 0.4488, Val Loss: 0.9789\n",
      "Epoch [3548/10000], Train Loss: 0.4104, Val Loss: 0.6811\n",
      "Epoch [3549/10000], Train Loss: 0.3769, Val Loss: 0.5780\n",
      "Epoch [3550/10000], Train Loss: 0.3508, Val Loss: 0.4669\n",
      "Epoch [3551/10000], Train Loss: 0.3281, Val Loss: 0.3840\n",
      "Epoch [3552/10000], Train Loss: 0.3210, Val Loss: 0.3811\n",
      "Epoch [3553/10000], Train Loss: 0.3206, Val Loss: 0.3961\n",
      "Epoch [3554/10000], Train Loss: 0.3210, Val Loss: 0.4070\n",
      "Epoch [3555/10000], Train Loss: 0.3206, Val Loss: 0.3863\n",
      "Epoch [3556/10000], Train Loss: 0.3210, Val Loss: 0.4010\n",
      "Epoch [3557/10000], Train Loss: 0.3209, Val Loss: 0.3925\n",
      "Epoch [3558/10000], Train Loss: 0.3206, Val Loss: 0.3806\n",
      "Epoch [3559/10000], Train Loss: 0.3207, Val Loss: 0.3886\n",
      "Epoch [3560/10000], Train Loss: 0.3210, Val Loss: 0.3831\n",
      "Epoch [3561/10000], Train Loss: 0.3211, Val Loss: 0.3879\n",
      "Epoch [3562/10000], Train Loss: 0.3210, Val Loss: 0.3811\n",
      "Epoch [3563/10000], Train Loss: 0.3207, Val Loss: 0.4512\n",
      "Epoch [3564/10000], Train Loss: 0.3207, Val Loss: 0.3914\n",
      "Epoch [3565/10000], Train Loss: 0.3211, Val Loss: 0.3843\n",
      "Epoch [3566/10000], Train Loss: 0.3211, Val Loss: 0.8547\n",
      "Epoch [3567/10000], Train Loss: 0.3208, Val Loss: 0.4319\n",
      "Epoch [3568/10000], Train Loss: 0.3207, Val Loss: 0.3978\n",
      "Epoch [3569/10000], Train Loss: 0.3209, Val Loss: 0.3793\n",
      "Epoch [3570/10000], Train Loss: 0.3203, Val Loss: 0.4209\n",
      "Epoch [3571/10000], Train Loss: 0.3206, Val Loss: 0.4839\n",
      "Epoch [3572/10000], Train Loss: 0.3208, Val Loss: 0.3844\n",
      "Epoch [3573/10000], Train Loss: 0.3207, Val Loss: 0.3908\n",
      "Epoch [3574/10000], Train Loss: 0.3210, Val Loss: 0.4673\n",
      "Epoch [3575/10000], Train Loss: 0.3204, Val Loss: 0.3779\n",
      "Epoch [3576/10000], Train Loss: 0.3209, Val Loss: 0.3829\n",
      "Epoch [3577/10000], Train Loss: 0.3201, Val Loss: 0.4003\n",
      "Epoch [3578/10000], Train Loss: 0.3207, Val Loss: 0.4210\n",
      "Epoch [3579/10000], Train Loss: 0.3205, Val Loss: 0.3893\n",
      "Epoch [3580/10000], Train Loss: 0.3203, Val Loss: 0.4002\n",
      "Epoch [3581/10000], Train Loss: 0.3207, Val Loss: 0.3984\n",
      "Epoch [3582/10000], Train Loss: 0.3213, Val Loss: 0.3848\n",
      "Epoch [3583/10000], Train Loss: 0.3208, Val Loss: 0.4182\n",
      "Epoch [3584/10000], Train Loss: 0.3207, Val Loss: 0.3913\n",
      "Epoch [3585/10000], Train Loss: 0.3209, Val Loss: 0.4210\n",
      "Epoch [3586/10000], Train Loss: 0.3207, Val Loss: 0.3857\n",
      "Epoch [3587/10000], Train Loss: 0.3204, Val Loss: 0.4040\n",
      "Epoch [3588/10000], Train Loss: 0.3210, Val Loss: 0.3922\n",
      "Epoch [3589/10000], Train Loss: 0.3207, Val Loss: 0.3946\n",
      "Epoch [3590/10000], Train Loss: 0.3208, Val Loss: 0.4146\n",
      "Epoch [3591/10000], Train Loss: 0.3209, Val Loss: 0.3815\n",
      "Epoch [3592/10000], Train Loss: 0.3206, Val Loss: 0.4945\n",
      "Epoch [3593/10000], Train Loss: 0.3204, Val Loss: 0.3998\n",
      "Epoch [3594/10000], Train Loss: 0.3205, Val Loss: 0.3836\n",
      "Epoch [3595/10000], Train Loss: 0.3205, Val Loss: 0.4002\n",
      "Epoch [3596/10000], Train Loss: 0.3205, Val Loss: 0.3789\n",
      "Epoch [3597/10000], Train Loss: 0.3205, Val Loss: 0.5624\n",
      "Epoch [3598/10000], Train Loss: 0.3213, Val Loss: 0.3819\n",
      "Epoch [3599/10000], Train Loss: 0.3208, Val Loss: 0.3788\n",
      "Epoch [3600/10000], Train Loss: 0.3208, Val Loss: 0.3883\n",
      "Epoch [3601/10000], Train Loss: 0.3207, Val Loss: 0.3896\n",
      "Epoch [3602/10000], Train Loss: 0.3206, Val Loss: 0.3867\n",
      "Epoch [3603/10000], Train Loss: 0.3209, Val Loss: 0.3856\n",
      "Epoch [3604/10000], Train Loss: 0.3207, Val Loss: 0.3802\n",
      "Epoch [3605/10000], Train Loss: 0.3206, Val Loss: 0.3883\n",
      "Epoch [3606/10000], Train Loss: 0.3211, Val Loss: 0.3799\n",
      "Epoch [3607/10000], Train Loss: 0.3210, Val Loss: 0.3776\n",
      "Epoch [3608/10000], Train Loss: 0.3205, Val Loss: 0.3974\n",
      "Epoch [3609/10000], Train Loss: 0.3210, Val Loss: 0.4079\n",
      "Epoch [3610/10000], Train Loss: 0.3206, Val Loss: 0.3881\n",
      "Epoch [3611/10000], Train Loss: 0.3204, Val Loss: 0.5545\n",
      "Epoch [3612/10000], Train Loss: 0.3208, Val Loss: 0.4052\n",
      "Epoch [3613/10000], Train Loss: 0.3206, Val Loss: 0.4005\n",
      "Epoch [3614/10000], Train Loss: 0.3202, Val Loss: 0.4192\n",
      "Epoch [3615/10000], Train Loss: 0.3203, Val Loss: 0.3891\n",
      "Epoch [3616/10000], Train Loss: 0.3208, Val Loss: 0.3836\n",
      "Epoch [3617/10000], Train Loss: 0.3207, Val Loss: 0.3901\n",
      "Epoch [3618/10000], Train Loss: 0.3206, Val Loss: 0.3894\n",
      "Epoch [3619/10000], Train Loss: 0.3205, Val Loss: 0.3872\n",
      "Epoch [3620/10000], Train Loss: 0.3210, Val Loss: 0.4013\n",
      "Epoch [3621/10000], Train Loss: 0.5639, Val Loss: 9.3596\n",
      "Epoch [3622/10000], Train Loss: 1.5920, Val Loss: 5.7429\n",
      "Epoch [3623/10000], Train Loss: 1.2656, Val Loss: 3.3512\n",
      "Epoch [3624/10000], Train Loss: 1.1455, Val Loss: 2.9081\n",
      "Epoch [3625/10000], Train Loss: 0.7141, Val Loss: 0.7876\n",
      "Epoch [3626/10000], Train Loss: 0.4375, Val Loss: 0.4765\n",
      "Epoch [3627/10000], Train Loss: 0.3418, Val Loss: 0.4137\n",
      "Epoch [3628/10000], Train Loss: 0.3313, Val Loss: 0.4038\n",
      "Epoch [3629/10000], Train Loss: 0.3221, Val Loss: 0.3880\n",
      "Epoch [3630/10000], Train Loss: 0.3210, Val Loss: 0.3986\n",
      "Epoch [3631/10000], Train Loss: 0.3211, Val Loss: 0.3818\n",
      "Epoch [3632/10000], Train Loss: 0.3215, Val Loss: 0.3977\n",
      "Epoch [3633/10000], Train Loss: 0.3215, Val Loss: 0.3891\n",
      "Epoch [3634/10000], Train Loss: 0.3233, Val Loss: 0.4411\n",
      "Epoch [3635/10000], Train Loss: 0.3206, Val Loss: 0.3827\n",
      "Epoch [3636/10000], Train Loss: 0.3208, Val Loss: 0.3825\n",
      "Epoch [3637/10000], Train Loss: 0.3214, Val Loss: 0.3918\n",
      "Epoch [3638/10000], Train Loss: 0.3207, Val Loss: 0.4042\n",
      "Epoch [3639/10000], Train Loss: 0.3210, Val Loss: 0.4019\n",
      "Epoch [3640/10000], Train Loss: 0.3209, Val Loss: 0.3858\n",
      "Epoch [3641/10000], Train Loss: 0.3212, Val Loss: 0.3858\n",
      "Epoch [3642/10000], Train Loss: 0.3214, Val Loss: 0.4219\n",
      "Epoch [3643/10000], Train Loss: 0.3212, Val Loss: 0.4026\n",
      "Epoch [3644/10000], Train Loss: 0.3209, Val Loss: 0.3861\n",
      "Epoch [3645/10000], Train Loss: 0.3211, Val Loss: 0.4482\n",
      "Epoch [3646/10000], Train Loss: 0.3209, Val Loss: 0.3888\n",
      "Epoch [3647/10000], Train Loss: 0.3209, Val Loss: 0.3867\n",
      "Epoch [3648/10000], Train Loss: 0.3210, Val Loss: 0.3809\n",
      "Epoch [3649/10000], Train Loss: 0.3210, Val Loss: 0.3867\n",
      "Epoch [3650/10000], Train Loss: 0.3208, Val Loss: 0.3799\n",
      "Epoch [3651/10000], Train Loss: 0.3208, Val Loss: 0.3880\n",
      "Epoch [3652/10000], Train Loss: 0.3212, Val Loss: 0.3945\n",
      "Epoch [3653/10000], Train Loss: 0.3212, Val Loss: 0.3969\n",
      "Epoch [3654/10000], Train Loss: 0.3209, Val Loss: 0.3927\n",
      "Epoch [3655/10000], Train Loss: 0.3205, Val Loss: 0.3956\n",
      "Epoch [3656/10000], Train Loss: 0.3210, Val Loss: 0.3950\n",
      "Epoch [3657/10000], Train Loss: 0.3204, Val Loss: 0.3925\n",
      "Epoch [3658/10000], Train Loss: 0.3204, Val Loss: 0.3826\n",
      "Epoch [3659/10000], Train Loss: 0.3209, Val Loss: 0.3963\n",
      "Epoch [3660/10000], Train Loss: 0.3210, Val Loss: 0.4124\n",
      "Epoch [3661/10000], Train Loss: 0.3214, Val Loss: 0.4246\n",
      "Epoch [3662/10000], Train Loss: 0.3208, Val Loss: 0.3883\n",
      "Epoch [3663/10000], Train Loss: 0.3208, Val Loss: 0.3920\n",
      "Epoch [3664/10000], Train Loss: 0.3211, Val Loss: 0.3768\n",
      "Epoch [3665/10000], Train Loss: 0.3207, Val Loss: 0.3894\n",
      "Epoch [3666/10000], Train Loss: 0.3211, Val Loss: 0.4102\n",
      "Epoch [3667/10000], Train Loss: 0.3210, Val Loss: 0.4140\n",
      "Epoch [3668/10000], Train Loss: 0.3207, Val Loss: 0.3806\n",
      "Epoch [3669/10000], Train Loss: 0.3212, Val Loss: 0.3949\n",
      "Epoch [3670/10000], Train Loss: 0.3212, Val Loss: 0.3891\n",
      "Epoch [3671/10000], Train Loss: 0.3209, Val Loss: 0.3855\n",
      "Epoch [3672/10000], Train Loss: 0.3206, Val Loss: 0.3794\n",
      "Epoch [3673/10000], Train Loss: 0.3209, Val Loss: 0.3923\n",
      "Epoch [3674/10000], Train Loss: 0.3207, Val Loss: 0.3844\n",
      "Epoch [3675/10000], Train Loss: 0.3207, Val Loss: 0.3964\n",
      "Epoch [3676/10000], Train Loss: 0.3208, Val Loss: 0.3961\n",
      "Epoch [3677/10000], Train Loss: 0.3206, Val Loss: 0.4105\n",
      "Epoch [3678/10000], Train Loss: 0.3210, Val Loss: 0.3833\n",
      "Epoch [3679/10000], Train Loss: 0.3210, Val Loss: 0.3832\n",
      "Epoch [3680/10000], Train Loss: 0.3207, Val Loss: 0.3853\n",
      "Epoch [3681/10000], Train Loss: 0.3205, Val Loss: 0.3812\n",
      "Epoch [3682/10000], Train Loss: 0.3210, Val Loss: 0.3862\n",
      "Epoch [3683/10000], Train Loss: 0.3213, Val Loss: 0.4086\n",
      "Epoch [3684/10000], Train Loss: 0.3208, Val Loss: 0.4294\n",
      "Epoch [3685/10000], Train Loss: 0.3210, Val Loss: 0.3872\n",
      "Epoch [3686/10000], Train Loss: 0.3208, Val Loss: 0.4339\n",
      "Epoch [3687/10000], Train Loss: 0.3209, Val Loss: 0.3955\n",
      "Epoch [3688/10000], Train Loss: 0.3209, Val Loss: 0.3809\n",
      "Epoch [3689/10000], Train Loss: 0.3207, Val Loss: 0.3863\n",
      "Epoch [3690/10000], Train Loss: 0.3207, Val Loss: 0.3842\n",
      "Epoch [3691/10000], Train Loss: 0.3210, Val Loss: 0.3798\n",
      "Epoch [3692/10000], Train Loss: 0.3206, Val Loss: 0.3879\n",
      "Epoch [3693/10000], Train Loss: 0.3205, Val Loss: 0.3930\n",
      "Epoch [3694/10000], Train Loss: 0.3206, Val Loss: 0.3962\n",
      "Epoch [3695/10000], Train Loss: 0.3205, Val Loss: 0.3780\n",
      "Epoch [3696/10000], Train Loss: 0.3205, Val Loss: 0.3855\n",
      "Epoch [3697/10000], Train Loss: 0.3206, Val Loss: 0.3869\n",
      "Epoch [3698/10000], Train Loss: 0.3204, Val Loss: 0.3922\n",
      "Epoch [3699/10000], Train Loss: 0.3208, Val Loss: 0.3933\n",
      "Epoch [3700/10000], Train Loss: 0.3208, Val Loss: 0.3855\n",
      "Epoch [3701/10000], Train Loss: 0.3210, Val Loss: 0.3875\n",
      "Epoch [3702/10000], Train Loss: 0.3207, Val Loss: 0.3954\n",
      "Epoch [3703/10000], Train Loss: 0.3206, Val Loss: 0.4001\n",
      "Epoch [3704/10000], Train Loss: 0.3205, Val Loss: 0.3998\n",
      "Epoch [3705/10000], Train Loss: 0.3206, Val Loss: 0.4012\n",
      "Epoch [3706/10000], Train Loss: 0.3208, Val Loss: 0.3900\n",
      "Epoch [3707/10000], Train Loss: 0.3204, Val Loss: 0.3789\n",
      "Epoch [3708/10000], Train Loss: 0.3205, Val Loss: 0.3803\n",
      "Epoch [3709/10000], Train Loss: 0.3212, Val Loss: 0.3872\n",
      "Epoch [3710/10000], Train Loss: 0.3210, Val Loss: 0.3745\n",
      "Epoch [3711/10000], Train Loss: 0.3209, Val Loss: 0.4179\n",
      "Epoch [3712/10000], Train Loss: 0.3209, Val Loss: 0.4127\n",
      "Epoch [3713/10000], Train Loss: 0.3206, Val Loss: 0.3852\n",
      "Epoch [3714/10000], Train Loss: 0.3211, Val Loss: 0.3878\n",
      "Epoch [3715/10000], Train Loss: 0.3205, Val Loss: 0.3840\n",
      "Epoch [3716/10000], Train Loss: 0.3208, Val Loss: 0.3808\n",
      "Epoch [3717/10000], Train Loss: 0.3209, Val Loss: 0.3856\n",
      "Epoch [3718/10000], Train Loss: 0.3207, Val Loss: 0.3937\n",
      "Epoch [3719/10000], Train Loss: 0.3209, Val Loss: 0.4019\n",
      "Epoch [3720/10000], Train Loss: 0.3207, Val Loss: 0.4175\n",
      "Epoch [3721/10000], Train Loss: 0.3208, Val Loss: 0.3841\n",
      "Epoch [3722/10000], Train Loss: 0.3207, Val Loss: 0.3867\n",
      "Epoch [3723/10000], Train Loss: 0.3209, Val Loss: 0.3932\n",
      "Epoch [3724/10000], Train Loss: 0.3208, Val Loss: 0.3946\n",
      "Epoch [3725/10000], Train Loss: 0.3211, Val Loss: 0.3939\n",
      "Epoch [3726/10000], Train Loss: 0.3213, Val Loss: 0.3921\n",
      "Epoch [3727/10000], Train Loss: 0.3209, Val Loss: 0.3854\n",
      "Epoch [3728/10000], Train Loss: 0.3208, Val Loss: 0.4155\n",
      "Epoch [3729/10000], Train Loss: 0.3208, Val Loss: 0.3940\n",
      "Epoch [3730/10000], Train Loss: 0.3207, Val Loss: 0.4142\n",
      "Epoch [3731/10000], Train Loss: 0.3204, Val Loss: 0.3844\n",
      "Epoch [3732/10000], Train Loss: 0.3204, Val Loss: 0.3797\n",
      "Epoch [3733/10000], Train Loss: 0.3209, Val Loss: 0.4089\n",
      "Epoch [3734/10000], Train Loss: 0.3208, Val Loss: 0.3812\n",
      "Epoch [3735/10000], Train Loss: 0.3209, Val Loss: 0.3903\n",
      "Epoch [3736/10000], Train Loss: 0.3205, Val Loss: 0.4169\n",
      "Epoch [3737/10000], Train Loss: 0.3209, Val Loss: 0.3837\n",
      "Epoch [3738/10000], Train Loss: 0.3205, Val Loss: 0.4576\n",
      "Epoch [3739/10000], Train Loss: 0.3208, Val Loss: 0.4068\n",
      "Epoch [3740/10000], Train Loss: 0.3206, Val Loss: 0.4151\n",
      "Epoch [3741/10000], Train Loss: 0.3204, Val Loss: 0.3807\n",
      "Epoch [3742/10000], Train Loss: 0.3209, Val Loss: 0.4563\n",
      "Epoch [3743/10000], Train Loss: 0.3210, Val Loss: 0.3990\n",
      "Epoch [3744/10000], Train Loss: 0.3206, Val Loss: 0.5138\n",
      "Epoch [3745/10000], Train Loss: 0.3213, Val Loss: 0.4319\n",
      "Epoch [3746/10000], Train Loss: 0.3210, Val Loss: 0.3808\n",
      "Epoch [3747/10000], Train Loss: 0.5631, Val Loss: 7.7488\n",
      "Epoch [3748/10000], Train Loss: 1.3655, Val Loss: 4.8171\n",
      "Epoch [3749/10000], Train Loss: 1.1920, Val Loss: 3.8411\n",
      "Epoch [3750/10000], Train Loss: 1.0336, Val Loss: 2.7221\n",
      "Epoch [3751/10000], Train Loss: 0.9088, Val Loss: 2.9215\n",
      "Epoch [3752/10000], Train Loss: 0.8737, Val Loss: 3.8866\n",
      "Epoch [3753/10000], Train Loss: 1.2320, Val Loss: 2.6517\n",
      "Epoch [3754/10000], Train Loss: 1.2038, Val Loss: 2.5931\n",
      "Epoch [3755/10000], Train Loss: 1.1873, Val Loss: 2.5500\n",
      "Epoch [3756/10000], Train Loss: 0.7903, Val Loss: 1.2831\n",
      "Epoch [3757/10000], Train Loss: 0.4496, Val Loss: 1.0763\n",
      "Epoch [3758/10000], Train Loss: 0.4132, Val Loss: 0.9453\n",
      "Epoch [3759/10000], Train Loss: 0.3881, Val Loss: 0.7839\n",
      "Epoch [3760/10000], Train Loss: 0.3624, Val Loss: 0.6331\n",
      "Epoch [3761/10000], Train Loss: 0.3444, Val Loss: 0.5688\n",
      "Epoch [3762/10000], Train Loss: 0.3343, Val Loss: 0.4523\n",
      "Epoch [3763/10000], Train Loss: 0.3298, Val Loss: 0.3938\n",
      "Epoch [3764/10000], Train Loss: 0.3271, Val Loss: 0.3996\n",
      "Epoch [3765/10000], Train Loss: 0.3259, Val Loss: 0.4116\n",
      "Epoch [3766/10000], Train Loss: 0.3253, Val Loss: 0.3884\n",
      "Epoch [3767/10000], Train Loss: 0.3241, Val Loss: 0.3927\n",
      "Epoch [3768/10000], Train Loss: 0.3243, Val Loss: 0.4516\n",
      "Epoch [3769/10000], Train Loss: 0.3239, Val Loss: 0.4031\n",
      "Epoch [3770/10000], Train Loss: 0.3233, Val Loss: 0.3991\n",
      "Epoch [3771/10000], Train Loss: 0.3234, Val Loss: 0.3876\n",
      "Epoch [3772/10000], Train Loss: 0.3231, Val Loss: 0.3909\n",
      "Epoch [3773/10000], Train Loss: 0.3232, Val Loss: 0.4093\n",
      "Epoch [3774/10000], Train Loss: 0.3226, Val Loss: 0.4056\n",
      "Epoch [3775/10000], Train Loss: 0.3243, Val Loss: 0.4537\n",
      "Epoch [3776/10000], Train Loss: 0.3243, Val Loss: 0.3877\n",
      "Epoch [3777/10000], Train Loss: 0.3223, Val Loss: 0.4079\n",
      "Epoch [3778/10000], Train Loss: 0.3222, Val Loss: 0.4249\n",
      "Epoch [3779/10000], Train Loss: 0.3222, Val Loss: 0.3839\n",
      "Epoch [3780/10000], Train Loss: 0.3223, Val Loss: 0.3986\n",
      "Epoch [3781/10000], Train Loss: 0.3224, Val Loss: 0.3899\n",
      "Epoch [3782/10000], Train Loss: 0.3220, Val Loss: 0.4005\n",
      "Epoch [3783/10000], Train Loss: 0.3218, Val Loss: 0.3930\n",
      "Epoch [3784/10000], Train Loss: 0.3224, Val Loss: 0.3825\n",
      "Epoch [3785/10000], Train Loss: 0.3226, Val Loss: 0.4033\n",
      "Epoch [3786/10000], Train Loss: 0.3219, Val Loss: 0.3921\n",
      "Epoch [3787/10000], Train Loss: 0.3219, Val Loss: 0.3885\n",
      "Epoch [3788/10000], Train Loss: 0.3219, Val Loss: 0.3957\n",
      "Epoch [3789/10000], Train Loss: 0.3218, Val Loss: 0.4660\n",
      "Epoch [3790/10000], Train Loss: 0.3213, Val Loss: 0.3960\n",
      "Epoch [3791/10000], Train Loss: 0.3217, Val Loss: 0.3891\n",
      "Epoch [3792/10000], Train Loss: 0.3219, Val Loss: 0.3850\n",
      "Epoch [3793/10000], Train Loss: 0.3213, Val Loss: 0.4000\n",
      "Epoch [3794/10000], Train Loss: 0.3212, Val Loss: 0.4058\n",
      "Epoch [3795/10000], Train Loss: 0.3213, Val Loss: 0.4005\n",
      "Epoch [3796/10000], Train Loss: 0.3216, Val Loss: 0.3996\n",
      "Epoch [3797/10000], Train Loss: 0.3216, Val Loss: 0.4021\n",
      "Epoch [3798/10000], Train Loss: 0.3216, Val Loss: 0.3876\n",
      "Epoch [3799/10000], Train Loss: 0.3212, Val Loss: 0.4024\n",
      "Epoch [3800/10000], Train Loss: 0.3215, Val Loss: 0.3832\n",
      "Epoch [3801/10000], Train Loss: 0.3215, Val Loss: 0.4113\n",
      "Epoch [3802/10000], Train Loss: 0.3216, Val Loss: 0.3984\n",
      "Epoch [3803/10000], Train Loss: 0.3217, Val Loss: 0.3851\n",
      "Epoch [3804/10000], Train Loss: 0.3215, Val Loss: 0.3789\n",
      "Epoch [3805/10000], Train Loss: 0.3217, Val Loss: 0.3980\n",
      "Epoch [3806/10000], Train Loss: 0.3210, Val Loss: 0.3849\n",
      "Epoch [3807/10000], Train Loss: 0.3214, Val Loss: 0.4814\n",
      "Epoch [3808/10000], Train Loss: 0.3211, Val Loss: 0.4090\n",
      "Epoch [3809/10000], Train Loss: 0.3212, Val Loss: 0.3828\n",
      "Epoch [3810/10000], Train Loss: 0.3212, Val Loss: 0.4030\n",
      "Epoch [3811/10000], Train Loss: 0.3213, Val Loss: 0.3899\n",
      "Epoch [3812/10000], Train Loss: 0.3211, Val Loss: 0.3877\n",
      "Epoch [3813/10000], Train Loss: 0.3213, Val Loss: 0.4135\n",
      "Epoch [3814/10000], Train Loss: 0.3210, Val Loss: 0.3909\n",
      "Epoch [3815/10000], Train Loss: 0.3213, Val Loss: 0.3965\n",
      "Epoch [3816/10000], Train Loss: 0.3209, Val Loss: 0.4094\n",
      "Epoch [3817/10000], Train Loss: 0.3214, Val Loss: 0.3842\n",
      "Epoch [3818/10000], Train Loss: 0.3211, Val Loss: 0.3876\n",
      "Epoch [3819/10000], Train Loss: 0.3211, Val Loss: 0.4070\n",
      "Epoch [3820/10000], Train Loss: 0.3209, Val Loss: 0.3820\n",
      "Epoch [3821/10000], Train Loss: 0.3207, Val Loss: 0.3827\n",
      "Epoch [3822/10000], Train Loss: 0.3212, Val Loss: 0.3991\n",
      "Epoch [3823/10000], Train Loss: 0.3208, Val Loss: 0.3862\n",
      "Epoch [3824/10000], Train Loss: 0.3212, Val Loss: 0.3863\n",
      "Epoch [3825/10000], Train Loss: 0.3205, Val Loss: 0.4052\n",
      "Epoch [3826/10000], Train Loss: 0.3211, Val Loss: 0.4360\n",
      "Epoch [3827/10000], Train Loss: 0.3206, Val Loss: 0.3882\n",
      "Epoch [3828/10000], Train Loss: 0.3209, Val Loss: 0.3931\n",
      "Epoch [3829/10000], Train Loss: 0.3209, Val Loss: 0.3923\n",
      "Epoch [3830/10000], Train Loss: 0.3212, Val Loss: 0.3811\n",
      "Epoch [3831/10000], Train Loss: 0.3211, Val Loss: 0.4265\n",
      "Epoch [3832/10000], Train Loss: 0.3211, Val Loss: 0.4015\n",
      "Epoch [3833/10000], Train Loss: 0.3211, Val Loss: 0.4015\n",
      "Epoch [3834/10000], Train Loss: 0.3237, Val Loss: 0.3995\n",
      "Epoch [3835/10000], Train Loss: 0.3202, Val Loss: 0.4015\n",
      "Epoch [3836/10000], Train Loss: 0.3203, Val Loss: 0.3965\n",
      "Epoch [3837/10000], Train Loss: 0.3211, Val Loss: 0.3867\n",
      "Epoch [3838/10000], Train Loss: 0.3210, Val Loss: 0.3962\n",
      "Epoch [3839/10000], Train Loss: 0.3211, Val Loss: 0.4107\n",
      "Epoch [3840/10000], Train Loss: 0.3212, Val Loss: 0.3833\n",
      "Epoch [3841/10000], Train Loss: 0.3210, Val Loss: 0.3920\n",
      "Epoch [3842/10000], Train Loss: 0.3210, Val Loss: 0.3900\n",
      "Epoch [3843/10000], Train Loss: 0.3209, Val Loss: 0.4300\n",
      "Epoch [3844/10000], Train Loss: 0.3206, Val Loss: 0.3936\n",
      "Epoch [3845/10000], Train Loss: 0.3213, Val Loss: 0.3942\n",
      "Epoch [3846/10000], Train Loss: 0.3211, Val Loss: 0.4036\n",
      "Epoch [3847/10000], Train Loss: 0.3208, Val Loss: 0.4179\n",
      "Epoch [3848/10000], Train Loss: 0.3207, Val Loss: 0.4017\n",
      "Epoch [3849/10000], Train Loss: 0.3209, Val Loss: 0.3949\n",
      "Epoch [3850/10000], Train Loss: 0.3204, Val Loss: 0.4263\n",
      "Epoch [3851/10000], Train Loss: 0.3213, Val Loss: 0.3907\n",
      "Epoch [3852/10000], Train Loss: 0.3210, Val Loss: 0.3974\n",
      "Epoch [3853/10000], Train Loss: 0.3210, Val Loss: 0.3851\n",
      "Epoch [3854/10000], Train Loss: 0.3212, Val Loss: 0.3866\n",
      "Epoch [3855/10000], Train Loss: 0.3210, Val Loss: 0.4516\n",
      "Epoch [3856/10000], Train Loss: 0.3211, Val Loss: 0.4068\n",
      "Epoch [3857/10000], Train Loss: 0.3209, Val Loss: 0.3782\n",
      "Epoch [3858/10000], Train Loss: 0.3213, Val Loss: 0.3911\n",
      "Epoch [3859/10000], Train Loss: 0.3207, Val Loss: 0.3870\n",
      "Epoch [3860/10000], Train Loss: 0.3214, Val Loss: 0.3859\n",
      "Epoch [3861/10000], Train Loss: 0.3205, Val Loss: 0.4220\n",
      "Epoch [3862/10000], Train Loss: 0.3208, Val Loss: 0.4029\n",
      "Epoch [3863/10000], Train Loss: 0.3253, Val Loss: 0.3875\n",
      "Epoch [3864/10000], Train Loss: 0.3206, Val Loss: 0.3887\n",
      "Epoch [3865/10000], Train Loss: 0.3206, Val Loss: 0.3974\n",
      "Epoch [3866/10000], Train Loss: 0.3206, Val Loss: 0.4063\n",
      "Epoch [3867/10000], Train Loss: 0.3208, Val Loss: 0.4138\n",
      "Epoch [3868/10000], Train Loss: 0.3208, Val Loss: 0.3949\n",
      "Epoch [3869/10000], Train Loss: 0.3207, Val Loss: 0.4077\n",
      "Epoch [3870/10000], Train Loss: 0.3214, Val Loss: 0.3878\n",
      "Epoch [3871/10000], Train Loss: 0.3209, Val Loss: 0.4051\n",
      "Epoch [3872/10000], Train Loss: 0.3209, Val Loss: 0.3893\n",
      "Epoch [3873/10000], Train Loss: 0.3209, Val Loss: 0.3862\n",
      "Epoch [3874/10000], Train Loss: 0.3208, Val Loss: 0.4082\n",
      "Epoch [3875/10000], Train Loss: 0.3211, Val Loss: 0.3878\n",
      "Epoch [3876/10000], Train Loss: 0.3210, Val Loss: 0.3826\n",
      "Epoch [3877/10000], Train Loss: 0.3207, Val Loss: 0.4304\n",
      "Epoch [3878/10000], Train Loss: 0.3208, Val Loss: 0.3788\n",
      "Epoch [3879/10000], Train Loss: 0.3208, Val Loss: 0.3827\n",
      "Epoch [3880/10000], Train Loss: 0.3209, Val Loss: 0.3767\n",
      "Epoch [3881/10000], Train Loss: 0.3209, Val Loss: 0.4031\n",
      "Epoch [3882/10000], Train Loss: 0.3209, Val Loss: 0.4263\n",
      "Epoch [3883/10000], Train Loss: 0.3206, Val Loss: 0.5136\n",
      "Epoch [3884/10000], Train Loss: 0.3207, Val Loss: 0.3800\n",
      "Epoch [3885/10000], Train Loss: 0.3206, Val Loss: 0.4011\n",
      "Epoch [3886/10000], Train Loss: 0.3209, Val Loss: 0.3959\n",
      "Epoch [3887/10000], Train Loss: 0.3210, Val Loss: 0.4029\n",
      "Epoch [3888/10000], Train Loss: 0.3205, Val Loss: 0.3911\n",
      "Epoch [3889/10000], Train Loss: 0.3213, Val Loss: 0.3841\n",
      "Epoch [3890/10000], Train Loss: 0.3208, Val Loss: 0.3814\n",
      "Epoch [3891/10000], Train Loss: 0.3208, Val Loss: 0.3914\n",
      "Epoch [3892/10000], Train Loss: 0.3206, Val Loss: 0.4875\n",
      "Epoch [3893/10000], Train Loss: 0.3204, Val Loss: 0.3832\n",
      "Epoch [3894/10000], Train Loss: 0.3210, Val Loss: 0.3806\n",
      "Epoch [3895/10000], Train Loss: 0.3209, Val Loss: 0.3913\n",
      "Epoch [3896/10000], Train Loss: 0.3208, Val Loss: 0.3947\n",
      "Epoch [3897/10000], Train Loss: 0.3202, Val Loss: 0.3797\n",
      "Epoch [3898/10000], Train Loss: 0.3204, Val Loss: 0.4508\n",
      "Epoch [3899/10000], Train Loss: 0.3209, Val Loss: 0.3843\n",
      "Epoch [3900/10000], Train Loss: 0.3207, Val Loss: 0.3998\n",
      "Epoch [3901/10000], Train Loss: 0.3208, Val Loss: 0.3809\n",
      "Epoch [3902/10000], Train Loss: 0.3211, Val Loss: 0.3831\n",
      "Epoch [3903/10000], Train Loss: 0.3209, Val Loss: 0.3873\n",
      "Epoch [3904/10000], Train Loss: 0.3207, Val Loss: 0.3956\n",
      "Epoch [3905/10000], Train Loss: 0.3203, Val Loss: 0.3832\n",
      "Epoch [3906/10000], Train Loss: 0.3211, Val Loss: 0.3906\n",
      "Epoch [3907/10000], Train Loss: 0.3208, Val Loss: 0.4379\n",
      "Epoch [3908/10000], Train Loss: 0.3207, Val Loss: 0.3811\n",
      "Epoch [3909/10000], Train Loss: 0.3213, Val Loss: 0.4076\n",
      "Epoch [3910/10000], Train Loss: 0.3205, Val Loss: 0.3927\n",
      "Epoch [3911/10000], Train Loss: 0.3209, Val Loss: 0.3915\n",
      "Epoch [3912/10000], Train Loss: 0.3210, Val Loss: 0.3889\n",
      "Epoch [3913/10000], Train Loss: 0.3206, Val Loss: 0.4054\n",
      "Epoch [3914/10000], Train Loss: 0.3207, Val Loss: 0.3880\n",
      "Epoch [3915/10000], Train Loss: 0.3207, Val Loss: 0.3783\n",
      "Epoch [3916/10000], Train Loss: 0.3211, Val Loss: 0.3813\n",
      "Epoch [3917/10000], Train Loss: 0.3207, Val Loss: 0.3858\n",
      "Epoch [3918/10000], Train Loss: 0.3205, Val Loss: 0.3801\n",
      "Epoch [3919/10000], Train Loss: 0.3207, Val Loss: 0.3951\n",
      "Epoch [3920/10000], Train Loss: 0.3210, Val Loss: 0.4174\n",
      "Epoch [3921/10000], Train Loss: 0.3208, Val Loss: 0.3853\n",
      "Epoch [3922/10000], Train Loss: 0.3211, Val Loss: 0.3850\n",
      "Epoch [3923/10000], Train Loss: 0.3209, Val Loss: 0.3822\n",
      "Epoch [3924/10000], Train Loss: 0.3210, Val Loss: 0.4003\n",
      "Epoch [3925/10000], Train Loss: 0.3206, Val Loss: 0.3998\n",
      "Epoch [3926/10000], Train Loss: 0.3208, Val Loss: 0.3840\n",
      "Epoch [3927/10000], Train Loss: 0.3210, Val Loss: 0.3815\n",
      "Epoch [3928/10000], Train Loss: 0.3211, Val Loss: 0.3964\n",
      "Epoch [3929/10000], Train Loss: 0.3210, Val Loss: 0.4125\n",
      "Epoch [3930/10000], Train Loss: 0.3205, Val Loss: 0.3843\n",
      "Epoch [3931/10000], Train Loss: 0.3208, Val Loss: 0.3899\n",
      "Epoch [3932/10000], Train Loss: 0.3204, Val Loss: 0.3860\n",
      "Epoch [3933/10000], Train Loss: 0.3203, Val Loss: 0.3815\n",
      "Epoch [3934/10000], Train Loss: 0.3207, Val Loss: 0.4360\n",
      "Epoch [3935/10000], Train Loss: 0.3206, Val Loss: 0.4060\n",
      "Epoch [3936/10000], Train Loss: 0.3203, Val Loss: 0.3873\n",
      "Epoch [3937/10000], Train Loss: 0.3204, Val Loss: 0.4039\n",
      "Epoch [3938/10000], Train Loss: 0.3208, Val Loss: 0.4379\n",
      "Epoch [3939/10000], Train Loss: 0.3208, Val Loss: 0.3939\n",
      "Epoch [3940/10000], Train Loss: 0.3207, Val Loss: 0.3808\n",
      "Epoch [3941/10000], Train Loss: 0.3208, Val Loss: 0.3912\n",
      "Epoch [3942/10000], Train Loss: 0.3207, Val Loss: 0.3835\n",
      "Epoch [3943/10000], Train Loss: 0.3209, Val Loss: 0.4099\n",
      "Epoch [3944/10000], Train Loss: 0.3209, Val Loss: 0.3885\n",
      "Epoch [3945/10000], Train Loss: 0.3486, Val Loss: 1.1496\n",
      "Epoch [3946/10000], Train Loss: 0.3484, Val Loss: 0.3928\n",
      "Epoch [3947/10000], Train Loss: 0.3215, Val Loss: 0.4005\n",
      "Epoch [3948/10000], Train Loss: 0.3198, Val Loss: 0.3796\n",
      "Epoch [3949/10000], Train Loss: 0.3198, Val Loss: 0.3959\n",
      "Epoch [3950/10000], Train Loss: 0.3201, Val Loss: 0.3989\n",
      "Epoch [3951/10000], Train Loss: 0.3207, Val Loss: 0.3858\n",
      "Epoch [3952/10000], Train Loss: 0.3205, Val Loss: 0.3934\n",
      "Epoch [3953/10000], Train Loss: 0.3209, Val Loss: 0.3799\n",
      "Epoch [3954/10000], Train Loss: 0.3207, Val Loss: 0.3886\n",
      "Epoch [3955/10000], Train Loss: 0.3204, Val Loss: 0.3981\n",
      "Epoch [3956/10000], Train Loss: 0.3208, Val Loss: 0.4342\n",
      "Epoch [3957/10000], Train Loss: 0.3208, Val Loss: 0.4182\n",
      "Epoch [3958/10000], Train Loss: 0.3209, Val Loss: 0.3880\n",
      "Epoch [3959/10000], Train Loss: 0.3211, Val Loss: 0.3823\n",
      "Epoch [3960/10000], Train Loss: 0.3205, Val Loss: 0.3985\n",
      "Epoch [3961/10000], Train Loss: 0.3208, Val Loss: 0.4030\n",
      "Epoch [3962/10000], Train Loss: 0.3202, Val Loss: 0.3803\n",
      "Epoch [3963/10000], Train Loss: 0.3208, Val Loss: 0.3871\n",
      "Epoch [3964/10000], Train Loss: 0.3205, Val Loss: 0.3850\n",
      "Epoch [3965/10000], Train Loss: 0.3206, Val Loss: 0.3916\n",
      "Epoch [3966/10000], Train Loss: 0.3211, Val Loss: 0.3889\n",
      "Epoch [3967/10000], Train Loss: 0.3212, Val Loss: 0.4075\n",
      "Epoch [3968/10000], Train Loss: 0.3205, Val Loss: 0.3752\n",
      "Epoch [3969/10000], Train Loss: 0.3207, Val Loss: 0.4383\n",
      "Epoch [3970/10000], Train Loss: 0.3208, Val Loss: 0.3797\n",
      "Epoch [3971/10000], Train Loss: 0.3209, Val Loss: 0.3892\n",
      "Epoch [3972/10000], Train Loss: 0.3205, Val Loss: 0.3912\n",
      "Epoch [3973/10000], Train Loss: 0.3207, Val Loss: 0.3953\n",
      "Epoch [3974/10000], Train Loss: 0.3211, Val Loss: 0.3834\n",
      "Epoch [3975/10000], Train Loss: 0.3207, Val Loss: 0.3824\n",
      "Epoch [3976/10000], Train Loss: 0.3205, Val Loss: 0.4162\n",
      "Epoch [3977/10000], Train Loss: 0.3208, Val Loss: 0.3956\n",
      "Epoch [3978/10000], Train Loss: 0.3208, Val Loss: 0.3883\n",
      "Epoch [3979/10000], Train Loss: 0.3211, Val Loss: 0.3883\n",
      "Epoch [3980/10000], Train Loss: 0.3209, Val Loss: 0.4708\n",
      "Epoch [3981/10000], Train Loss: 0.3203, Val Loss: 0.3848\n",
      "Epoch [3982/10000], Train Loss: 0.3203, Val Loss: 0.3976\n",
      "Epoch [3983/10000], Train Loss: 0.3209, Val Loss: 0.3881\n",
      "Epoch [3984/10000], Train Loss: 0.3206, Val Loss: 0.4080\n",
      "Epoch [3985/10000], Train Loss: 0.3206, Val Loss: 0.4271\n",
      "Epoch [3986/10000], Train Loss: 0.3212, Val Loss: 0.3936\n",
      "Epoch [3987/10000], Train Loss: 0.3210, Val Loss: 0.4073\n",
      "Epoch [3988/10000], Train Loss: 0.3202, Val Loss: 0.3893\n",
      "Epoch [3989/10000], Train Loss: 0.3206, Val Loss: 0.3971\n",
      "Epoch [3990/10000], Train Loss: 0.3207, Val Loss: 0.3985\n",
      "Epoch [3991/10000], Train Loss: 0.3208, Val Loss: 0.4838\n",
      "Epoch [3992/10000], Train Loss: 0.3204, Val Loss: 0.3888\n",
      "Epoch [3993/10000], Train Loss: 0.3209, Val Loss: 0.4008\n",
      "Epoch [3994/10000], Train Loss: 0.3209, Val Loss: 0.3883\n",
      "Epoch [3995/10000], Train Loss: 0.3207, Val Loss: 0.3797\n",
      "Epoch [3996/10000], Train Loss: 0.3207, Val Loss: 0.3857\n",
      "Epoch [3997/10000], Train Loss: 0.3202, Val Loss: 0.4003\n",
      "Epoch [3998/10000], Train Loss: 0.3209, Val Loss: 0.3952\n",
      "Epoch [3999/10000], Train Loss: 0.3207, Val Loss: 0.3836\n",
      "Epoch [4000/10000], Train Loss: 0.3210, Val Loss: 0.3786\n",
      "Epoch [4001/10000], Train Loss: 0.3203, Val Loss: 0.3872\n",
      "Epoch [4002/10000], Train Loss: 0.3211, Val Loss: 0.3862\n",
      "Epoch [4003/10000], Train Loss: 0.3209, Val Loss: 0.3822\n",
      "Epoch [4004/10000], Train Loss: 0.3207, Val Loss: 0.3847\n",
      "Epoch [4005/10000], Train Loss: 0.3209, Val Loss: 0.3804\n",
      "Epoch [4006/10000], Train Loss: 0.3205, Val Loss: 0.3994\n",
      "Epoch [4007/10000], Train Loss: 0.3209, Val Loss: 0.3804\n",
      "Epoch [4008/10000], Train Loss: 0.3206, Val Loss: 0.4869\n",
      "Epoch [4009/10000], Train Loss: 0.3204, Val Loss: 0.3858\n",
      "Epoch [4010/10000], Train Loss: 0.3207, Val Loss: 0.3907\n",
      "Epoch [4011/10000], Train Loss: 0.3207, Val Loss: 0.3952\n",
      "Epoch [4012/10000], Train Loss: 0.3212, Val Loss: 0.4116\n",
      "Epoch [4013/10000], Train Loss: 0.3209, Val Loss: 0.3867\n",
      "Epoch [4014/10000], Train Loss: 0.3206, Val Loss: 0.4086\n",
      "Epoch [4015/10000], Train Loss: 0.3208, Val Loss: 0.3912\n",
      "Epoch [4016/10000], Train Loss: 0.3204, Val Loss: 0.3866\n",
      "Epoch [4017/10000], Train Loss: 0.3204, Val Loss: 0.3900\n",
      "Epoch [4018/10000], Train Loss: 0.3208, Val Loss: 0.4167\n",
      "Epoch [4019/10000], Train Loss: 0.3205, Val Loss: 0.3986\n",
      "Epoch [4020/10000], Train Loss: 0.3211, Val Loss: 0.3994\n",
      "Epoch [4021/10000], Train Loss: 0.3205, Val Loss: 0.3891\n",
      "Epoch [4022/10000], Train Loss: 0.3206, Val Loss: 0.4357\n",
      "Epoch [4023/10000], Train Loss: 0.3207, Val Loss: 0.3771\n",
      "Epoch [4024/10000], Train Loss: 0.3208, Val Loss: 0.4138\n",
      "Epoch [4025/10000], Train Loss: 0.3205, Val Loss: 0.3962\n",
      "Epoch [4026/10000], Train Loss: 0.3207, Val Loss: 0.3999\n",
      "Epoch [4027/10000], Train Loss: 0.3206, Val Loss: 0.3795\n",
      "Epoch [4028/10000], Train Loss: 0.3206, Val Loss: 0.3815\n",
      "Epoch [4029/10000], Train Loss: 0.3206, Val Loss: 0.3788\n",
      "Epoch [4030/10000], Train Loss: 0.3202, Val Loss: 0.4193\n",
      "Epoch [4031/10000], Train Loss: 0.3223, Val Loss: 0.3864\n",
      "Epoch [4032/10000], Train Loss: 0.3208, Val Loss: 0.3882\n",
      "Epoch [4033/10000], Train Loss: 0.3202, Val Loss: 0.3906\n",
      "Epoch [4034/10000], Train Loss: 0.3207, Val Loss: 0.3845\n",
      "Epoch [4035/10000], Train Loss: 0.3207, Val Loss: 0.3941\n",
      "Epoch [4036/10000], Train Loss: 0.3208, Val Loss: 0.3978\n",
      "Epoch [4037/10000], Train Loss: 0.3207, Val Loss: 0.3886\n",
      "Epoch [4038/10000], Train Loss: 0.3207, Val Loss: 0.3975\n",
      "Epoch [4039/10000], Train Loss: 0.3207, Val Loss: 0.4973\n",
      "Epoch [4040/10000], Train Loss: 0.3206, Val Loss: 0.4020\n",
      "Epoch [4041/10000], Train Loss: 0.3203, Val Loss: 0.4018\n",
      "Epoch [4042/10000], Train Loss: 0.3206, Val Loss: 0.3775\n",
      "Epoch [4043/10000], Train Loss: 0.3207, Val Loss: 0.3966\n",
      "Epoch [4044/10000], Train Loss: 0.3204, Val Loss: 0.3773\n",
      "Epoch [4045/10000], Train Loss: 0.3205, Val Loss: 0.3872\n",
      "Epoch [4046/10000], Train Loss: 0.3202, Val Loss: 0.5579\n",
      "Epoch [4047/10000], Train Loss: 0.3206, Val Loss: 0.3809\n",
      "Epoch [4048/10000], Train Loss: 0.3205, Val Loss: 0.4340\n",
      "Epoch [4049/10000], Train Loss: 0.3207, Val Loss: 0.3837\n",
      "Epoch [4050/10000], Train Loss: 0.3209, Val Loss: 0.3870\n",
      "Epoch [4051/10000], Train Loss: 0.3202, Val Loss: 0.4100\n",
      "Epoch [4052/10000], Train Loss: 0.3204, Val Loss: 0.3827\n",
      "Epoch [4053/10000], Train Loss: 0.3206, Val Loss: 0.3916\n",
      "Epoch [4054/10000], Train Loss: 0.3209, Val Loss: 0.4125\n",
      "Epoch [4055/10000], Train Loss: 0.3208, Val Loss: 0.3855\n",
      "Epoch [4056/10000], Train Loss: 0.3254, Val Loss: 0.3795\n",
      "Epoch [4057/10000], Train Loss: 0.3195, Val Loss: 0.3864\n",
      "Epoch [4058/10000], Train Loss: 0.3201, Val Loss: 0.3972\n",
      "Epoch [4059/10000], Train Loss: 0.3207, Val Loss: 0.3896\n",
      "Epoch [4060/10000], Train Loss: 0.3208, Val Loss: 0.3935\n",
      "Epoch [4061/10000], Train Loss: 0.3204, Val Loss: 0.4033\n",
      "Epoch [4062/10000], Train Loss: 0.3204, Val Loss: 0.3832\n",
      "Epoch [4063/10000], Train Loss: 0.3205, Val Loss: 0.4350\n",
      "Epoch [4064/10000], Train Loss: 0.3209, Val Loss: 0.3793\n",
      "Epoch [4065/10000], Train Loss: 0.3206, Val Loss: 0.3960\n",
      "Epoch [4066/10000], Train Loss: 0.3205, Val Loss: 0.3896\n",
      "Epoch [4067/10000], Train Loss: 0.3205, Val Loss: 0.4152\n",
      "Epoch [4068/10000], Train Loss: 0.3208, Val Loss: 0.3860\n",
      "Epoch [4069/10000], Train Loss: 0.3205, Val Loss: 0.4139\n",
      "Epoch [4070/10000], Train Loss: 0.3205, Val Loss: 0.3915\n",
      "Epoch [4071/10000], Train Loss: 0.3209, Val Loss: 0.3967\n",
      "Epoch [4072/10000], Train Loss: 0.3209, Val Loss: 0.3847\n",
      "Epoch [4073/10000], Train Loss: 0.3206, Val Loss: 0.4301\n",
      "Epoch [4074/10000], Train Loss: 0.3203, Val Loss: 0.4122\n",
      "Epoch [4075/10000], Train Loss: 0.3206, Val Loss: 0.3850\n",
      "Epoch [4076/10000], Train Loss: 0.3205, Val Loss: 0.3801\n",
      "Epoch [4077/10000], Train Loss: 0.3207, Val Loss: 0.3996\n",
      "Epoch [4078/10000], Train Loss: 0.3209, Val Loss: 0.3789\n",
      "Epoch [4079/10000], Train Loss: 0.3204, Val Loss: 0.4017\n",
      "Epoch [4080/10000], Train Loss: 0.3202, Val Loss: 0.4248\n",
      "Epoch [4081/10000], Train Loss: 0.3207, Val Loss: 0.3985\n",
      "Epoch [4082/10000], Train Loss: 0.3206, Val Loss: 0.4137\n",
      "Epoch [4083/10000], Train Loss: 0.3208, Val Loss: 0.3937\n",
      "Epoch [4084/10000], Train Loss: 0.3202, Val Loss: 0.3768\n",
      "Epoch [4085/10000], Train Loss: 0.3208, Val Loss: 0.3938\n",
      "Epoch [4086/10000], Train Loss: 0.3207, Val Loss: 0.3841\n",
      "Epoch [4087/10000], Train Loss: 0.3208, Val Loss: 0.4111\n",
      "Epoch [4088/10000], Train Loss: 0.3205, Val Loss: 0.4077\n",
      "Epoch [4089/10000], Train Loss: 0.3203, Val Loss: 0.3993\n",
      "Epoch [4090/10000], Train Loss: 0.3207, Val Loss: 0.3802\n",
      "Epoch [4091/10000], Train Loss: 0.3205, Val Loss: 0.3844\n",
      "Epoch [4092/10000], Train Loss: 0.3203, Val Loss: 0.3796\n",
      "Epoch [4093/10000], Train Loss: 0.3206, Val Loss: 0.3901\n",
      "Epoch [4094/10000], Train Loss: 0.3205, Val Loss: 0.3819\n",
      "Epoch [4095/10000], Train Loss: 0.3207, Val Loss: 0.3789\n",
      "Epoch [4096/10000], Train Loss: 0.3204, Val Loss: 0.4307\n",
      "Epoch [4097/10000], Train Loss: 0.3207, Val Loss: 0.3964\n",
      "Epoch [4098/10000], Train Loss: 0.3207, Val Loss: 0.3989\n",
      "Epoch [4099/10000], Train Loss: 0.3210, Val Loss: 0.3761\n",
      "Epoch [4100/10000], Train Loss: 0.3208, Val Loss: 0.3959\n",
      "Epoch [4101/10000], Train Loss: 0.3207, Val Loss: 0.4215\n",
      "Epoch [4102/10000], Train Loss: 0.3208, Val Loss: 0.4109\n",
      "Epoch [4103/10000], Train Loss: 0.3206, Val Loss: 0.3885\n",
      "Epoch [4104/10000], Train Loss: 0.3207, Val Loss: 0.3942\n",
      "Epoch [4105/10000], Train Loss: 0.3207, Val Loss: 0.3926\n",
      "Epoch [4106/10000], Train Loss: 0.3203, Val Loss: 0.3990\n",
      "Epoch [4107/10000], Train Loss: 0.3206, Val Loss: 0.4929\n",
      "Epoch [4108/10000], Train Loss: 0.3205, Val Loss: 0.4438\n",
      "Epoch [4109/10000], Train Loss: 0.3208, Val Loss: 0.3908\n",
      "Epoch [4110/10000], Train Loss: 0.3208, Val Loss: 0.3755\n",
      "Epoch [4111/10000], Train Loss: 0.3204, Val Loss: 0.3787\n",
      "Epoch [4112/10000], Train Loss: 0.3207, Val Loss: 0.3818\n",
      "Epoch [4113/10000], Train Loss: 0.3206, Val Loss: 0.3945\n",
      "Epoch [4114/10000], Train Loss: 0.3203, Val Loss: 0.4019\n",
      "Epoch [4115/10000], Train Loss: 0.3242, Val Loss: 0.4441\n",
      "Epoch [4116/10000], Train Loss: 0.3218, Val Loss: 0.3988\n",
      "Epoch [4117/10000], Train Loss: 0.3202, Val Loss: 0.3861\n",
      "Epoch [4118/10000], Train Loss: 0.3204, Val Loss: 0.4390\n",
      "Epoch [4119/10000], Train Loss: 0.3206, Val Loss: 0.4038\n",
      "Epoch [4120/10000], Train Loss: 0.3206, Val Loss: 0.3982\n",
      "Epoch [4121/10000], Train Loss: 0.3208, Val Loss: 0.3912\n",
      "Epoch [4122/10000], Train Loss: 0.3212, Val Loss: 0.3831\n",
      "Epoch [4123/10000], Train Loss: 0.3207, Val Loss: 0.3808\n",
      "Epoch [4124/10000], Train Loss: 0.3202, Val Loss: 0.4380\n",
      "Epoch [4125/10000], Train Loss: 0.3208, Val Loss: 0.3864\n",
      "Epoch [4126/10000], Train Loss: 0.3205, Val Loss: 0.3855\n",
      "Epoch [4127/10000], Train Loss: 0.3206, Val Loss: 0.3966\n",
      "Epoch [4128/10000], Train Loss: 0.3203, Val Loss: 0.3747\n",
      "Epoch [4129/10000], Train Loss: 0.3206, Val Loss: 0.3890\n",
      "Epoch [4130/10000], Train Loss: 0.3205, Val Loss: 0.3839\n",
      "Epoch [4131/10000], Train Loss: 0.3204, Val Loss: 0.3835\n",
      "Epoch [4132/10000], Train Loss: 0.3206, Val Loss: 0.3897\n",
      "Epoch [4133/10000], Train Loss: 0.3208, Val Loss: 0.3799\n",
      "Epoch [4134/10000], Train Loss: 0.3207, Val Loss: 0.3907\n",
      "Epoch [4135/10000], Train Loss: 0.3203, Val Loss: 0.3769\n",
      "Epoch [4136/10000], Train Loss: 0.3205, Val Loss: 0.3885\n",
      "Epoch [4137/10000], Train Loss: 0.3207, Val Loss: 0.3747\n",
      "Epoch [4138/10000], Train Loss: 0.3208, Val Loss: 0.4148\n",
      "Epoch [4139/10000], Train Loss: 0.3202, Val Loss: 0.3977\n",
      "Epoch [4140/10000], Train Loss: 0.3205, Val Loss: 0.3852\n",
      "Epoch [4141/10000], Train Loss: 0.3205, Val Loss: 0.3876\n",
      "Epoch [4142/10000], Train Loss: 0.3203, Val Loss: 0.3824\n",
      "Epoch [4143/10000], Train Loss: 0.3204, Val Loss: 0.4110\n",
      "Epoch [4144/10000], Train Loss: 0.3205, Val Loss: 0.3892\n",
      "Epoch [4145/10000], Train Loss: 0.3206, Val Loss: 0.4019\n",
      "Epoch [4146/10000], Train Loss: 0.3205, Val Loss: 0.3814\n",
      "Epoch [4147/10000], Train Loss: 0.3205, Val Loss: 0.5030\n",
      "Epoch [4148/10000], Train Loss: 0.3205, Val Loss: 0.3769\n",
      "Epoch [4149/10000], Train Loss: 0.3206, Val Loss: 0.4425\n",
      "Epoch [4150/10000], Train Loss: 0.3203, Val Loss: 0.3910\n",
      "Epoch [4151/10000], Train Loss: 0.3210, Val Loss: 0.4094\n",
      "Epoch [4152/10000], Train Loss: 0.3207, Val Loss: 0.3865\n",
      "Epoch [4153/10000], Train Loss: 0.3204, Val Loss: 0.3784\n",
      "Epoch [4154/10000], Train Loss: 0.3205, Val Loss: 0.4181\n",
      "Epoch [4155/10000], Train Loss: 0.3207, Val Loss: 0.3854\n",
      "Epoch [4156/10000], Train Loss: 0.3206, Val Loss: 0.4115\n",
      "Epoch [4157/10000], Train Loss: 0.3206, Val Loss: 1.3176\n",
      "Epoch [4158/10000], Train Loss: 0.3212, Val Loss: 0.3945\n",
      "Epoch [4159/10000], Train Loss: 0.3205, Val Loss: 0.3854\n",
      "Epoch [4160/10000], Train Loss: 0.3214, Val Loss: 0.3798\n",
      "Epoch [4161/10000], Train Loss: 0.3200, Val Loss: 0.4383\n",
      "Epoch [4162/10000], Train Loss: 0.3209, Val Loss: 0.3873\n",
      "Epoch [4163/10000], Train Loss: 0.3207, Val Loss: 0.3809\n",
      "Epoch [4164/10000], Train Loss: 0.3207, Val Loss: 0.3780\n",
      "Epoch [4165/10000], Train Loss: 0.3204, Val Loss: 0.3839\n",
      "Epoch [4166/10000], Train Loss: 0.3207, Val Loss: 0.3775\n",
      "Epoch [4167/10000], Train Loss: 0.3216, Val Loss: 0.4584\n",
      "Epoch [4168/10000], Train Loss: 0.3205, Val Loss: 0.3797\n",
      "Epoch [4169/10000], Train Loss: 0.3204, Val Loss: 0.3847\n",
      "Epoch [4170/10000], Train Loss: 0.3204, Val Loss: 0.3982\n",
      "Epoch [4171/10000], Train Loss: 0.3210, Val Loss: 0.4011\n",
      "Epoch [4172/10000], Train Loss: 0.3202, Val Loss: 0.3959\n",
      "Epoch [4173/10000], Train Loss: 0.3205, Val Loss: 0.3939\n",
      "Epoch [4174/10000], Train Loss: 0.3207, Val Loss: 0.3834\n",
      "Epoch [4175/10000], Train Loss: 0.3206, Val Loss: 0.3996\n",
      "Epoch [4176/10000], Train Loss: 0.3205, Val Loss: 0.3824\n",
      "Epoch [4177/10000], Train Loss: 0.3205, Val Loss: 0.3953\n",
      "Epoch [4178/10000], Train Loss: 0.3205, Val Loss: 0.3839\n",
      "Epoch [4179/10000], Train Loss: 0.3204, Val Loss: 0.4132\n",
      "Epoch [4180/10000], Train Loss: 0.3203, Val Loss: 0.4073\n",
      "Epoch [4181/10000], Train Loss: 0.3209, Val Loss: 0.3897\n",
      "Epoch [4182/10000], Train Loss: 0.3210, Val Loss: 0.3771\n",
      "Epoch [4183/10000], Train Loss: 0.3207, Val Loss: 0.3846\n",
      "Epoch [4184/10000], Train Loss: 0.3207, Val Loss: 0.3827\n",
      "Epoch [4185/10000], Train Loss: 0.3206, Val Loss: 0.3762\n",
      "Epoch [4186/10000], Train Loss: 0.3207, Val Loss: 0.3804\n",
      "Epoch [4187/10000], Train Loss: 0.3205, Val Loss: 0.3835\n",
      "Epoch [4188/10000], Train Loss: 0.3203, Val Loss: 0.3799\n",
      "Epoch [4189/10000], Train Loss: 0.3206, Val Loss: 0.3791\n",
      "Epoch [4190/10000], Train Loss: 0.3205, Val Loss: 0.4057\n",
      "Epoch [4191/10000], Train Loss: 0.3208, Val Loss: 0.3883\n",
      "Epoch [4192/10000], Train Loss: 0.3201, Val Loss: 0.3921\n",
      "Epoch [4193/10000], Train Loss: 0.3211, Val Loss: 0.3829\n",
      "Epoch [4194/10000], Train Loss: 0.3210, Val Loss: 0.3823\n",
      "Epoch [4195/10000], Train Loss: 0.3205, Val Loss: 0.3853\n",
      "Epoch [4196/10000], Train Loss: 0.3204, Val Loss: 0.4415\n",
      "Epoch [4197/10000], Train Loss: 0.3206, Val Loss: 0.3914\n",
      "Epoch [4198/10000], Train Loss: 0.3207, Val Loss: 0.3901\n",
      "Epoch [4199/10000], Train Loss: 0.3206, Val Loss: 0.4180\n",
      "Epoch [4200/10000], Train Loss: 0.3204, Val Loss: 0.3856\n",
      "Epoch [4201/10000], Train Loss: 0.3203, Val Loss: 0.3792\n",
      "Epoch [4202/10000], Train Loss: 0.3205, Val Loss: 0.3877\n",
      "Epoch [4203/10000], Train Loss: 0.3204, Val Loss: 0.3754\n",
      "Epoch [4204/10000], Train Loss: 0.3205, Val Loss: 0.3774\n",
      "Epoch [4205/10000], Train Loss: 0.3206, Val Loss: 0.4079\n",
      "Epoch [4206/10000], Train Loss: 0.3208, Val Loss: 0.4101\n",
      "Epoch [4207/10000], Train Loss: 0.3207, Val Loss: 0.3745\n",
      "Epoch [4208/10000], Train Loss: 0.3209, Val Loss: 0.3804\n",
      "Epoch [4209/10000], Train Loss: 0.3203, Val Loss: 0.3964\n",
      "Epoch [4210/10000], Train Loss: 0.3205, Val Loss: 0.4223\n",
      "Epoch [4211/10000], Train Loss: 0.3211, Val Loss: 0.4141\n",
      "Epoch [4212/10000], Train Loss: 0.3202, Val Loss: 0.3867\n",
      "Epoch [4213/10000], Train Loss: 0.3204, Val Loss: 0.3855\n",
      "Epoch [4214/10000], Train Loss: 0.3203, Val Loss: 0.4104\n",
      "Epoch [4215/10000], Train Loss: 0.3210, Val Loss: 0.4135\n",
      "Epoch [4216/10000], Train Loss: 0.3204, Val Loss: 0.4015\n",
      "Epoch [4217/10000], Train Loss: 0.3201, Val Loss: 0.4423\n",
      "Epoch [4218/10000], Train Loss: 0.3202, Val Loss: 0.3802\n",
      "Epoch [4219/10000], Train Loss: 0.3204, Val Loss: 0.3738\n",
      "Epoch [4220/10000], Train Loss: 0.3206, Val Loss: 0.3797\n",
      "Epoch [4221/10000], Train Loss: 0.3206, Val Loss: 0.3829\n",
      "Epoch [4222/10000], Train Loss: 0.3203, Val Loss: 0.3771\n",
      "Epoch [4223/10000], Train Loss: 0.3207, Val Loss: 0.3898\n",
      "Epoch [4224/10000], Train Loss: 0.3202, Val Loss: 0.4199\n",
      "Epoch [4225/10000], Train Loss: 0.3204, Val Loss: 0.4015\n",
      "Epoch [4226/10000], Train Loss: 0.3203, Val Loss: 0.4013\n",
      "Epoch [4227/10000], Train Loss: 0.3206, Val Loss: 0.4035\n",
      "Epoch [4228/10000], Train Loss: 0.3202, Val Loss: 0.3736\n",
      "Epoch [4229/10000], Train Loss: 0.3205, Val Loss: 0.3984\n",
      "Epoch [4230/10000], Train Loss: 0.3202, Val Loss: 0.3861\n",
      "Epoch [4231/10000], Train Loss: 0.3206, Val Loss: 0.3757\n",
      "Epoch [4232/10000], Train Loss: 0.3201, Val Loss: 0.3895\n",
      "Epoch [4233/10000], Train Loss: 0.3205, Val Loss: 0.4324\n",
      "Epoch [4234/10000], Train Loss: 0.3203, Val Loss: 0.3979\n",
      "Epoch [4235/10000], Train Loss: 0.3209, Val Loss: 0.3764\n",
      "Epoch [4236/10000], Train Loss: 0.3314, Val Loss: 0.4176\n",
      "Epoch [4237/10000], Train Loss: 0.3217, Val Loss: 0.3804\n",
      "Epoch [4238/10000], Train Loss: 0.3199, Val Loss: 0.3779\n",
      "Epoch [4239/10000], Train Loss: 0.3197, Val Loss: 0.3790\n",
      "Epoch [4240/10000], Train Loss: 0.3208, Val Loss: 0.3829\n",
      "Epoch [4241/10000], Train Loss: 0.3205, Val Loss: 0.3897\n",
      "Epoch [4242/10000], Train Loss: 0.3207, Val Loss: 0.3826\n",
      "Epoch [4243/10000], Train Loss: 0.3204, Val Loss: 0.3810\n",
      "Epoch [4244/10000], Train Loss: 0.3206, Val Loss: 0.3848\n",
      "Epoch [4245/10000], Train Loss: 0.3207, Val Loss: 0.3812\n",
      "Epoch [4246/10000], Train Loss: 0.3203, Val Loss: 0.4202\n",
      "Epoch [4247/10000], Train Loss: 0.3208, Val Loss: 0.3779\n",
      "Epoch [4248/10000], Train Loss: 0.3206, Val Loss: 0.3836\n",
      "Epoch [4249/10000], Train Loss: 0.3205, Val Loss: 0.3840\n",
      "Epoch [4250/10000], Train Loss: 0.3209, Val Loss: 0.3831\n",
      "Epoch [4251/10000], Train Loss: 0.3202, Val Loss: 0.3975\n",
      "Epoch [4252/10000], Train Loss: 0.3205, Val Loss: 0.4038\n",
      "Epoch [4253/10000], Train Loss: 0.3205, Val Loss: 0.3848\n",
      "Epoch [4254/10000], Train Loss: 0.3206, Val Loss: 0.3886\n",
      "Epoch [4255/10000], Train Loss: 0.3209, Val Loss: 0.4254\n",
      "Epoch [4256/10000], Train Loss: 0.3204, Val Loss: 0.4380\n",
      "Epoch [4257/10000], Train Loss: 0.3205, Val Loss: 0.4130\n",
      "Epoch [4258/10000], Train Loss: 0.3211, Val Loss: 0.3911\n",
      "Epoch [4259/10000], Train Loss: 0.3207, Val Loss: 0.3780\n",
      "Epoch [4260/10000], Train Loss: 0.3202, Val Loss: 0.3805\n",
      "Epoch [4261/10000], Train Loss: 0.3206, Val Loss: 0.3826\n",
      "Epoch [4262/10000], Train Loss: 0.3206, Val Loss: 0.3990\n",
      "Epoch [4263/10000], Train Loss: 0.3208, Val Loss: 0.3887\n",
      "Epoch [4264/10000], Train Loss: 0.3208, Val Loss: 0.3823\n",
      "Epoch [4265/10000], Train Loss: 0.3203, Val Loss: 0.3753\n",
      "Epoch [4266/10000], Train Loss: 0.3203, Val Loss: 0.4011\n",
      "Epoch [4267/10000], Train Loss: 0.3209, Val Loss: 0.3843\n",
      "Epoch [4268/10000], Train Loss: 0.3210, Val Loss: 0.3958\n",
      "Epoch [4269/10000], Train Loss: 0.3204, Val Loss: 0.3829\n",
      "Epoch [4270/10000], Train Loss: 0.3202, Val Loss: 0.3746\n",
      "Epoch [4271/10000], Train Loss: 0.3203, Val Loss: 0.3985\n",
      "Epoch [4272/10000], Train Loss: 0.3205, Val Loss: 0.3799\n",
      "Epoch [4273/10000], Train Loss: 0.3202, Val Loss: 0.3942\n",
      "Epoch [4274/10000], Train Loss: 0.3203, Val Loss: 0.3754\n",
      "Epoch [4275/10000], Train Loss: 0.3201, Val Loss: 0.4131\n",
      "Epoch [4276/10000], Train Loss: 0.3210, Val Loss: 0.4166\n",
      "Epoch [4277/10000], Train Loss: 0.3210, Val Loss: 0.3762\n",
      "Epoch [4278/10000], Train Loss: 0.3204, Val Loss: 0.3906\n",
      "Epoch [4279/10000], Train Loss: 0.3203, Val Loss: 0.4016\n",
      "Epoch [4280/10000], Train Loss: 0.3202, Val Loss: 0.3924\n",
      "Epoch [4281/10000], Train Loss: 0.3204, Val Loss: 0.3849\n",
      "Epoch [4282/10000], Train Loss: 0.3204, Val Loss: 0.4168\n",
      "Epoch [4283/10000], Train Loss: 0.3204, Val Loss: 0.4334\n",
      "Epoch [4284/10000], Train Loss: 0.3208, Val Loss: 0.3863\n",
      "Epoch [4285/10000], Train Loss: 0.3204, Val Loss: 0.3857\n",
      "Epoch [4286/10000], Train Loss: 0.3204, Val Loss: 0.3808\n",
      "Epoch [4287/10000], Train Loss: 0.3206, Val Loss: 0.3807\n",
      "Epoch [4288/10000], Train Loss: 0.3206, Val Loss: 0.3948\n",
      "Epoch [4289/10000], Train Loss: 0.3210, Val Loss: 0.3766\n",
      "Epoch [4290/10000], Train Loss: 0.3203, Val Loss: 0.3781\n",
      "Epoch [4291/10000], Train Loss: 0.3203, Val Loss: 0.4000\n",
      "Epoch [4292/10000], Train Loss: 0.3209, Val Loss: 0.3917\n",
      "Epoch [4293/10000], Train Loss: 0.3205, Val Loss: 0.3826\n",
      "Epoch [4294/10000], Train Loss: 0.3204, Val Loss: 0.3973\n",
      "Epoch [4295/10000], Train Loss: 0.3202, Val Loss: 0.4090\n",
      "Epoch [4296/10000], Train Loss: 0.3209, Val Loss: 0.3836\n",
      "Epoch [4297/10000], Train Loss: 0.3203, Val Loss: 0.4226\n",
      "Epoch [4298/10000], Train Loss: 0.3208, Val Loss: 0.3860\n",
      "Epoch [4299/10000], Train Loss: 0.3205, Val Loss: 0.4436\n",
      "Epoch [4300/10000], Train Loss: 0.3207, Val Loss: 0.3858\n",
      "Epoch [4301/10000], Train Loss: 0.3207, Val Loss: 0.3802\n",
      "Epoch [4302/10000], Train Loss: 0.3203, Val Loss: 0.3907\n",
      "Epoch [4303/10000], Train Loss: 0.3206, Val Loss: 0.3977\n",
      "Epoch [4304/10000], Train Loss: 0.3206, Val Loss: 0.4127\n",
      "Epoch [4305/10000], Train Loss: 0.3205, Val Loss: 0.3764\n",
      "Epoch [4306/10000], Train Loss: 0.3201, Val Loss: 0.4257\n",
      "Epoch [4307/10000], Train Loss: 0.3213, Val Loss: 0.4358\n",
      "Epoch [4308/10000], Train Loss: 0.3206, Val Loss: 0.3840\n",
      "Epoch [4309/10000], Train Loss: 0.3208, Val Loss: 0.3922\n",
      "Epoch [4310/10000], Train Loss: 0.3205, Val Loss: 0.3804\n",
      "Epoch [4311/10000], Train Loss: 0.3207, Val Loss: 0.4031\n",
      "Epoch [4312/10000], Train Loss: 0.3204, Val Loss: 0.3979\n",
      "Epoch [4313/10000], Train Loss: 0.3206, Val Loss: 0.3785\n",
      "Epoch [4314/10000], Train Loss: 0.3206, Val Loss: 0.3892\n",
      "Epoch [4315/10000], Train Loss: 0.3210, Val Loss: 0.3754\n",
      "Epoch [4316/10000], Train Loss: 0.3210, Val Loss: 0.4339\n",
      "Epoch [4317/10000], Train Loss: 0.3210, Val Loss: 0.4030\n",
      "Epoch [4318/10000], Train Loss: 0.3205, Val Loss: 0.4000\n",
      "Epoch [4319/10000], Train Loss: 0.3204, Val Loss: 0.4286\n",
      "Epoch [4320/10000], Train Loss: 0.3207, Val Loss: 0.4473\n",
      "Epoch [4321/10000], Train Loss: 0.3206, Val Loss: 0.3818\n",
      "Epoch [4322/10000], Train Loss: 0.3203, Val Loss: 0.3934\n",
      "Epoch [4323/10000], Train Loss: 0.3203, Val Loss: 0.3895\n",
      "Epoch [4324/10000], Train Loss: 0.3203, Val Loss: 0.3818\n",
      "Epoch [4325/10000], Train Loss: 0.3203, Val Loss: 0.3904\n",
      "Epoch [4326/10000], Train Loss: 0.3209, Val Loss: 0.4596\n",
      "Epoch [4327/10000], Train Loss: 0.3208, Val Loss: 0.4023\n",
      "Epoch [4328/10000], Train Loss: 0.3204, Val Loss: 0.3767\n",
      "Epoch [4329/10000], Train Loss: 0.3203, Val Loss: 0.3879\n",
      "Epoch [4330/10000], Train Loss: 0.3205, Val Loss: 0.3758\n",
      "Epoch [4331/10000], Train Loss: 0.3203, Val Loss: 0.3841\n",
      "Epoch [4332/10000], Train Loss: 0.3204, Val Loss: 0.3769\n",
      "Epoch [4333/10000], Train Loss: 0.3201, Val Loss: 0.3753\n",
      "Epoch [4334/10000], Train Loss: 0.3205, Val Loss: 0.3984\n",
      "Epoch [4335/10000], Train Loss: 0.3205, Val Loss: 0.3851\n",
      "Epoch [4336/10000], Train Loss: 0.3203, Val Loss: 0.3803\n",
      "Epoch [4337/10000], Train Loss: 0.3204, Val Loss: 0.3896\n",
      "Epoch [4338/10000], Train Loss: 0.3205, Val Loss: 0.3763\n",
      "Epoch [4339/10000], Train Loss: 0.3204, Val Loss: 0.3938\n",
      "Epoch [4340/10000], Train Loss: 0.3204, Val Loss: 0.3902\n",
      "Epoch [4341/10000], Train Loss: 0.3206, Val Loss: 0.3885\n",
      "Epoch [4342/10000], Train Loss: 0.3205, Val Loss: 0.3772\n",
      "Epoch [4343/10000], Train Loss: 0.3204, Val Loss: 0.4029\n",
      "Epoch [4344/10000], Train Loss: 0.3209, Val Loss: 0.4807\n",
      "Epoch [4345/10000], Train Loss: 0.3202, Val Loss: 0.3824\n",
      "Epoch [4346/10000], Train Loss: 0.3200, Val Loss: 0.4035\n",
      "Epoch [4347/10000], Train Loss: 0.3205, Val Loss: 0.4079\n",
      "Epoch [4348/10000], Train Loss: 0.3206, Val Loss: 0.3839\n",
      "Epoch [4349/10000], Train Loss: 0.3207, Val Loss: 0.3999\n",
      "Epoch [4350/10000], Train Loss: 0.3201, Val Loss: 0.4448\n",
      "Epoch [4351/10000], Train Loss: 0.3206, Val Loss: 0.3845\n",
      "Epoch [4352/10000], Train Loss: 0.3206, Val Loss: 0.4381\n",
      "Epoch [4353/10000], Train Loss: 0.3206, Val Loss: 0.3771\n",
      "Epoch [4354/10000], Train Loss: 0.3204, Val Loss: 0.3801\n",
      "Epoch [4355/10000], Train Loss: 0.3204, Val Loss: 0.3795\n",
      "Epoch [4356/10000], Train Loss: 0.3207, Val Loss: 0.3756\n",
      "Epoch [4357/10000], Train Loss: 0.3207, Val Loss: 0.3819\n",
      "Epoch [4358/10000], Train Loss: 0.3206, Val Loss: 0.3839\n",
      "Epoch [4359/10000], Train Loss: 0.3205, Val Loss: 0.3822\n",
      "Epoch [4360/10000], Train Loss: 0.3209, Val Loss: 0.3777\n",
      "Epoch [4361/10000], Train Loss: 0.3205, Val Loss: 0.3820\n",
      "Epoch [4362/10000], Train Loss: 0.3207, Val Loss: 0.4022\n",
      "Epoch [4363/10000], Train Loss: 0.3202, Val Loss: 0.3892\n",
      "Epoch [4364/10000], Train Loss: 0.3208, Val Loss: 0.3829\n",
      "Epoch [4365/10000], Train Loss: 0.3201, Val Loss: 0.3904\n",
      "Epoch [4366/10000], Train Loss: 0.3203, Val Loss: 0.4465\n",
      "Epoch [4367/10000], Train Loss: 0.3203, Val Loss: 0.4045\n",
      "Epoch [4368/10000], Train Loss: 0.3205, Val Loss: 0.3825\n",
      "Epoch [4369/10000], Train Loss: 0.3206, Val Loss: 0.3761\n",
      "Epoch [4370/10000], Train Loss: 0.3207, Val Loss: 0.3855\n",
      "Epoch [4371/10000], Train Loss: 0.3204, Val Loss: 0.3799\n",
      "Epoch [4372/10000], Train Loss: 0.3208, Val Loss: 0.3790\n",
      "Epoch [4373/10000], Train Loss: 0.3203, Val Loss: 0.4208\n",
      "Epoch [4374/10000], Train Loss: 0.3207, Val Loss: 0.3978\n",
      "Epoch [4375/10000], Train Loss: 0.3205, Val Loss: 0.4090\n",
      "Epoch [4376/10000], Train Loss: 0.3207, Val Loss: 0.4025\n",
      "Epoch [4377/10000], Train Loss: 0.3206, Val Loss: 0.5755\n",
      "Epoch [4378/10000], Train Loss: 0.3205, Val Loss: 0.3869\n",
      "Epoch [4379/10000], Train Loss: 0.3207, Val Loss: 0.3920\n",
      "Epoch [4380/10000], Train Loss: 0.3207, Val Loss: 0.3768\n",
      "Epoch [4381/10000], Train Loss: 0.3208, Val Loss: 0.3783\n",
      "Epoch [4382/10000], Train Loss: 0.3201, Val Loss: 0.4070\n",
      "Epoch [4383/10000], Train Loss: 0.3206, Val Loss: 0.3814\n",
      "Epoch [4384/10000], Train Loss: 0.3200, Val Loss: 0.3922\n",
      "Epoch [4385/10000], Train Loss: 0.3205, Val Loss: 0.3765\n",
      "Epoch [4386/10000], Train Loss: 0.3205, Val Loss: 0.3773\n",
      "Epoch [4387/10000], Train Loss: 0.3208, Val Loss: 0.3866\n",
      "Epoch [4388/10000], Train Loss: 0.3202, Val Loss: 0.4052\n",
      "Epoch [4389/10000], Train Loss: 0.3204, Val Loss: 0.3929\n",
      "Epoch [4390/10000], Train Loss: 0.3207, Val Loss: 0.3933\n",
      "Epoch [4391/10000], Train Loss: 0.3202, Val Loss: 0.3781\n",
      "Epoch [4392/10000], Train Loss: 0.3206, Val Loss: 0.3892\n",
      "Epoch [4393/10000], Train Loss: 0.3202, Val Loss: 0.3779\n",
      "Epoch [4394/10000], Train Loss: 0.3205, Val Loss: 0.3999\n",
      "Epoch [4395/10000], Train Loss: 0.3205, Val Loss: 0.3825\n",
      "Epoch [4396/10000], Train Loss: 0.3207, Val Loss: 0.3925\n",
      "Epoch [4397/10000], Train Loss: 0.3204, Val Loss: 0.3881\n",
      "Epoch [4398/10000], Train Loss: 0.3204, Val Loss: 0.3766\n",
      "Epoch [4399/10000], Train Loss: 0.3203, Val Loss: 0.3827\n",
      "Epoch [4400/10000], Train Loss: 0.3205, Val Loss: 0.3849\n",
      "Epoch [4401/10000], Train Loss: 0.3206, Val Loss: 0.4348\n",
      "Epoch [4402/10000], Train Loss: 0.3203, Val Loss: 0.3790\n",
      "Epoch [4403/10000], Train Loss: 0.3206, Val Loss: 0.3944\n",
      "Epoch [4404/10000], Train Loss: 0.3204, Val Loss: 0.3837\n",
      "Epoch [4405/10000], Train Loss: 0.3203, Val Loss: 0.3859\n",
      "Epoch [4406/10000], Train Loss: 0.3198, Val Loss: 0.4507\n",
      "Epoch [4407/10000], Train Loss: 0.3205, Val Loss: 0.3844\n",
      "Epoch [4408/10000], Train Loss: 0.3205, Val Loss: 0.4091\n",
      "Epoch [4409/10000], Train Loss: 0.3211, Val Loss: 0.3791\n",
      "Epoch [4410/10000], Train Loss: 0.3206, Val Loss: 0.3785\n",
      "Epoch [4411/10000], Train Loss: 0.3203, Val Loss: 0.3824\n",
      "Epoch [4412/10000], Train Loss: 0.3201, Val Loss: 0.3790\n",
      "Epoch [4413/10000], Train Loss: 0.3202, Val Loss: 0.3827\n",
      "Epoch [4414/10000], Train Loss: 0.3203, Val Loss: 0.3817\n",
      "Epoch [4415/10000], Train Loss: 0.3204, Val Loss: 0.3965\n",
      "Epoch [4416/10000], Train Loss: 0.3203, Val Loss: 0.3747\n",
      "Epoch [4417/10000], Train Loss: 0.3210, Val Loss: 0.3791\n",
      "Epoch [4418/10000], Train Loss: 0.3204, Val Loss: 0.4032\n",
      "Epoch [4419/10000], Train Loss: 0.3293, Val Loss: 0.5888\n",
      "Epoch [4420/10000], Train Loss: 0.3302, Val Loss: 0.3980\n",
      "Epoch [4421/10000], Train Loss: 0.3223, Val Loss: 0.3938\n",
      "Epoch [4422/10000], Train Loss: 0.3202, Val Loss: 0.3745\n",
      "Epoch [4423/10000], Train Loss: 0.3201, Val Loss: 0.4063\n",
      "Epoch [4424/10000], Train Loss: 0.3209, Val Loss: 0.3826\n",
      "Epoch [4425/10000], Train Loss: 0.3203, Val Loss: 0.3839\n",
      "Epoch [4426/10000], Train Loss: 0.3203, Val Loss: 0.3896\n",
      "Epoch [4427/10000], Train Loss: 0.3208, Val Loss: 0.3879\n",
      "Epoch [4428/10000], Train Loss: 0.3208, Val Loss: 0.3910\n",
      "Epoch [4429/10000], Train Loss: 0.3198, Val Loss: 0.3896\n",
      "Epoch [4430/10000], Train Loss: 0.3202, Val Loss: 0.3824\n",
      "Epoch [4431/10000], Train Loss: 0.3204, Val Loss: 0.3914\n",
      "Epoch [4432/10000], Train Loss: 0.3203, Val Loss: 0.4049\n",
      "Epoch [4433/10000], Train Loss: 0.3201, Val Loss: 0.4040\n",
      "Epoch [4434/10000], Train Loss: 0.3207, Val Loss: 0.3885\n",
      "Epoch [4435/10000], Train Loss: 0.3205, Val Loss: 0.3888\n",
      "Epoch [4436/10000], Train Loss: 0.3204, Val Loss: 0.3801\n",
      "Epoch [4437/10000], Train Loss: 0.3202, Val Loss: 0.3912\n",
      "Epoch [4438/10000], Train Loss: 0.3204, Val Loss: 0.3968\n",
      "Epoch [4439/10000], Train Loss: 0.3204, Val Loss: 0.4130\n",
      "Epoch [4440/10000], Train Loss: 0.3201, Val Loss: 0.3884\n",
      "Epoch [4441/10000], Train Loss: 0.3230, Val Loss: 0.4294\n",
      "Epoch [4442/10000], Train Loss: 0.3200, Val Loss: 0.3804\n",
      "Epoch [4443/10000], Train Loss: 0.3199, Val Loss: 0.3880\n",
      "Epoch [4444/10000], Train Loss: 0.3199, Val Loss: 0.3903\n",
      "Epoch [4445/10000], Train Loss: 0.3209, Val Loss: 0.3958\n",
      "Epoch [4446/10000], Train Loss: 0.3202, Val Loss: 0.4225\n",
      "Epoch [4447/10000], Train Loss: 0.3205, Val Loss: 0.4084\n",
      "Epoch [4448/10000], Train Loss: 0.3204, Val Loss: 0.3869\n",
      "Epoch [4449/10000], Train Loss: 0.3204, Val Loss: 0.3853\n",
      "Epoch [4450/10000], Train Loss: 0.3208, Val Loss: 0.4062\n",
      "Epoch [4451/10000], Train Loss: 0.3202, Val Loss: 0.4437\n",
      "Epoch [4452/10000], Train Loss: 0.3208, Val Loss: 0.3928\n",
      "Epoch [4453/10000], Train Loss: 0.3209, Val Loss: 0.3889\n",
      "Epoch [4454/10000], Train Loss: 0.3202, Val Loss: 0.3847\n",
      "Epoch [4455/10000], Train Loss: 0.3252, Val Loss: 0.4214\n",
      "Epoch [4456/10000], Train Loss: 0.3225, Val Loss: 0.3829\n",
      "Epoch [4457/10000], Train Loss: 0.3212, Val Loss: 0.3810\n",
      "Epoch [4458/10000], Train Loss: 0.3203, Val Loss: 0.3814\n",
      "Epoch [4459/10000], Train Loss: 0.3202, Val Loss: 0.3887\n",
      "Epoch [4460/10000], Train Loss: 0.3205, Val Loss: 0.4579\n",
      "Epoch [4461/10000], Train Loss: 0.3204, Val Loss: 0.3905\n",
      "Epoch [4462/10000], Train Loss: 0.3207, Val Loss: 0.3762\n",
      "Epoch [4463/10000], Train Loss: 0.3203, Val Loss: 0.3798\n",
      "Epoch [4464/10000], Train Loss: 0.3204, Val Loss: 0.4060\n",
      "Epoch [4465/10000], Train Loss: 0.3207, Val Loss: 0.3809\n",
      "Epoch [4466/10000], Train Loss: 0.3203, Val Loss: 0.3906\n",
      "Epoch [4467/10000], Train Loss: 0.3205, Val Loss: 0.4303\n",
      "Epoch [4468/10000], Train Loss: 0.3203, Val Loss: 0.3885\n",
      "Epoch [4469/10000], Train Loss: 0.3202, Val Loss: 0.3991\n",
      "Epoch [4470/10000], Train Loss: 0.3205, Val Loss: 0.3945\n",
      "Epoch [4471/10000], Train Loss: 0.3203, Val Loss: 0.3981\n",
      "Epoch [4472/10000], Train Loss: 0.3207, Val Loss: 0.3786\n",
      "Epoch [4473/10000], Train Loss: 0.3204, Val Loss: 0.3805\n",
      "Epoch [4474/10000], Train Loss: 0.3203, Val Loss: 0.3901\n",
      "Epoch [4475/10000], Train Loss: 0.3204, Val Loss: 0.3828\n",
      "Epoch [4476/10000], Train Loss: 0.3208, Val Loss: 0.4411\n",
      "Epoch [4477/10000], Train Loss: 0.3203, Val Loss: 0.3779\n",
      "Epoch [4478/10000], Train Loss: 0.3209, Val Loss: 0.4129\n",
      "Epoch [4479/10000], Train Loss: 0.3203, Val Loss: 0.3931\n",
      "Epoch [4480/10000], Train Loss: 0.3204, Val Loss: 0.3888\n",
      "Epoch [4481/10000], Train Loss: 0.3204, Val Loss: 0.3777\n",
      "Epoch [4482/10000], Train Loss: 0.3205, Val Loss: 0.3813\n",
      "Epoch [4483/10000], Train Loss: 0.3208, Val Loss: 0.3784\n",
      "Epoch [4484/10000], Train Loss: 0.3202, Val Loss: 0.3847\n",
      "Epoch [4485/10000], Train Loss: 0.3205, Val Loss: 0.3792\n",
      "Epoch [4486/10000], Train Loss: 0.3206, Val Loss: 0.3766\n",
      "Epoch [4487/10000], Train Loss: 0.3205, Val Loss: 0.3879\n",
      "Epoch [4488/10000], Train Loss: 0.3204, Val Loss: 0.4017\n",
      "Epoch [4489/10000], Train Loss: 0.3205, Val Loss: 0.4051\n",
      "Epoch [4490/10000], Train Loss: 0.3209, Val Loss: 0.4005\n",
      "Epoch [4491/10000], Train Loss: 0.3208, Val Loss: 0.4156\n",
      "Epoch [4492/10000], Train Loss: 0.3209, Val Loss: 0.3912\n",
      "Epoch [4493/10000], Train Loss: 0.3203, Val Loss: 0.3894\n",
      "Epoch [4494/10000], Train Loss: 0.3208, Val Loss: 0.3795\n",
      "Epoch [4495/10000], Train Loss: 0.3208, Val Loss: 0.3960\n",
      "Epoch [4496/10000], Train Loss: 0.3205, Val Loss: 0.3866\n",
      "Epoch [4497/10000], Train Loss: 0.3206, Val Loss: 0.4013\n",
      "Epoch [4498/10000], Train Loss: 0.3202, Val Loss: 0.4727\n",
      "Epoch [4499/10000], Train Loss: 0.3341, Val Loss: 0.6372\n",
      "Epoch [4500/10000], Train Loss: 0.3289, Val Loss: 0.4375\n",
      "Epoch [4501/10000], Train Loss: 0.3241, Val Loss: 0.4199\n",
      "Epoch [4502/10000], Train Loss: 0.3220, Val Loss: 0.5016\n",
      "Epoch [4503/10000], Train Loss: 0.3210, Val Loss: 0.4093\n",
      "Epoch [4504/10000], Train Loss: 0.3199, Val Loss: 0.3913\n",
      "Epoch [4505/10000], Train Loss: 0.3204, Val Loss: 0.3980\n",
      "Epoch [4506/10000], Train Loss: 0.3207, Val Loss: 0.3991\n",
      "Epoch [4507/10000], Train Loss: 0.3208, Val Loss: 0.3974\n",
      "Epoch [4508/10000], Train Loss: 0.3205, Val Loss: 0.3757\n",
      "Epoch [4509/10000], Train Loss: 0.3208, Val Loss: 0.3817\n",
      "Epoch [4510/10000], Train Loss: 0.3208, Val Loss: 0.3942\n",
      "Epoch [4511/10000], Train Loss: 0.3205, Val Loss: 0.3920\n",
      "Epoch [4512/10000], Train Loss: 0.3210, Val Loss: 0.3863\n",
      "Epoch [4513/10000], Train Loss: 0.3206, Val Loss: 0.3966\n",
      "Epoch [4514/10000], Train Loss: 0.3204, Val Loss: 0.4033\n",
      "Epoch [4515/10000], Train Loss: 0.3205, Val Loss: 0.3833\n",
      "Epoch [4516/10000], Train Loss: 0.3203, Val Loss: 0.3865\n",
      "Epoch [4517/10000], Train Loss: 0.3204, Val Loss: 0.3831\n",
      "Epoch [4518/10000], Train Loss: 0.3206, Val Loss: 0.4213\n",
      "Epoch [4519/10000], Train Loss: 0.3202, Val Loss: 0.4005\n",
      "Epoch [4520/10000], Train Loss: 0.3207, Val Loss: 0.3866\n",
      "Epoch [4521/10000], Train Loss: 0.3207, Val Loss: 0.4290\n",
      "Epoch [4522/10000], Train Loss: 0.3201, Val Loss: 0.3778\n",
      "Epoch [4523/10000], Train Loss: 0.3201, Val Loss: 0.3740\n",
      "Epoch [4524/10000], Train Loss: 0.3206, Val Loss: 0.3895\n",
      "Epoch [4525/10000], Train Loss: 0.3202, Val Loss: 0.3811\n",
      "Epoch [4526/10000], Train Loss: 0.3203, Val Loss: 0.3878\n",
      "Epoch [4527/10000], Train Loss: 0.3210, Val Loss: 0.3788\n",
      "Epoch [4528/10000], Train Loss: 0.3205, Val Loss: 0.3841\n",
      "Epoch [4529/10000], Train Loss: 0.3203, Val Loss: 0.4512\n",
      "Epoch [4530/10000], Train Loss: 0.3206, Val Loss: 0.3760\n",
      "Epoch [4531/10000], Train Loss: 0.3206, Val Loss: 0.3912\n",
      "Epoch [4532/10000], Train Loss: 0.3202, Val Loss: 0.3823\n",
      "Epoch [4533/10000], Train Loss: 0.3206, Val Loss: 0.4893\n",
      "Epoch [4534/10000], Train Loss: 0.3208, Val Loss: 0.3934\n",
      "Epoch [4535/10000], Train Loss: 0.3208, Val Loss: 0.4355\n",
      "Epoch [4536/10000], Train Loss: 0.3205, Val Loss: 0.3818\n",
      "Epoch [4537/10000], Train Loss: 0.3202, Val Loss: 0.5898\n",
      "Epoch [4538/10000], Train Loss: 0.3207, Val Loss: 0.4219\n",
      "Epoch [4539/10000], Train Loss: 0.3203, Val Loss: 0.3789\n",
      "Epoch [4540/10000], Train Loss: 0.3204, Val Loss: 0.3782\n",
      "Epoch [4541/10000], Train Loss: 0.3204, Val Loss: 0.3813\n",
      "Epoch [4542/10000], Train Loss: 0.3203, Val Loss: 0.3813\n",
      "Epoch [4543/10000], Train Loss: 0.3205, Val Loss: 0.3826\n",
      "Epoch [4544/10000], Train Loss: 0.3205, Val Loss: 0.3944\n",
      "Epoch [4545/10000], Train Loss: 0.3203, Val Loss: 0.4079\n",
      "Epoch [4546/10000], Train Loss: 0.3207, Val Loss: 0.3754\n",
      "Epoch [4547/10000], Train Loss: 0.3204, Val Loss: 0.3862\n",
      "Epoch [4548/10000], Train Loss: 0.3207, Val Loss: 0.4127\n",
      "Epoch [4549/10000], Train Loss: 0.3205, Val Loss: 0.4169\n",
      "Epoch [4550/10000], Train Loss: 0.3205, Val Loss: 0.4082\n",
      "Epoch [4551/10000], Train Loss: 0.3208, Val Loss: 0.3813\n",
      "Epoch [4552/10000], Train Loss: 0.3200, Val Loss: 0.4363\n",
      "Epoch [4553/10000], Train Loss: 0.3206, Val Loss: 0.3998\n",
      "Epoch [4554/10000], Train Loss: 0.3204, Val Loss: 0.3891\n",
      "Epoch [4555/10000], Train Loss: 0.3203, Val Loss: 0.4163\n",
      "Epoch [4556/10000], Train Loss: 0.3199, Val Loss: 0.3855\n",
      "Epoch [4557/10000], Train Loss: 0.3201, Val Loss: 0.3835\n",
      "Epoch [4558/10000], Train Loss: 0.3205, Val Loss: 0.3837\n",
      "Epoch [4559/10000], Train Loss: 0.3203, Val Loss: 0.3783\n",
      "Epoch [4560/10000], Train Loss: 0.3200, Val Loss: 0.3948\n",
      "Epoch [4561/10000], Train Loss: 0.3207, Val Loss: 0.3872\n",
      "Epoch [4562/10000], Train Loss: 0.3201, Val Loss: 0.3846\n",
      "Epoch [4563/10000], Train Loss: 0.3208, Val Loss: 0.3929\n",
      "Epoch [4564/10000], Train Loss: 0.3200, Val Loss: 0.3852\n",
      "Epoch [4565/10000], Train Loss: 0.3205, Val Loss: 0.3809\n",
      "Epoch [4566/10000], Train Loss: 0.3204, Val Loss: 0.3932\n",
      "Epoch [4567/10000], Train Loss: 0.3207, Val Loss: 0.4136\n",
      "Epoch [4568/10000], Train Loss: 0.3205, Val Loss: 0.3808\n",
      "Epoch [4569/10000], Train Loss: 0.3207, Val Loss: 0.3915\n",
      "Epoch [4570/10000], Train Loss: 0.3200, Val Loss: 0.4253\n",
      "Epoch [4571/10000], Train Loss: 0.3204, Val Loss: 0.3809\n",
      "Epoch [4572/10000], Train Loss: 0.3206, Val Loss: 0.3754\n",
      "Epoch [4573/10000], Train Loss: 0.3204, Val Loss: 0.3886\n",
      "Epoch [4574/10000], Train Loss: 0.3207, Val Loss: 0.3890\n",
      "Epoch [4575/10000], Train Loss: 0.3206, Val Loss: 0.3883\n",
      "Epoch [4576/10000], Train Loss: 0.3205, Val Loss: 0.3798\n",
      "Epoch [4577/10000], Train Loss: 0.3202, Val Loss: 0.3771\n",
      "Epoch [4578/10000], Train Loss: 0.3203, Val Loss: 0.3836\n",
      "Epoch [4579/10000], Train Loss: 0.3205, Val Loss: 0.3780\n",
      "Epoch [4580/10000], Train Loss: 0.3203, Val Loss: 0.3964\n",
      "Epoch [4581/10000], Train Loss: 0.3205, Val Loss: 0.3845\n",
      "Epoch [4582/10000], Train Loss: 0.3206, Val Loss: 0.4238\n",
      "Epoch [4583/10000], Train Loss: 0.3205, Val Loss: 0.4089\n",
      "Epoch [4584/10000], Train Loss: 0.3206, Val Loss: 0.4174\n",
      "Epoch [4585/10000], Train Loss: 0.3203, Val Loss: 0.4008\n",
      "Epoch [4586/10000], Train Loss: 0.3208, Val Loss: 0.3887\n",
      "Epoch [4587/10000], Train Loss: 0.3203, Val Loss: 0.3876\n",
      "Epoch [4588/10000], Train Loss: 0.3204, Val Loss: 0.3819\n",
      "Epoch [4589/10000], Train Loss: 0.3201, Val Loss: 0.3806\n",
      "Epoch [4590/10000], Train Loss: 0.3203, Val Loss: 0.3865\n",
      "Epoch [4591/10000], Train Loss: 0.3205, Val Loss: 0.3853\n",
      "Epoch [4592/10000], Train Loss: 0.3203, Val Loss: 0.3781\n",
      "Epoch [4593/10000], Train Loss: 0.3205, Val Loss: 0.3779\n",
      "Epoch [4594/10000], Train Loss: 0.3206, Val Loss: 0.4150\n",
      "Epoch [4595/10000], Train Loss: 0.3202, Val Loss: 0.3783\n",
      "Epoch [4596/10000], Train Loss: 0.3207, Val Loss: 0.3911\n",
      "Epoch [4597/10000], Train Loss: 0.3204, Val Loss: 0.3932\n",
      "Epoch [4598/10000], Train Loss: 0.3203, Val Loss: 0.4058\n",
      "Epoch [4599/10000], Train Loss: 0.3207, Val Loss: 0.3996\n",
      "Epoch [4600/10000], Train Loss: 0.3206, Val Loss: 0.4168\n",
      "Epoch [4601/10000], Train Loss: 0.3205, Val Loss: 0.3947\n",
      "Epoch [4602/10000], Train Loss: 0.3207, Val Loss: 0.5551\n",
      "Epoch [4603/10000], Train Loss: 0.3205, Val Loss: 0.3783\n",
      "Epoch [4604/10000], Train Loss: 0.3207, Val Loss: 0.3892\n",
      "Epoch [4605/10000], Train Loss: 0.3202, Val Loss: 0.3817\n",
      "Epoch [4606/10000], Train Loss: 0.3204, Val Loss: 0.3751\n",
      "Epoch [4607/10000], Train Loss: 0.3202, Val Loss: 0.3791\n",
      "Epoch [4608/10000], Train Loss: 0.3205, Val Loss: 0.3771\n",
      "Epoch [4609/10000], Train Loss: 0.3206, Val Loss: 0.3781\n",
      "Epoch [4610/10000], Train Loss: 0.3205, Val Loss: 0.3856\n",
      "Epoch [4611/10000], Train Loss: 0.3207, Val Loss: 0.3885\n",
      "Epoch [4612/10000], Train Loss: 0.3208, Val Loss: 0.3791\n",
      "Epoch [4613/10000], Train Loss: 0.3206, Val Loss: 0.3950\n",
      "Epoch [4614/10000], Train Loss: 0.3205, Val Loss: 0.4165\n",
      "Epoch [4615/10000], Train Loss: 0.3208, Val Loss: 0.3850\n",
      "Epoch [4616/10000], Train Loss: 0.3203, Val Loss: 0.3743\n",
      "Epoch [4617/10000], Train Loss: 0.3202, Val Loss: 0.3762\n",
      "Epoch [4618/10000], Train Loss: 0.3206, Val Loss: 0.3764\n",
      "Epoch [4619/10000], Train Loss: 0.3205, Val Loss: 0.3900\n",
      "Epoch [4620/10000], Train Loss: 0.3203, Val Loss: 0.3994\n",
      "Epoch [4621/10000], Train Loss: 0.3203, Val Loss: 0.3858\n",
      "Epoch [4622/10000], Train Loss: 0.3206, Val Loss: 0.3799\n",
      "Epoch [4623/10000], Train Loss: 0.3205, Val Loss: 0.3874\n",
      "Epoch [4624/10000], Train Loss: 0.3203, Val Loss: 0.4121\n",
      "Epoch [4625/10000], Train Loss: 0.3203, Val Loss: 0.3779\n",
      "Epoch [4626/10000], Train Loss: 0.3200, Val Loss: 0.3804\n",
      "Epoch [4627/10000], Train Loss: 0.3205, Val Loss: 0.3756\n",
      "Epoch [4628/10000], Train Loss: 0.3204, Val Loss: 0.3854\n",
      "Epoch [4629/10000], Train Loss: 0.3204, Val Loss: 0.4304\n",
      "Epoch [4630/10000], Train Loss: 0.3202, Val Loss: 0.3803\n",
      "Epoch [4631/10000], Train Loss: 0.3204, Val Loss: 0.3870\n",
      "Epoch [4632/10000], Train Loss: 0.3206, Val Loss: 0.4387\n",
      "Epoch [4633/10000], Train Loss: 0.3203, Val Loss: 0.3792\n",
      "Epoch [4634/10000], Train Loss: 0.3204, Val Loss: 0.3975\n",
      "Epoch [4635/10000], Train Loss: 0.3227, Val Loss: 0.3972\n",
      "Epoch [4636/10000], Train Loss: 0.3218, Val Loss: 0.4049\n",
      "Epoch [4637/10000], Train Loss: 0.3202, Val Loss: 0.3954\n",
      "Epoch [4638/10000], Train Loss: 0.3203, Val Loss: 0.3757\n",
      "Epoch [4639/10000], Train Loss: 0.3204, Val Loss: 0.4148\n",
      "Epoch [4640/10000], Train Loss: 0.3202, Val Loss: 0.3954\n",
      "Epoch [4641/10000], Train Loss: 0.3208, Val Loss: 0.3798\n",
      "Epoch [4642/10000], Train Loss: 0.3204, Val Loss: 0.4033\n",
      "Epoch [4643/10000], Train Loss: 0.3204, Val Loss: 0.3904\n",
      "Epoch [4644/10000], Train Loss: 0.3203, Val Loss: 0.4427\n",
      "Epoch [4645/10000], Train Loss: 0.3206, Val Loss: 0.3934\n",
      "Epoch [4646/10000], Train Loss: 0.3204, Val Loss: 0.3848\n",
      "Epoch [4647/10000], Train Loss: 0.3205, Val Loss: 0.4498\n",
      "Epoch [4648/10000], Train Loss: 0.3204, Val Loss: 0.3825\n",
      "Epoch [4649/10000], Train Loss: 0.3206, Val Loss: 0.3942\n",
      "Epoch [4650/10000], Train Loss: 0.3205, Val Loss: 0.3770\n",
      "Epoch [4651/10000], Train Loss: 0.3205, Val Loss: 0.4141\n",
      "Epoch [4652/10000], Train Loss: 0.3203, Val Loss: 0.3813\n",
      "Epoch [4653/10000], Train Loss: 0.3200, Val Loss: 0.3868\n",
      "Epoch [4654/10000], Train Loss: 0.3199, Val Loss: 0.3838\n",
      "Epoch [4655/10000], Train Loss: 0.3204, Val Loss: 0.6139\n",
      "Epoch [4656/10000], Train Loss: 0.4251, Val Loss: 0.5529\n",
      "Epoch [4657/10000], Train Loss: 0.3312, Val Loss: 0.4349\n",
      "Epoch [4658/10000], Train Loss: 0.3224, Val Loss: 0.3853\n",
      "Epoch [4659/10000], Train Loss: 0.3194, Val Loss: 0.3772\n",
      "Epoch [4660/10000], Train Loss: 0.3194, Val Loss: 0.3961\n",
      "Epoch [4661/10000], Train Loss: 0.3201, Val Loss: 0.3775\n",
      "Epoch [4662/10000], Train Loss: 0.3206, Val Loss: 0.3928\n",
      "Epoch [4663/10000], Train Loss: 0.3202, Val Loss: 0.3961\n",
      "Epoch [4664/10000], Train Loss: 0.3204, Val Loss: 0.3807\n",
      "Epoch [4665/10000], Train Loss: 0.3204, Val Loss: 0.3831\n",
      "Epoch [4666/10000], Train Loss: 0.3201, Val Loss: 0.3885\n",
      "Epoch [4667/10000], Train Loss: 0.3206, Val Loss: 0.3777\n",
      "Epoch [4668/10000], Train Loss: 0.3207, Val Loss: 0.3826\n",
      "Epoch [4669/10000], Train Loss: 0.3203, Val Loss: 0.3836\n",
      "Epoch [4670/10000], Train Loss: 0.3205, Val Loss: 0.4715\n",
      "Epoch [4671/10000], Train Loss: 0.3201, Val Loss: 0.3912\n",
      "Epoch [4672/10000], Train Loss: 0.3207, Val Loss: 0.4592\n",
      "Epoch [4673/10000], Train Loss: 0.3209, Val Loss: 0.3869\n",
      "Epoch [4674/10000], Train Loss: 0.3206, Val Loss: 0.3864\n",
      "Epoch [4675/10000], Train Loss: 0.3203, Val Loss: 0.3821\n",
      "Epoch [4676/10000], Train Loss: 0.3201, Val Loss: 0.3927\n",
      "Epoch [4677/10000], Train Loss: 0.3201, Val Loss: 0.5361\n",
      "Epoch [4678/10000], Train Loss: 0.3210, Val Loss: 0.4016\n",
      "Epoch [4679/10000], Train Loss: 0.3206, Val Loss: 0.3825\n",
      "Epoch [4680/10000], Train Loss: 0.3204, Val Loss: 0.3828\n",
      "Epoch [4681/10000], Train Loss: 0.3216, Val Loss: 0.3992\n",
      "Epoch [4682/10000], Train Loss: 0.3200, Val Loss: 0.3954\n",
      "Epoch [4683/10000], Train Loss: 0.3200, Val Loss: 0.3886\n",
      "Epoch [4684/10000], Train Loss: 0.3203, Val Loss: 0.3802\n",
      "Epoch [4685/10000], Train Loss: 0.3203, Val Loss: 0.3930\n",
      "Epoch [4686/10000], Train Loss: 0.3206, Val Loss: 0.4124\n",
      "Epoch [4687/10000], Train Loss: 4.1740, Val Loss: 10.1180\n",
      "Epoch [4688/10000], Train Loss: 4.5269, Val Loss: 5.7089\n",
      "Epoch [4689/10000], Train Loss: 2.5752, Val Loss: 4.0358\n",
      "Epoch [4690/10000], Train Loss: 1.8819, Val Loss: 2.7370\n",
      "Epoch [4691/10000], Train Loss: 1.7245, Val Loss: 2.1399\n",
      "Epoch [4692/10000], Train Loss: 1.5932, Val Loss: 1.9681\n",
      "Epoch [4693/10000], Train Loss: 1.5754, Val Loss: 1.9043\n",
      "Epoch [4694/10000], Train Loss: 1.5584, Val Loss: 1.9193\n",
      "Epoch [4695/10000], Train Loss: 1.5572, Val Loss: 1.9209\n",
      "Epoch [4696/10000], Train Loss: 1.5645, Val Loss: 1.9256\n",
      "Epoch [4697/10000], Train Loss: 1.5721, Val Loss: 1.9250\n",
      "Epoch [4698/10000], Train Loss: 1.5772, Val Loss: 1.9563\n",
      "Epoch [4699/10000], Train Loss: 1.5696, Val Loss: 1.9469\n",
      "Epoch [4700/10000], Train Loss: 1.5596, Val Loss: 1.9602\n",
      "Epoch [4701/10000], Train Loss: 1.5719, Val Loss: 1.9596\n",
      "Epoch [4702/10000], Train Loss: 1.5760, Val Loss: 1.9669\n",
      "Epoch [4703/10000], Train Loss: 1.5572, Val Loss: 1.9532\n",
      "Epoch [4704/10000], Train Loss: 1.5446, Val Loss: 1.9735\n",
      "Epoch [4705/10000], Train Loss: 1.5247, Val Loss: 2.0175\n",
      "Epoch [4706/10000], Train Loss: 1.5475, Val Loss: 1.9581\n",
      "Epoch [4707/10000], Train Loss: 1.5617, Val Loss: 1.9443\n",
      "Epoch [4708/10000], Train Loss: 1.5226, Val Loss: 2.0076\n",
      "Epoch [4709/10000], Train Loss: 1.5316, Val Loss: 2.0244\n",
      "Epoch [4710/10000], Train Loss: 1.5495, Val Loss: 1.8563\n",
      "Epoch [4711/10000], Train Loss: 1.5656, Val Loss: 1.9061\n",
      "Epoch [4712/10000], Train Loss: 1.5622, Val Loss: 1.9100\n",
      "Epoch [4713/10000], Train Loss: 1.5647, Val Loss: 1.8967\n",
      "Epoch [4714/10000], Train Loss: 1.5660, Val Loss: 1.9381\n",
      "Epoch [4715/10000], Train Loss: 1.5459, Val Loss: 1.9817\n",
      "Epoch [4716/10000], Train Loss: 1.5269, Val Loss: 1.8856\n",
      "Epoch [4717/10000], Train Loss: 1.5334, Val Loss: 1.8890\n",
      "Epoch [4718/10000], Train Loss: 1.5400, Val Loss: 1.9909\n",
      "Epoch [4719/10000], Train Loss: 1.5399, Val Loss: 1.9399\n",
      "Epoch [4720/10000], Train Loss: 1.5268, Val Loss: 2.0176\n",
      "Epoch [4721/10000], Train Loss: 1.5135, Val Loss: 2.0237\n",
      "Epoch [4722/10000], Train Loss: 1.5145, Val Loss: 2.0322\n",
      "Epoch [4723/10000], Train Loss: 1.5511, Val Loss: 1.8479\n",
      "Epoch [4724/10000], Train Loss: 1.5495, Val Loss: 1.8191\n",
      "Epoch [4725/10000], Train Loss: 1.5446, Val Loss: 1.7896\n",
      "Epoch [4726/10000], Train Loss: 1.5608, Val Loss: 1.8172\n",
      "Epoch [4727/10000], Train Loss: 1.5718, Val Loss: 1.8453\n",
      "Epoch [4728/10000], Train Loss: 1.5718, Val Loss: 1.8870\n",
      "Epoch [4729/10000], Train Loss: 1.5665, Val Loss: 1.9321\n",
      "Epoch [4730/10000], Train Loss: 1.5539, Val Loss: 1.9597\n",
      "Epoch [4731/10000], Train Loss: 1.5609, Val Loss: 1.8974\n",
      "Epoch [4732/10000], Train Loss: 1.5651, Val Loss: 1.8418\n",
      "Epoch [4733/10000], Train Loss: 1.5644, Val Loss: 1.8363\n",
      "Epoch [4734/10000], Train Loss: 1.5635, Val Loss: 1.8342\n",
      "Epoch [4735/10000], Train Loss: 1.5643, Val Loss: 1.8396\n",
      "Epoch [4736/10000], Train Loss: 1.5616, Val Loss: 1.8399\n",
      "Epoch [4737/10000], Train Loss: 1.5610, Val Loss: 1.8312\n",
      "Epoch [4738/10000], Train Loss: 1.5614, Val Loss: 1.8267\n",
      "Epoch [4739/10000], Train Loss: 1.5636, Val Loss: 1.8588\n",
      "Epoch [4740/10000], Train Loss: 1.5669, Val Loss: 1.8590\n",
      "Epoch [4741/10000], Train Loss: 1.5653, Val Loss: 1.8432\n",
      "Epoch [4742/10000], Train Loss: 1.5663, Val Loss: 1.8781\n",
      "Epoch [4743/10000], Train Loss: 1.5724, Val Loss: 1.9072\n",
      "Epoch [4744/10000], Train Loss: 1.5842, Val Loss: 1.9131\n",
      "Epoch [4745/10000], Train Loss: 1.5757, Val Loss: 1.9070\n",
      "Epoch [4746/10000], Train Loss: 1.5790, Val Loss: 1.9156\n",
      "Epoch [4747/10000], Train Loss: 1.5879, Val Loss: 1.9132\n",
      "Epoch [4748/10000], Train Loss: 1.5918, Val Loss: 1.9108\n",
      "Epoch [4749/10000], Train Loss: 1.5873, Val Loss: 1.9206\n",
      "Epoch [4750/10000], Train Loss: 1.5934, Val Loss: 1.9118\n",
      "Epoch [4751/10000], Train Loss: 1.5951, Val Loss: 1.9231\n",
      "Epoch [4752/10000], Train Loss: 1.5952, Val Loss: 1.9186\n",
      "Epoch [4753/10000], Train Loss: 1.5947, Val Loss: 1.9045\n",
      "Epoch [4754/10000], Train Loss: 1.5852, Val Loss: 1.8715\n",
      "Epoch [4755/10000], Train Loss: 1.5876, Val Loss: 1.8843\n",
      "Epoch [4756/10000], Train Loss: 1.5905, Val Loss: 1.8888\n",
      "Epoch [4757/10000], Train Loss: 1.5886, Val Loss: 1.8680\n",
      "Epoch [4758/10000], Train Loss: 1.5890, Val Loss: 1.8759\n",
      "Epoch [4759/10000], Train Loss: 1.5908, Val Loss: 1.8974\n",
      "Epoch [4760/10000], Train Loss: 1.5932, Val Loss: 1.8927\n",
      "Epoch [4761/10000], Train Loss: 1.5921, Val Loss: 1.9225\n",
      "Epoch [4762/10000], Train Loss: 1.5933, Val Loss: 1.8973\n",
      "Epoch [4763/10000], Train Loss: 1.5938, Val Loss: 1.9636\n",
      "Epoch [4764/10000], Train Loss: 1.5914, Val Loss: 1.9714\n",
      "Epoch [4765/10000], Train Loss: 1.5961, Val Loss: 1.9382\n",
      "Epoch [4766/10000], Train Loss: 1.5955, Val Loss: 1.9601\n",
      "Epoch [4767/10000], Train Loss: 1.5953, Val Loss: 1.9525\n",
      "Epoch [4768/10000], Train Loss: 1.5941, Val Loss: 1.9190\n",
      "Epoch [4769/10000], Train Loss: 1.5964, Val Loss: 1.9163\n",
      "Epoch [4770/10000], Train Loss: 1.5957, Val Loss: 1.9122\n",
      "Epoch [4771/10000], Train Loss: 1.5937, Val Loss: 1.8776\n",
      "Epoch [4772/10000], Train Loss: 1.5901, Val Loss: 1.9109\n",
      "Epoch [4773/10000], Train Loss: 1.5887, Val Loss: 1.9238\n",
      "Epoch [4774/10000], Train Loss: 1.5920, Val Loss: 1.9739\n",
      "Epoch [4775/10000], Train Loss: 1.5964, Val Loss: 1.9566\n",
      "Epoch [4776/10000], Train Loss: 1.5909, Val Loss: 1.9995\n",
      "Epoch [4777/10000], Train Loss: 1.5876, Val Loss: 1.9884\n",
      "Epoch [4778/10000], Train Loss: 1.5883, Val Loss: 2.0038\n",
      "Epoch [4779/10000], Train Loss: 1.5867, Val Loss: 2.0152\n",
      "Epoch [4780/10000], Train Loss: 1.5914, Val Loss: 1.9725\n",
      "Epoch [4781/10000], Train Loss: 1.5965, Val Loss: 1.9333\n",
      "Epoch [4782/10000], Train Loss: 1.5967, Val Loss: 1.9079\n",
      "Epoch [4783/10000], Train Loss: 1.5965, Val Loss: 1.9047\n",
      "Epoch [4784/10000], Train Loss: 1.5980, Val Loss: 1.9119\n",
      "Epoch [4785/10000], Train Loss: 1.5967, Val Loss: 1.9012\n",
      "Epoch [4786/10000], Train Loss: 1.5927, Val Loss: 1.8841\n",
      "Epoch [4787/10000], Train Loss: 1.5913, Val Loss: 1.8770\n",
      "Epoch [4788/10000], Train Loss: 1.5948, Val Loss: 1.8996\n",
      "Epoch [4789/10000], Train Loss: 1.5955, Val Loss: 1.9160\n",
      "Epoch [4790/10000], Train Loss: 1.5939, Val Loss: 1.8783\n",
      "Epoch [4791/10000], Train Loss: 1.5939, Val Loss: 1.8706\n",
      "Epoch [4792/10000], Train Loss: 1.5901, Val Loss: 1.8929\n",
      "Epoch [4793/10000], Train Loss: 1.5895, Val Loss: 1.8674\n",
      "Epoch [4794/10000], Train Loss: 1.5870, Val Loss: 1.8712\n",
      "Epoch [4795/10000], Train Loss: 1.5918, Val Loss: 1.8819\n",
      "Epoch [4796/10000], Train Loss: 1.5940, Val Loss: 1.8989\n",
      "Epoch [4797/10000], Train Loss: 1.5944, Val Loss: 1.9063\n",
      "Epoch [4798/10000], Train Loss: 1.5961, Val Loss: 1.9005\n",
      "Epoch [4799/10000], Train Loss: 1.5962, Val Loss: 1.9111\n",
      "Epoch [4800/10000], Train Loss: 1.5974, Val Loss: 1.8882\n",
      "Epoch [4801/10000], Train Loss: 1.5958, Val Loss: 1.8752\n",
      "Epoch [4802/10000], Train Loss: 1.5974, Val Loss: 1.8953\n",
      "Epoch [4803/10000], Train Loss: 1.5970, Val Loss: 1.8633\n",
      "Epoch [4804/10000], Train Loss: 1.5948, Val Loss: 1.8705\n",
      "Epoch [4805/10000], Train Loss: 1.5930, Val Loss: 1.8594\n",
      "Epoch [4806/10000], Train Loss: 1.5960, Val Loss: 1.8743\n",
      "Epoch [4807/10000], Train Loss: 1.5969, Val Loss: 1.8778\n",
      "Epoch [4808/10000], Train Loss: 1.5964, Val Loss: 1.8956\n",
      "Epoch [4809/10000], Train Loss: 1.5953, Val Loss: 1.8977\n",
      "Epoch [4810/10000], Train Loss: 1.5972, Val Loss: 1.8618\n",
      "Epoch [4811/10000], Train Loss: 1.5967, Val Loss: 1.8663\n",
      "Epoch [4812/10000], Train Loss: 1.5956, Val Loss: 1.8655\n",
      "Epoch [4813/10000], Train Loss: 1.5934, Val Loss: 1.8488\n",
      "Epoch [4814/10000], Train Loss: 1.5884, Val Loss: 1.8315\n",
      "Epoch [4815/10000], Train Loss: 1.5838, Val Loss: 1.8323\n",
      "Epoch [4816/10000], Train Loss: 1.5847, Val Loss: 1.8572\n",
      "Epoch [4817/10000], Train Loss: 1.5930, Val Loss: 1.8646\n",
      "Epoch [4818/10000], Train Loss: 1.5973, Val Loss: 1.8802\n",
      "Epoch [4819/10000], Train Loss: 1.5973, Val Loss: 1.8913\n",
      "Epoch [4820/10000], Train Loss: 1.5978, Val Loss: 1.8732\n",
      "Epoch [4821/10000], Train Loss: 1.5988, Val Loss: 1.9202\n",
      "Epoch [4822/10000], Train Loss: 1.5977, Val Loss: 1.9018\n",
      "Epoch [4823/10000], Train Loss: 1.5975, Val Loss: 1.9061\n",
      "Epoch [4824/10000], Train Loss: 1.5975, Val Loss: 1.9000\n",
      "Epoch [4825/10000], Train Loss: 1.5974, Val Loss: 1.8840\n",
      "Epoch [4826/10000], Train Loss: 1.5972, Val Loss: 1.8668\n",
      "Epoch [4827/10000], Train Loss: 1.5929, Val Loss: 1.8666\n",
      "Epoch [4828/10000], Train Loss: 1.5849, Val Loss: 1.8349\n",
      "Epoch [4829/10000], Train Loss: 1.5857, Val Loss: 1.8314\n",
      "Epoch [4830/10000], Train Loss: 1.5840, Val Loss: 1.8280\n",
      "Epoch [4831/10000], Train Loss: 1.5800, Val Loss: 1.8221\n",
      "Epoch [4832/10000], Train Loss: 1.5775, Val Loss: 1.8470\n",
      "Epoch [4833/10000], Train Loss: 1.5691, Val Loss: 1.8539\n",
      "Epoch [4834/10000], Train Loss: 1.5671, Val Loss: 1.8396\n",
      "Epoch [4835/10000], Train Loss: 1.5602, Val Loss: 1.8966\n",
      "Epoch [4836/10000], Train Loss: 1.5591, Val Loss: 1.8675\n",
      "Epoch [4837/10000], Train Loss: 1.5644, Val Loss: 1.8585\n",
      "Epoch [4838/10000], Train Loss: 1.5669, Val Loss: 1.8669\n",
      "Epoch [4839/10000], Train Loss: 1.5586, Val Loss: 1.8629\n",
      "Epoch [4840/10000], Train Loss: 1.5600, Val Loss: 1.8687\n",
      "Epoch [4841/10000], Train Loss: 1.5568, Val Loss: 1.8785\n",
      "Epoch [4842/10000], Train Loss: 1.5562, Val Loss: 1.8867\n",
      "Epoch [4843/10000], Train Loss: 1.5566, Val Loss: 1.8742\n",
      "Epoch [4844/10000], Train Loss: 1.5634, Val Loss: 1.8698\n",
      "Epoch [4845/10000], Train Loss: 1.5707, Val Loss: 1.8737\n",
      "Epoch [4846/10000], Train Loss: 1.5703, Val Loss: 1.8708\n",
      "Epoch [4847/10000], Train Loss: 1.5701, Val Loss: 1.8601\n",
      "Epoch [4848/10000], Train Loss: 1.5678, Val Loss: 1.8530\n",
      "Epoch [4849/10000], Train Loss: 1.5651, Val Loss: 1.8338\n",
      "Epoch [4850/10000], Train Loss: 1.5623, Val Loss: 1.8296\n",
      "Epoch [4851/10000], Train Loss: 1.5602, Val Loss: 1.8331\n",
      "Epoch [4852/10000], Train Loss: 1.5626, Val Loss: 1.8368\n",
      "Epoch [4853/10000], Train Loss: 1.5654, Val Loss: 1.8173\n",
      "Epoch [4854/10000], Train Loss: 1.5638, Val Loss: 1.8222\n",
      "Epoch [4855/10000], Train Loss: 1.5621, Val Loss: 1.8168\n",
      "Epoch [4856/10000], Train Loss: 1.5641, Val Loss: 1.8173\n",
      "Epoch [4857/10000], Train Loss: 1.5755, Val Loss: 1.8274\n",
      "Epoch [4858/10000], Train Loss: 1.5777, Val Loss: 1.8309\n",
      "Epoch [4859/10000], Train Loss: 1.5810, Val Loss: 1.8671\n",
      "Epoch [4860/10000], Train Loss: 1.5891, Val Loss: 1.8571\n",
      "Epoch [4861/10000], Train Loss: 1.5857, Val Loss: 1.8619\n",
      "Epoch [4862/10000], Train Loss: 1.5766, Val Loss: 1.8217\n",
      "Epoch [4863/10000], Train Loss: 1.5660, Val Loss: 1.8395\n",
      "Epoch [4864/10000], Train Loss: 1.5691, Val Loss: 1.8274\n",
      "Epoch [4865/10000], Train Loss: 1.5728, Val Loss: 1.8463\n",
      "Epoch [4866/10000], Train Loss: 1.5710, Val Loss: 1.8398\n",
      "Epoch [4867/10000], Train Loss: 1.5688, Val Loss: 1.8421\n",
      "Epoch [4868/10000], Train Loss: 1.5672, Val Loss: 1.8552\n",
      "Epoch [4869/10000], Train Loss: 1.5614, Val Loss: 1.8456\n",
      "Epoch [4870/10000], Train Loss: 1.5603, Val Loss: 1.8290\n",
      "Epoch [4871/10000], Train Loss: 1.5651, Val Loss: 1.8248\n",
      "Epoch [4872/10000], Train Loss: 1.5583, Val Loss: 1.8219\n",
      "Epoch [4873/10000], Train Loss: 1.5548, Val Loss: 1.8100\n",
      "Epoch [4874/10000], Train Loss: 1.5612, Val Loss: 1.8140\n",
      "Epoch [4875/10000], Train Loss: 1.5637, Val Loss: 1.8443\n",
      "Epoch [4876/10000], Train Loss: 1.5616, Val Loss: 1.8278\n",
      "Epoch [4877/10000], Train Loss: 1.5503, Val Loss: 1.8191\n",
      "Epoch [4878/10000], Train Loss: 1.5462, Val Loss: 1.8130\n",
      "Epoch [4879/10000], Train Loss: 1.5442, Val Loss: 1.8200\n",
      "Epoch [4880/10000], Train Loss: 1.5454, Val Loss: 1.8248\n",
      "Epoch [4881/10000], Train Loss: 1.5465, Val Loss: 1.8301\n",
      "Epoch [4882/10000], Train Loss: 1.5412, Val Loss: 1.8325\n",
      "Epoch [4883/10000], Train Loss: 1.5435, Val Loss: 1.8347\n",
      "Epoch [4884/10000], Train Loss: 1.5453, Val Loss: 1.8164\n",
      "Epoch [4885/10000], Train Loss: 1.5438, Val Loss: 1.8299\n",
      "Epoch [4886/10000], Train Loss: 1.5463, Val Loss: 1.8170\n",
      "Epoch [4887/10000], Train Loss: 1.5529, Val Loss: 1.8529\n",
      "Epoch [4888/10000], Train Loss: 1.5469, Val Loss: 1.9252\n",
      "Epoch [4889/10000], Train Loss: 1.5597, Val Loss: 1.9723\n",
      "Epoch [4890/10000], Train Loss: 1.5676, Val Loss: 2.0137\n",
      "Epoch [4891/10000], Train Loss: 1.5644, Val Loss: 1.9813\n",
      "Epoch [4892/10000], Train Loss: 1.5677, Val Loss: 1.9285\n",
      "Epoch [4893/10000], Train Loss: 1.5711, Val Loss: 1.9142\n",
      "Epoch [4894/10000], Train Loss: 1.5750, Val Loss: 1.9165\n",
      "Epoch [4895/10000], Train Loss: 1.5629, Val Loss: 1.9450\n",
      "Epoch [4896/10000], Train Loss: 1.5666, Val Loss: 1.8965\n",
      "Epoch [4897/10000], Train Loss: 1.5648, Val Loss: 1.9174\n",
      "Epoch [4898/10000], Train Loss: 1.5595, Val Loss: 1.9062\n",
      "Epoch [4899/10000], Train Loss: 1.5569, Val Loss: 1.9315\n",
      "Epoch [4900/10000], Train Loss: 1.5611, Val Loss: 1.9274\n",
      "Epoch [4901/10000], Train Loss: 1.5623, Val Loss: 1.9303\n",
      "Epoch [4902/10000], Train Loss: 1.5739, Val Loss: 1.9644\n",
      "Epoch [4903/10000], Train Loss: 1.5723, Val Loss: 1.9715\n",
      "Epoch [4904/10000], Train Loss: 1.5643, Val Loss: 2.0164\n",
      "Epoch [4905/10000], Train Loss: 1.5530, Val Loss: 2.0710\n",
      "Epoch [4906/10000], Train Loss: 1.5358, Val Loss: 2.1839\n",
      "Epoch [4907/10000], Train Loss: 1.5141, Val Loss: 2.0858\n",
      "Epoch [4908/10000], Train Loss: 1.5114, Val Loss: 2.0767\n",
      "Epoch [4909/10000], Train Loss: 1.5191, Val Loss: 2.1996\n",
      "Epoch [4910/10000], Train Loss: 1.5303, Val Loss: 2.1895\n",
      "Epoch [4911/10000], Train Loss: 1.5480, Val Loss: 2.1953\n",
      "Epoch [4912/10000], Train Loss: 1.5561, Val Loss: 2.1736\n",
      "Epoch [4913/10000], Train Loss: 1.5526, Val Loss: 2.2400\n",
      "Epoch [4914/10000], Train Loss: 1.5572, Val Loss: 2.1317\n",
      "Epoch [4915/10000], Train Loss: 1.5606, Val Loss: 2.1524\n",
      "Epoch [4916/10000], Train Loss: 1.5488, Val Loss: 1.9370\n",
      "Epoch [4917/10000], Train Loss: 1.5333, Val Loss: 1.8801\n",
      "Epoch [4918/10000], Train Loss: 1.5324, Val Loss: 1.8824\n",
      "Epoch [4919/10000], Train Loss: 1.5352, Val Loss: 1.8568\n",
      "Epoch [4920/10000], Train Loss: 1.5345, Val Loss: 1.8555\n",
      "Epoch [4921/10000], Train Loss: 1.5353, Val Loss: 1.8662\n",
      "Epoch [4922/10000], Train Loss: 1.5347, Val Loss: 1.8412\n",
      "Epoch [4923/10000], Train Loss: 1.5327, Val Loss: 1.8326\n",
      "Epoch [4924/10000], Train Loss: 1.5348, Val Loss: 1.8476\n",
      "Epoch [4925/10000], Train Loss: 1.5304, Val Loss: 1.8461\n",
      "Epoch [4926/10000], Train Loss: 1.5294, Val Loss: 1.8446\n",
      "Epoch [4927/10000], Train Loss: 1.5335, Val Loss: 1.8326\n",
      "Epoch [4928/10000], Train Loss: 1.5334, Val Loss: 1.8181\n",
      "Epoch [4929/10000], Train Loss: 1.5309, Val Loss: 1.8084\n",
      "Epoch [4930/10000], Train Loss: 1.5327, Val Loss: 1.8308\n",
      "Epoch [4931/10000], Train Loss: 1.5300, Val Loss: 1.8201\n",
      "Epoch [4932/10000], Train Loss: 1.5281, Val Loss: 1.8318\n",
      "Epoch [4933/10000], Train Loss: 1.5280, Val Loss: 1.8313\n",
      "Epoch [4934/10000], Train Loss: 1.5286, Val Loss: 1.8300\n",
      "Epoch [4935/10000], Train Loss: 1.5297, Val Loss: 1.8313\n",
      "Epoch [4936/10000], Train Loss: 1.5281, Val Loss: 1.8201\n",
      "Epoch [4937/10000], Train Loss: 1.5259, Val Loss: 1.8243\n",
      "Epoch [4938/10000], Train Loss: 1.5205, Val Loss: 1.8170\n",
      "Epoch [4939/10000], Train Loss: 1.5109, Val Loss: 1.8196\n",
      "Epoch [4940/10000], Train Loss: 1.4932, Val Loss: 1.8476\n",
      "Epoch [4941/10000], Train Loss: 1.4575, Val Loss: 1.9077\n",
      "Epoch [4942/10000], Train Loss: 1.4353, Val Loss: 1.9599\n",
      "Epoch [4943/10000], Train Loss: 1.4266, Val Loss: 2.0015\n",
      "Epoch [4944/10000], Train Loss: 1.4070, Val Loss: 2.3803\n",
      "Epoch [4945/10000], Train Loss: 0.8610, Val Loss: 0.9961\n",
      "Epoch [4946/10000], Train Loss: 0.6173, Val Loss: 0.7951\n",
      "Epoch [4947/10000], Train Loss: 0.5541, Val Loss: 0.7400\n",
      "Epoch [4948/10000], Train Loss: 0.5168, Val Loss: 0.6663\n",
      "Epoch [4949/10000], Train Loss: 0.4755, Val Loss: 0.6863\n",
      "Epoch [4950/10000], Train Loss: 0.4328, Val Loss: 0.6333\n",
      "Epoch [4951/10000], Train Loss: 0.4006, Val Loss: 0.5276\n",
      "Epoch [4952/10000], Train Loss: 0.3809, Val Loss: 0.5269\n",
      "Epoch [4953/10000], Train Loss: 0.3697, Val Loss: 0.4941\n",
      "Epoch [4954/10000], Train Loss: 0.3631, Val Loss: 0.4662\n",
      "Epoch [4955/10000], Train Loss: 0.3588, Val Loss: 0.4569\n",
      "Epoch [4956/10000], Train Loss: 0.3554, Val Loss: 0.4458\n",
      "Epoch [4957/10000], Train Loss: 0.3522, Val Loss: 0.4662\n",
      "Epoch [4958/10000], Train Loss: 0.3498, Val Loss: 0.4482\n",
      "Epoch [4959/10000], Train Loss: 0.3474, Val Loss: 0.4458\n",
      "Epoch [4960/10000], Train Loss: 0.3466, Val Loss: 0.4302\n",
      "Epoch [4961/10000], Train Loss: 0.3449, Val Loss: 0.4385\n",
      "Epoch [4962/10000], Train Loss: 0.3443, Val Loss: 0.4252\n",
      "Epoch [4963/10000], Train Loss: 0.3439, Val Loss: 0.4219\n",
      "Epoch [4964/10000], Train Loss: 0.3431, Val Loss: 0.6063\n",
      "Epoch [4965/10000], Train Loss: 0.3436, Val Loss: 0.4256\n",
      "Epoch [4966/10000], Train Loss: 0.3429, Val Loss: 0.4292\n",
      "Epoch [4967/10000], Train Loss: 0.3425, Val Loss: 0.4244\n",
      "Epoch [4968/10000], Train Loss: 0.3416, Val Loss: 0.4177\n",
      "Epoch [4969/10000], Train Loss: 0.3422, Val Loss: 0.5006\n",
      "Epoch [4970/10000], Train Loss: 0.3415, Val Loss: 0.4429\n",
      "Epoch [4971/10000], Train Loss: 0.3421, Val Loss: 0.4164\n",
      "Epoch [4972/10000], Train Loss: 0.3416, Val Loss: 0.4638\n",
      "Epoch [4973/10000], Train Loss: 0.3411, Val Loss: 0.4546\n",
      "Epoch [4974/10000], Train Loss: 0.3407, Val Loss: 0.4113\n",
      "Epoch [4975/10000], Train Loss: 0.3411, Val Loss: 0.4311\n",
      "Epoch [4976/10000], Train Loss: 0.3408, Val Loss: 0.4905\n",
      "Epoch [4977/10000], Train Loss: 0.3410, Val Loss: 0.4854\n",
      "Epoch [4978/10000], Train Loss: 0.3405, Val Loss: 0.5337\n",
      "Epoch [4979/10000], Train Loss: 0.3405, Val Loss: 0.4297\n",
      "Epoch [4980/10000], Train Loss: 0.3404, Val Loss: 0.4079\n",
      "Epoch [4981/10000], Train Loss: 0.3411, Val Loss: 0.4080\n",
      "Epoch [4982/10000], Train Loss: 0.3409, Val Loss: 0.4095\n",
      "Epoch [4983/10000], Train Loss: 0.3403, Val Loss: 0.4219\n",
      "Epoch [4984/10000], Train Loss: 0.3405, Val Loss: 0.4064\n",
      "Epoch [4985/10000], Train Loss: 0.3400, Val Loss: 0.4100\n",
      "Epoch [4986/10000], Train Loss: 0.3396, Val Loss: 0.4253\n",
      "Epoch [4987/10000], Train Loss: 0.3402, Val Loss: 0.4223\n",
      "Epoch [4988/10000], Train Loss: 0.3399, Val Loss: 0.4025\n",
      "Epoch [4989/10000], Train Loss: 0.3395, Val Loss: 0.4072\n",
      "Epoch [4990/10000], Train Loss: 0.3397, Val Loss: 0.4315\n",
      "Epoch [4991/10000], Train Loss: 0.3394, Val Loss: 0.4384\n",
      "Epoch [4992/10000], Train Loss: 0.3392, Val Loss: 0.4058\n",
      "Epoch [4993/10000], Train Loss: 0.3397, Val Loss: 0.4164\n",
      "Epoch [4994/10000], Train Loss: 0.3396, Val Loss: 0.4074\n",
      "Epoch [4995/10000], Train Loss: 0.3397, Val Loss: 0.4574\n",
      "Epoch [4996/10000], Train Loss: 0.3396, Val Loss: 0.5642\n",
      "Epoch [4997/10000], Train Loss: 0.3392, Val Loss: 0.4097\n",
      "Epoch [4998/10000], Train Loss: 0.3395, Val Loss: 0.4103\n",
      "Epoch [4999/10000], Train Loss: 0.3396, Val Loss: 0.4365\n",
      "Epoch [5000/10000], Train Loss: 0.3392, Val Loss: 0.5566\n",
      "Epoch [5001/10000], Train Loss: 0.3397, Val Loss: 0.4226\n",
      "Epoch [5002/10000], Train Loss: 0.3395, Val Loss: 0.4118\n",
      "Epoch [5003/10000], Train Loss: 0.3392, Val Loss: 0.4079\n",
      "Epoch [5004/10000], Train Loss: 0.3393, Val Loss: 0.4031\n",
      "Epoch [5005/10000], Train Loss: 0.3396, Val Loss: 0.4384\n",
      "Epoch [5006/10000], Train Loss: 0.3396, Val Loss: 0.4286\n",
      "Epoch [5007/10000], Train Loss: 0.3392, Val Loss: 0.4059\n",
      "Epoch [5008/10000], Train Loss: 0.3392, Val Loss: 0.5512\n",
      "Epoch [5009/10000], Train Loss: 0.3390, Val Loss: 0.4373\n",
      "Epoch [5010/10000], Train Loss: 0.3391, Val Loss: 0.4212\n",
      "Epoch [5011/10000], Train Loss: 0.3394, Val Loss: 0.5139\n",
      "Epoch [5012/10000], Train Loss: 0.3392, Val Loss: 0.4972\n",
      "Epoch [5013/10000], Train Loss: 0.3394, Val Loss: 0.4383\n",
      "Epoch [5014/10000], Train Loss: 0.3393, Val Loss: 0.5025\n",
      "Epoch [5015/10000], Train Loss: 0.3389, Val Loss: 0.4271\n",
      "Epoch [5016/10000], Train Loss: 0.3393, Val Loss: 0.4399\n",
      "Epoch [5017/10000], Train Loss: 0.3388, Val Loss: 0.4044\n",
      "Epoch [5018/10000], Train Loss: 0.3390, Val Loss: 0.4286\n",
      "Epoch [5019/10000], Train Loss: 0.3388, Val Loss: 0.4392\n",
      "Epoch [5020/10000], Train Loss: 0.3392, Val Loss: 0.4397\n",
      "Epoch [5021/10000], Train Loss: 0.3390, Val Loss: 0.4136\n",
      "Epoch [5022/10000], Train Loss: 0.3391, Val Loss: 0.4085\n",
      "Epoch [5023/10000], Train Loss: 0.3387, Val Loss: 0.4179\n",
      "Epoch [5024/10000], Train Loss: 0.3386, Val Loss: 0.4061\n",
      "Epoch [5025/10000], Train Loss: 0.3390, Val Loss: 0.4283\n",
      "Epoch [5026/10000], Train Loss: 0.3386, Val Loss: 0.4154\n",
      "Epoch [5027/10000], Train Loss: 0.3386, Val Loss: 0.4178\n",
      "Epoch [5028/10000], Train Loss: 0.3386, Val Loss: 0.4191\n",
      "Epoch [5029/10000], Train Loss: 0.3390, Val Loss: 0.4015\n",
      "Epoch [5030/10000], Train Loss: 0.3390, Val Loss: 0.3988\n",
      "Epoch [5031/10000], Train Loss: 0.3393, Val Loss: 0.5222\n",
      "Epoch [5032/10000], Train Loss: 0.3397, Val Loss: 0.4166\n",
      "Epoch [5033/10000], Train Loss: 0.3387, Val Loss: 0.4009\n",
      "Epoch [5034/10000], Train Loss: 0.3386, Val Loss: 0.4439\n",
      "Epoch [5035/10000], Train Loss: 0.3385, Val Loss: 0.4392\n",
      "Epoch [5036/10000], Train Loss: 0.3392, Val Loss: 0.4753\n",
      "Epoch [5037/10000], Train Loss: 0.3388, Val Loss: 0.3996\n",
      "Epoch [5038/10000], Train Loss: 0.3387, Val Loss: 0.4205\n",
      "Epoch [5039/10000], Train Loss: 0.3387, Val Loss: 0.4173\n",
      "Epoch [5040/10000], Train Loss: 0.3391, Val Loss: 0.4009\n",
      "Epoch [5041/10000], Train Loss: 0.3392, Val Loss: 0.4480\n",
      "Epoch [5042/10000], Train Loss: 0.3391, Val Loss: 0.4827\n",
      "Epoch [5043/10000], Train Loss: 0.3385, Val Loss: 0.4618\n",
      "Epoch [5044/10000], Train Loss: 0.3391, Val Loss: 0.5167\n",
      "Epoch [5045/10000], Train Loss: 0.3392, Val Loss: 0.4077\n",
      "Epoch [5046/10000], Train Loss: 0.3386, Val Loss: 0.4072\n",
      "Epoch [5047/10000], Train Loss: 0.3389, Val Loss: 0.4214\n",
      "Epoch [5048/10000], Train Loss: 0.3385, Val Loss: 0.4155\n",
      "Epoch [5049/10000], Train Loss: 0.3391, Val Loss: 0.5233\n",
      "Epoch [5050/10000], Train Loss: 0.3385, Val Loss: 0.4053\n",
      "Epoch [5051/10000], Train Loss: 0.3382, Val Loss: 0.4156\n",
      "Epoch [5052/10000], Train Loss: 0.3388, Val Loss: 0.4717\n",
      "Epoch [5053/10000], Train Loss: 0.3387, Val Loss: 0.4008\n",
      "Epoch [5054/10000], Train Loss: 0.3387, Val Loss: 0.4339\n",
      "Epoch [5055/10000], Train Loss: 0.3388, Val Loss: 0.4542\n",
      "Epoch [5056/10000], Train Loss: 0.3388, Val Loss: 0.4034\n",
      "Epoch [5057/10000], Train Loss: 0.3382, Val Loss: 0.4505\n",
      "Epoch [5058/10000], Train Loss: 0.3387, Val Loss: 0.4210\n",
      "Epoch [5059/10000], Train Loss: 0.3385, Val Loss: 0.3963\n",
      "Epoch [5060/10000], Train Loss: 0.3390, Val Loss: 0.4448\n",
      "Epoch [5061/10000], Train Loss: 0.3381, Val Loss: 0.4364\n",
      "Epoch [5062/10000], Train Loss: 0.3390, Val Loss: 0.4246\n",
      "Epoch [5063/10000], Train Loss: 0.3382, Val Loss: 0.4154\n",
      "Epoch [5064/10000], Train Loss: 0.3385, Val Loss: 0.6005\n",
      "Epoch [5065/10000], Train Loss: 0.3386, Val Loss: 0.4066\n",
      "Epoch [5066/10000], Train Loss: 0.3380, Val Loss: 0.4009\n",
      "Epoch [5067/10000], Train Loss: 0.3382, Val Loss: 0.4755\n",
      "Epoch [5068/10000], Train Loss: 0.3383, Val Loss: 0.4599\n",
      "Epoch [5069/10000], Train Loss: 0.3385, Val Loss: 0.3986\n",
      "Epoch [5070/10000], Train Loss: 0.3385, Val Loss: 0.4159\n",
      "Epoch [5071/10000], Train Loss: 0.3388, Val Loss: 0.4039\n",
      "Epoch [5072/10000], Train Loss: 0.3388, Val Loss: 0.4103\n",
      "Epoch [5073/10000], Train Loss: 0.3379, Val Loss: 0.4640\n",
      "Epoch [5074/10000], Train Loss: 0.3382, Val Loss: 0.4047\n",
      "Epoch [5075/10000], Train Loss: 0.3378, Val Loss: 0.5321\n",
      "Epoch [5076/10000], Train Loss: 0.3384, Val Loss: 0.4058\n",
      "Epoch [5077/10000], Train Loss: 0.3381, Val Loss: 0.4318\n",
      "Epoch [5078/10000], Train Loss: 0.3378, Val Loss: 0.4006\n",
      "Epoch [5079/10000], Train Loss: 0.3381, Val Loss: 0.4499\n",
      "Epoch [5080/10000], Train Loss: 0.3379, Val Loss: 0.5351\n",
      "Epoch [5081/10000], Train Loss: 0.3380, Val Loss: 0.4372\n",
      "Epoch [5082/10000], Train Loss: 0.3384, Val Loss: 0.4549\n",
      "Epoch [5083/10000], Train Loss: 0.3380, Val Loss: 0.3979\n",
      "Epoch [5084/10000], Train Loss: 0.3379, Val Loss: 0.4081\n",
      "Epoch [5085/10000], Train Loss: 0.3384, Val Loss: 0.4073\n",
      "Epoch [5086/10000], Train Loss: 0.3387, Val Loss: 0.3943\n",
      "Epoch [5087/10000], Train Loss: 0.3382, Val Loss: 0.4966\n",
      "Epoch [5088/10000], Train Loss: 0.3380, Val Loss: 0.3955\n",
      "Epoch [5089/10000], Train Loss: 0.3384, Val Loss: 0.4409\n",
      "Epoch [5090/10000], Train Loss: 0.3382, Val Loss: 0.4468\n",
      "Epoch [5091/10000], Train Loss: 0.3385, Val Loss: 0.4196\n",
      "Epoch [5092/10000], Train Loss: 0.3385, Val Loss: 0.4207\n",
      "Epoch [5093/10000], Train Loss: 0.3381, Val Loss: 0.4737\n",
      "Epoch [5094/10000], Train Loss: 0.3383, Val Loss: 0.4105\n",
      "Epoch [5095/10000], Train Loss: 0.3389, Val Loss: 0.4178\n",
      "Epoch [5096/10000], Train Loss: 0.3382, Val Loss: 0.4043\n",
      "Epoch [5097/10000], Train Loss: 0.3392, Val Loss: 0.4188\n",
      "Epoch [5098/10000], Train Loss: 0.3376, Val Loss: 0.4100\n",
      "Epoch [5099/10000], Train Loss: 0.3383, Val Loss: 0.4387\n",
      "Epoch [5100/10000], Train Loss: 0.3375, Val Loss: 0.4122\n",
      "Epoch [5101/10000], Train Loss: 0.3378, Val Loss: 0.4098\n",
      "Epoch [5102/10000], Train Loss: 0.3381, Val Loss: 0.3964\n",
      "Epoch [5103/10000], Train Loss: 0.3381, Val Loss: 0.4777\n",
      "Epoch [5104/10000], Train Loss: 0.3375, Val Loss: 0.4443\n",
      "Epoch [5105/10000], Train Loss: 0.3382, Val Loss: 0.4261\n",
      "Epoch [5106/10000], Train Loss: 0.3380, Val Loss: 0.4163\n",
      "Epoch [5107/10000], Train Loss: 0.3379, Val Loss: 0.4005\n",
      "Epoch [5108/10000], Train Loss: 0.3378, Val Loss: 0.4534\n",
      "Epoch [5109/10000], Train Loss: 0.3375, Val Loss: 0.4081\n",
      "Epoch [5110/10000], Train Loss: 0.3387, Val Loss: 0.4036\n",
      "Epoch [5111/10000], Train Loss: 0.3385, Val Loss: 0.4600\n",
      "Epoch [5112/10000], Train Loss: 0.3382, Val Loss: 0.4136\n",
      "Epoch [5113/10000], Train Loss: 0.3382, Val Loss: 0.4617\n",
      "Epoch [5114/10000], Train Loss: 0.3378, Val Loss: 0.4323\n",
      "Epoch [5115/10000], Train Loss: 0.3384, Val Loss: 0.4193\n",
      "Epoch [5116/10000], Train Loss: 0.3382, Val Loss: 0.5206\n",
      "Epoch [5117/10000], Train Loss: 0.3385, Val Loss: 0.5595\n",
      "Epoch [5118/10000], Train Loss: 0.3378, Val Loss: 0.4316\n",
      "Epoch [5119/10000], Train Loss: 0.3378, Val Loss: 0.3974\n",
      "Epoch [5120/10000], Train Loss: 0.3370, Val Loss: 0.4011\n",
      "Epoch [5121/10000], Train Loss: 0.3379, Val Loss: 0.5502\n",
      "Epoch [5122/10000], Train Loss: 0.3381, Val Loss: 0.4113\n",
      "Epoch [5123/10000], Train Loss: 0.3374, Val Loss: 0.4018\n",
      "Epoch [5124/10000], Train Loss: 0.3382, Val Loss: 0.5601\n",
      "Epoch [5125/10000], Train Loss: 0.3381, Val Loss: 0.4387\n",
      "Epoch [5126/10000], Train Loss: 0.3388, Val Loss: 0.4016\n",
      "Epoch [5127/10000], Train Loss: 0.3381, Val Loss: 0.4262\n",
      "Epoch [5128/10000], Train Loss: 0.3382, Val Loss: 0.4208\n",
      "Epoch [5129/10000], Train Loss: 0.3383, Val Loss: 0.4191\n",
      "Epoch [5130/10000], Train Loss: 0.3380, Val Loss: 0.3970\n",
      "Epoch [5131/10000], Train Loss: 0.3379, Val Loss: 0.4196\n",
      "Epoch [5132/10000], Train Loss: 0.3379, Val Loss: 0.4003\n",
      "Epoch [5133/10000], Train Loss: 0.3378, Val Loss: 0.3949\n",
      "Epoch [5134/10000], Train Loss: 0.3378, Val Loss: 0.4193\n",
      "Epoch [5135/10000], Train Loss: 0.3379, Val Loss: 0.4379\n",
      "Epoch [5136/10000], Train Loss: 0.3382, Val Loss: 0.4109\n",
      "Epoch [5137/10000], Train Loss: 0.3383, Val Loss: 0.4396\n",
      "Epoch [5138/10000], Train Loss: 0.3376, Val Loss: 0.4296\n",
      "Epoch [5139/10000], Train Loss: 0.3384, Val Loss: 0.4020\n",
      "Epoch [5140/10000], Train Loss: 0.3379, Val Loss: 0.5469\n",
      "Epoch [5141/10000], Train Loss: 0.3373, Val Loss: 0.5488\n",
      "Epoch [5142/10000], Train Loss: 0.3379, Val Loss: 0.4012\n",
      "Epoch [5143/10000], Train Loss: 0.3378, Val Loss: 0.3958\n",
      "Epoch [5144/10000], Train Loss: 0.3380, Val Loss: 0.4514\n",
      "Epoch [5145/10000], Train Loss: 0.3384, Val Loss: 0.4201\n",
      "Epoch [5146/10000], Train Loss: 0.3379, Val Loss: 0.4044\n",
      "Epoch [5147/10000], Train Loss: 0.3380, Val Loss: 0.4037\n",
      "Epoch [5148/10000], Train Loss: 0.3378, Val Loss: 0.4118\n",
      "Epoch [5149/10000], Train Loss: 0.3382, Val Loss: 0.4191\n",
      "Epoch [5150/10000], Train Loss: 0.3380, Val Loss: 0.4271\n",
      "Epoch [5151/10000], Train Loss: 0.3380, Val Loss: 0.4422\n",
      "Epoch [5152/10000], Train Loss: 0.3377, Val Loss: 0.4390\n",
      "Epoch [5153/10000], Train Loss: 0.3371, Val Loss: 0.4562\n",
      "Epoch [5154/10000], Train Loss: 0.3381, Val Loss: 0.5681\n",
      "Epoch [5155/10000], Train Loss: 0.3378, Val Loss: 0.4033\n",
      "Epoch [5156/10000], Train Loss: 0.3378, Val Loss: 0.3969\n",
      "Epoch [5157/10000], Train Loss: 0.3379, Val Loss: 0.4198\n",
      "Epoch [5158/10000], Train Loss: 0.3377, Val Loss: 0.4198\n",
      "Epoch [5159/10000], Train Loss: 0.3376, Val Loss: 0.4340\n",
      "Epoch [5160/10000], Train Loss: 0.3385, Val Loss: 0.4049\n",
      "Epoch [5161/10000], Train Loss: 0.3379, Val Loss: 0.4107\n",
      "Epoch [5162/10000], Train Loss: 0.3384, Val Loss: 0.4037\n",
      "Epoch [5163/10000], Train Loss: 0.3375, Val Loss: 0.4241\n",
      "Epoch [5164/10000], Train Loss: 0.3376, Val Loss: 0.4248\n",
      "Epoch [5165/10000], Train Loss: 0.3379, Val Loss: 0.4078\n",
      "Epoch [5166/10000], Train Loss: 0.3381, Val Loss: 0.4063\n",
      "Epoch [5167/10000], Train Loss: 0.3378, Val Loss: 0.4230\n",
      "Epoch [5168/10000], Train Loss: 0.3381, Val Loss: 0.4101\n",
      "Epoch [5169/10000], Train Loss: 0.3378, Val Loss: 0.3978\n",
      "Epoch [5170/10000], Train Loss: 0.3377, Val Loss: 0.4920\n",
      "Epoch [5171/10000], Train Loss: 0.3381, Val Loss: 0.4961\n",
      "Epoch [5172/10000], Train Loss: 0.3375, Val Loss: 0.3993\n",
      "Epoch [5173/10000], Train Loss: 0.3382, Val Loss: 0.4747\n",
      "Epoch [5174/10000], Train Loss: 0.3375, Val Loss: 0.3969\n",
      "Epoch [5175/10000], Train Loss: 0.3386, Val Loss: 0.4225\n",
      "Epoch [5176/10000], Train Loss: 0.3379, Val Loss: 0.4107\n",
      "Epoch [5177/10000], Train Loss: 0.3376, Val Loss: 0.4752\n",
      "Epoch [5178/10000], Train Loss: 0.3381, Val Loss: 0.4059\n",
      "Epoch [5179/10000], Train Loss: 0.3376, Val Loss: 0.4232\n",
      "Epoch [5180/10000], Train Loss: 0.3377, Val Loss: 0.4041\n",
      "Epoch [5181/10000], Train Loss: 0.3377, Val Loss: 0.3957\n",
      "Epoch [5182/10000], Train Loss: 0.3383, Val Loss: 0.3924\n",
      "Epoch [5183/10000], Train Loss: 0.3376, Val Loss: 0.5117\n",
      "Epoch [5184/10000], Train Loss: 0.3376, Val Loss: 0.4183\n",
      "Epoch [5185/10000], Train Loss: 0.3386, Val Loss: 0.4252\n",
      "Epoch [5186/10000], Train Loss: 0.3371, Val Loss: 0.4115\n",
      "Epoch [5187/10000], Train Loss: 0.3380, Val Loss: 0.4026\n",
      "Epoch [5188/10000], Train Loss: 0.3375, Val Loss: 0.4132\n",
      "Epoch [5189/10000], Train Loss: 0.3378, Val Loss: 0.4464\n",
      "Epoch [5190/10000], Train Loss: 0.3372, Val Loss: 0.6115\n",
      "Epoch [5191/10000], Train Loss: 0.3373, Val Loss: 0.4269\n",
      "Epoch [5192/10000], Train Loss: 0.3386, Val Loss: 0.4043\n",
      "Epoch [5193/10000], Train Loss: 0.3376, Val Loss: 0.5811\n",
      "Epoch [5194/10000], Train Loss: 0.3374, Val Loss: 0.3956\n",
      "Epoch [5195/10000], Train Loss: 0.3378, Val Loss: 0.3944\n",
      "Epoch [5196/10000], Train Loss: 0.3377, Val Loss: 0.3958\n",
      "Epoch [5197/10000], Train Loss: 0.3375, Val Loss: 0.4533\n",
      "Epoch [5198/10000], Train Loss: 0.3374, Val Loss: 0.4149\n",
      "Epoch [5199/10000], Train Loss: 0.3373, Val Loss: 0.5398\n",
      "Epoch [5200/10000], Train Loss: 0.3378, Val Loss: 0.4080\n",
      "Epoch [5201/10000], Train Loss: 0.3377, Val Loss: 0.4045\n",
      "Epoch [5202/10000], Train Loss: 0.3379, Val Loss: 0.4169\n",
      "Epoch [5203/10000], Train Loss: 0.3383, Val Loss: 0.4152\n",
      "Epoch [5204/10000], Train Loss: 0.3380, Val Loss: 0.4219\n",
      "Epoch [5205/10000], Train Loss: 0.3379, Val Loss: 0.4117\n",
      "Epoch [5206/10000], Train Loss: 0.3375, Val Loss: 0.4560\n",
      "Epoch [5207/10000], Train Loss: 0.3377, Val Loss: 0.4262\n",
      "Epoch [5208/10000], Train Loss: 0.3371, Val Loss: 0.3948\n",
      "Epoch [5209/10000], Train Loss: 0.3374, Val Loss: 0.4043\n",
      "Epoch [5210/10000], Train Loss: 0.3374, Val Loss: 0.3971\n",
      "Epoch [5211/10000], Train Loss: 0.3379, Val Loss: 0.3939\n",
      "Epoch [5212/10000], Train Loss: 0.3373, Val Loss: 0.4069\n",
      "Epoch [5213/10000], Train Loss: 0.3375, Val Loss: 0.4318\n",
      "Epoch [5214/10000], Train Loss: 0.3380, Val Loss: 0.3985\n",
      "Epoch [5215/10000], Train Loss: 0.3375, Val Loss: 0.4023\n",
      "Epoch [5216/10000], Train Loss: 0.3374, Val Loss: 0.4027\n",
      "Epoch [5217/10000], Train Loss: 0.3374, Val Loss: 0.4365\n",
      "Epoch [5218/10000], Train Loss: 0.3376, Val Loss: 0.4331\n",
      "Epoch [5219/10000], Train Loss: 0.3372, Val Loss: 0.4048\n",
      "Epoch [5220/10000], Train Loss: 0.3378, Val Loss: 0.4133\n",
      "Epoch [5221/10000], Train Loss: 0.3376, Val Loss: 0.5906\n",
      "Epoch [5222/10000], Train Loss: 0.3373, Val Loss: 0.4295\n",
      "Epoch [5223/10000], Train Loss: 0.3376, Val Loss: 0.3949\n",
      "Epoch [5224/10000], Train Loss: 0.3379, Val Loss: 0.5741\n",
      "Epoch [5225/10000], Train Loss: 0.3375, Val Loss: 0.4414\n",
      "Epoch [5226/10000], Train Loss: 0.3380, Val Loss: 0.3972\n",
      "Epoch [5227/10000], Train Loss: 0.3371, Val Loss: 0.4145\n",
      "Epoch [5228/10000], Train Loss: 0.3372, Val Loss: 0.4089\n",
      "Epoch [5229/10000], Train Loss: 0.3380, Val Loss: 0.4002\n",
      "Epoch [5230/10000], Train Loss: 0.3373, Val Loss: 0.4055\n",
      "Epoch [5231/10000], Train Loss: 0.3381, Val Loss: 0.4452\n",
      "Epoch [5232/10000], Train Loss: 0.3376, Val Loss: 0.4378\n",
      "Epoch [5233/10000], Train Loss: 0.3379, Val Loss: 0.4052\n",
      "Epoch [5234/10000], Train Loss: 0.3375, Val Loss: 0.4061\n",
      "Epoch [5235/10000], Train Loss: 0.3373, Val Loss: 0.4124\n",
      "Epoch [5236/10000], Train Loss: 0.3370, Val Loss: 0.3926\n",
      "Epoch [5237/10000], Train Loss: 0.3380, Val Loss: 0.6655\n",
      "Epoch [5238/10000], Train Loss: 0.3384, Val Loss: 0.4464\n",
      "Epoch [5239/10000], Train Loss: 0.3381, Val Loss: 0.3945\n",
      "Epoch [5240/10000], Train Loss: 0.3373, Val Loss: 0.4956\n",
      "Epoch [5241/10000], Train Loss: 0.3372, Val Loss: 0.4168\n",
      "Epoch [5242/10000], Train Loss: 0.3374, Val Loss: 0.4512\n",
      "Epoch [5243/10000], Train Loss: 0.3380, Val Loss: 0.4517\n",
      "Epoch [5244/10000], Train Loss: 0.3378, Val Loss: 0.5660\n",
      "Epoch [5245/10000], Train Loss: 0.3376, Val Loss: 0.4264\n",
      "Epoch [5246/10000], Train Loss: 0.3376, Val Loss: 0.4093\n",
      "Epoch [5247/10000], Train Loss: 0.3371, Val Loss: 0.4003\n",
      "Epoch [5248/10000], Train Loss: 0.3377, Val Loss: 0.3963\n",
      "Epoch [5249/10000], Train Loss: 0.3370, Val Loss: 0.4081\n",
      "Epoch [5250/10000], Train Loss: 0.3375, Val Loss: 0.4010\n",
      "Epoch [5251/10000], Train Loss: 0.3372, Val Loss: 0.4458\n",
      "Epoch [5252/10000], Train Loss: 0.3371, Val Loss: 0.4008\n",
      "Epoch [5253/10000], Train Loss: 0.3374, Val Loss: 0.4621\n",
      "Epoch [5254/10000], Train Loss: 0.3377, Val Loss: 0.4029\n",
      "Epoch [5255/10000], Train Loss: 0.3376, Val Loss: 0.3926\n",
      "Epoch [5256/10000], Train Loss: 0.3374, Val Loss: 0.5028\n",
      "Epoch [5257/10000], Train Loss: 0.3377, Val Loss: 0.4119\n",
      "Epoch [5258/10000], Train Loss: 0.3378, Val Loss: 0.5273\n",
      "Epoch [5259/10000], Train Loss: 0.3374, Val Loss: 0.4785\n",
      "Epoch [5260/10000], Train Loss: 0.3376, Val Loss: 0.4467\n",
      "Epoch [5261/10000], Train Loss: 0.3379, Val Loss: 0.4181\n",
      "Epoch [5262/10000], Train Loss: 0.3379, Val Loss: 0.5024\n",
      "Epoch [5263/10000], Train Loss: 0.3373, Val Loss: 0.4581\n",
      "Epoch [5264/10000], Train Loss: 0.3374, Val Loss: 0.3955\n",
      "Epoch [5265/10000], Train Loss: 0.3374, Val Loss: 0.4002\n",
      "Epoch [5266/10000], Train Loss: 0.3373, Val Loss: 0.4348\n",
      "Epoch [5267/10000], Train Loss: 0.3376, Val Loss: 0.3983\n",
      "Epoch [5268/10000], Train Loss: 0.3378, Val Loss: 0.4241\n",
      "Epoch [5269/10000], Train Loss: 0.3378, Val Loss: 0.3951\n",
      "Epoch [5270/10000], Train Loss: 0.3376, Val Loss: 0.3919\n",
      "Epoch [5271/10000], Train Loss: 0.3382, Val Loss: 0.4039\n",
      "Epoch [5272/10000], Train Loss: 0.3394, Val Loss: 0.4300\n",
      "Epoch [5273/10000], Train Loss: 0.3374, Val Loss: 0.4060\n",
      "Epoch [5274/10000], Train Loss: 0.3381, Val Loss: 0.4188\n",
      "Epoch [5275/10000], Train Loss: 0.3375, Val Loss: 0.5828\n",
      "Epoch [5276/10000], Train Loss: 0.3377, Val Loss: 0.3976\n",
      "Epoch [5277/10000], Train Loss: 0.3372, Val Loss: 0.3965\n",
      "Epoch [5278/10000], Train Loss: 0.3371, Val Loss: 0.4015\n",
      "Epoch [5279/10000], Train Loss: 0.3375, Val Loss: 0.4106\n",
      "Epoch [5280/10000], Train Loss: 0.3372, Val Loss: 0.4006\n",
      "Epoch [5281/10000], Train Loss: 0.3378, Val Loss: 0.3945\n",
      "Epoch [5282/10000], Train Loss: 0.3375, Val Loss: 0.4051\n",
      "Epoch [5283/10000], Train Loss: 0.3371, Val Loss: 0.3930\n",
      "Epoch [5284/10000], Train Loss: 0.3379, Val Loss: 0.4057\n",
      "Epoch [5285/10000], Train Loss: 0.3369, Val Loss: 0.4070\n",
      "Epoch [5286/10000], Train Loss: 0.3368, Val Loss: 0.4621\n",
      "Epoch [5287/10000], Train Loss: 0.3379, Val Loss: 0.3933\n",
      "Epoch [5288/10000], Train Loss: 0.3370, Val Loss: 0.4001\n",
      "Epoch [5289/10000], Train Loss: 0.3378, Val Loss: 0.3958\n",
      "Epoch [5290/10000], Train Loss: 0.3377, Val Loss: 0.4079\n",
      "Epoch [5291/10000], Train Loss: 0.3373, Val Loss: 0.4034\n",
      "Epoch [5292/10000], Train Loss: 0.3368, Val Loss: 0.4058\n",
      "Epoch [5293/10000], Train Loss: 0.3378, Val Loss: 0.3939\n",
      "Epoch [5294/10000], Train Loss: 0.3375, Val Loss: 0.4147\n",
      "Epoch [5295/10000], Train Loss: 0.3379, Val Loss: 0.4199\n",
      "Epoch [5296/10000], Train Loss: 0.3382, Val Loss: 0.4233\n",
      "Epoch [5297/10000], Train Loss: 0.3381, Val Loss: 0.3962\n",
      "Epoch [5298/10000], Train Loss: 0.3370, Val Loss: 0.4002\n",
      "Epoch [5299/10000], Train Loss: 0.3370, Val Loss: 0.4011\n",
      "Epoch [5300/10000], Train Loss: 0.3374, Val Loss: 0.4079\n",
      "Epoch [5301/10000], Train Loss: 0.3373, Val Loss: 0.4537\n",
      "Epoch [5302/10000], Train Loss: 0.3381, Val Loss: 0.4132\n",
      "Epoch [5303/10000], Train Loss: 0.3376, Val Loss: 0.4120\n",
      "Epoch [5304/10000], Train Loss: 0.3377, Val Loss: 0.4336\n",
      "Epoch [5305/10000], Train Loss: 0.3371, Val Loss: 0.4687\n",
      "Epoch [5306/10000], Train Loss: 0.3368, Val Loss: 0.4379\n",
      "Epoch [5307/10000], Train Loss: 0.3374, Val Loss: 0.4077\n",
      "Epoch [5308/10000], Train Loss: 0.3374, Val Loss: 0.5335\n",
      "Epoch [5309/10000], Train Loss: 0.3371, Val Loss: 0.4568\n",
      "Epoch [5310/10000], Train Loss: 0.3377, Val Loss: 0.4016\n",
      "Epoch [5311/10000], Train Loss: 0.3369, Val Loss: 0.3984\n",
      "Epoch [5312/10000], Train Loss: 0.3370, Val Loss: 0.4010\n",
      "Epoch [5313/10000], Train Loss: 0.3370, Val Loss: 0.4385\n",
      "Epoch [5314/10000], Train Loss: 0.3376, Val Loss: 0.4055\n",
      "Epoch [5315/10000], Train Loss: 0.3368, Val Loss: 0.4238\n",
      "Epoch [5316/10000], Train Loss: 0.3376, Val Loss: 0.4470\n",
      "Epoch [5317/10000], Train Loss: 0.3372, Val Loss: 0.4040\n",
      "Epoch [5318/10000], Train Loss: 0.3375, Val Loss: 0.4077\n",
      "Epoch [5319/10000], Train Loss: 0.3377, Val Loss: 0.4223\n",
      "Epoch [5320/10000], Train Loss: 0.3371, Val Loss: 0.4262\n",
      "Epoch [5321/10000], Train Loss: 0.3372, Val Loss: 0.4211\n",
      "Epoch [5322/10000], Train Loss: 0.3375, Val Loss: 0.4039\n",
      "Epoch [5323/10000], Train Loss: 0.3375, Val Loss: 0.4121\n",
      "Epoch [5324/10000], Train Loss: 0.3378, Val Loss: 0.4672\n",
      "Epoch [5325/10000], Train Loss: 0.3367, Val Loss: 0.3922\n",
      "Epoch [5326/10000], Train Loss: 0.3375, Val Loss: 0.4539\n",
      "Epoch [5327/10000], Train Loss: 0.3378, Val Loss: 0.3943\n",
      "Epoch [5328/10000], Train Loss: 0.3369, Val Loss: 0.3979\n",
      "Epoch [5329/10000], Train Loss: 0.3381, Val Loss: 0.4200\n",
      "Epoch [5330/10000], Train Loss: 0.3377, Val Loss: 0.4665\n",
      "Epoch [5331/10000], Train Loss: 0.3373, Val Loss: 0.4166\n",
      "Epoch [5332/10000], Train Loss: 0.3371, Val Loss: 0.3990\n",
      "Epoch [5333/10000], Train Loss: 0.3376, Val Loss: 0.4362\n",
      "Epoch [5334/10000], Train Loss: 0.3375, Val Loss: 0.3957\n",
      "Epoch [5335/10000], Train Loss: 0.3370, Val Loss: 0.4043\n",
      "Epoch [5336/10000], Train Loss: 0.3377, Val Loss: 0.4600\n",
      "Epoch [5337/10000], Train Loss: 0.3372, Val Loss: 0.4058\n",
      "Epoch [5338/10000], Train Loss: 0.3376, Val Loss: 0.4235\n",
      "Epoch [5339/10000], Train Loss: 0.3375, Val Loss: 0.4189\n",
      "Epoch [5340/10000], Train Loss: 0.3368, Val Loss: 0.4257\n",
      "Epoch [5341/10000], Train Loss: 0.3371, Val Loss: 0.3993\n",
      "Epoch [5342/10000], Train Loss: 0.3375, Val Loss: 0.4424\n",
      "Epoch [5343/10000], Train Loss: 0.3375, Val Loss: 0.3991\n",
      "Epoch [5344/10000], Train Loss: 0.3380, Val Loss: 0.3982\n",
      "Epoch [5345/10000], Train Loss: 0.3372, Val Loss: 0.3931\n",
      "Epoch [5346/10000], Train Loss: 0.3373, Val Loss: 0.3918\n",
      "Epoch [5347/10000], Train Loss: 0.3377, Val Loss: 0.4280\n",
      "Epoch [5348/10000], Train Loss: 0.3382, Val Loss: 0.3959\n",
      "Epoch [5349/10000], Train Loss: 0.3370, Val Loss: 0.4424\n",
      "Epoch [5350/10000], Train Loss: 0.3374, Val Loss: 0.3929\n",
      "Epoch [5351/10000], Train Loss: 0.3372, Val Loss: 0.3984\n",
      "Epoch [5352/10000], Train Loss: 0.3377, Val Loss: 0.4031\n",
      "Epoch [5353/10000], Train Loss: 0.3371, Val Loss: 0.4191\n",
      "Epoch [5354/10000], Train Loss: 0.3375, Val Loss: 0.5391\n",
      "Epoch [5355/10000], Train Loss: 0.3374, Val Loss: 0.4856\n",
      "Epoch [5356/10000], Train Loss: 0.3375, Val Loss: 0.4195\n",
      "Epoch [5357/10000], Train Loss: 0.3370, Val Loss: 0.5067\n",
      "Epoch [5358/10000], Train Loss: 0.3377, Val Loss: 0.4077\n",
      "Epoch [5359/10000], Train Loss: 0.3378, Val Loss: 0.4072\n",
      "Epoch [5360/10000], Train Loss: 0.3378, Val Loss: 0.4067\n",
      "Epoch [5361/10000], Train Loss: 0.3375, Val Loss: 0.4002\n",
      "Epoch [5362/10000], Train Loss: 0.3372, Val Loss: 0.4619\n",
      "Epoch [5363/10000], Train Loss: 0.3379, Val Loss: 0.3909\n",
      "Epoch [5364/10000], Train Loss: 0.3378, Val Loss: 0.6187\n",
      "Epoch [5365/10000], Train Loss: 0.3376, Val Loss: 0.4023\n",
      "Epoch [5366/10000], Train Loss: 0.3373, Val Loss: 0.4102\n",
      "Epoch [5367/10000], Train Loss: 0.3372, Val Loss: 0.4221\n",
      "Epoch [5368/10000], Train Loss: 0.3376, Val Loss: 0.4027\n",
      "Epoch [5369/10000], Train Loss: 0.3379, Val Loss: 0.4440\n",
      "Epoch [5370/10000], Train Loss: 0.3382, Val Loss: 0.4278\n",
      "Epoch [5371/10000], Train Loss: 0.3376, Val Loss: 0.4095\n",
      "Epoch [5372/10000], Train Loss: 0.3378, Val Loss: 0.4552\n",
      "Epoch [5373/10000], Train Loss: 0.3372, Val Loss: 0.4219\n",
      "Epoch [5374/10000], Train Loss: 0.3379, Val Loss: 0.5927\n",
      "Epoch [5375/10000], Train Loss: 0.3374, Val Loss: 0.4044\n",
      "Epoch [5376/10000], Train Loss: 0.3371, Val Loss: 0.4172\n",
      "Epoch [5377/10000], Train Loss: 0.3385, Val Loss: 0.4336\n",
      "Epoch [5378/10000], Train Loss: 0.3369, Val Loss: 0.4283\n",
      "Epoch [5379/10000], Train Loss: 0.3373, Val Loss: 0.4790\n",
      "Epoch [5380/10000], Train Loss: 0.3377, Val Loss: 0.3954\n",
      "Epoch [5381/10000], Train Loss: 0.3373, Val Loss: 0.4072\n",
      "Epoch [5382/10000], Train Loss: 0.3371, Val Loss: 0.4181\n",
      "Epoch [5383/10000], Train Loss: 0.3374, Val Loss: 0.4409\n",
      "Epoch [5384/10000], Train Loss: 0.3375, Val Loss: 0.4107\n",
      "Epoch [5385/10000], Train Loss: 0.3377, Val Loss: 0.3974\n",
      "Epoch [5386/10000], Train Loss: 0.3371, Val Loss: 0.4354\n",
      "Epoch [5387/10000], Train Loss: 0.3375, Val Loss: 0.4188\n",
      "Epoch [5388/10000], Train Loss: 0.3376, Val Loss: 0.4122\n",
      "Epoch [5389/10000], Train Loss: 0.3374, Val Loss: 0.4125\n",
      "Epoch [5390/10000], Train Loss: 0.3375, Val Loss: 0.4125\n",
      "Epoch [5391/10000], Train Loss: 0.3373, Val Loss: 0.4004\n",
      "Epoch [5392/10000], Train Loss: 0.3375, Val Loss: 0.4075\n",
      "Epoch [5393/10000], Train Loss: 0.3375, Val Loss: 0.4121\n",
      "Epoch [5394/10000], Train Loss: 0.3371, Val Loss: 0.4691\n",
      "Epoch [5395/10000], Train Loss: 0.3367, Val Loss: 0.4231\n",
      "Epoch [5396/10000], Train Loss: 0.3371, Val Loss: 0.4083\n",
      "Epoch [5397/10000], Train Loss: 0.3378, Val Loss: 0.3993\n",
      "Epoch [5398/10000], Train Loss: 0.3380, Val Loss: 0.4102\n",
      "Epoch [5399/10000], Train Loss: 0.3381, Val Loss: 0.4014\n",
      "Epoch [5400/10000], Train Loss: 0.3371, Val Loss: 0.6257\n",
      "Epoch [5401/10000], Train Loss: 0.3369, Val Loss: 0.3936\n",
      "Epoch [5402/10000], Train Loss: 0.3369, Val Loss: 0.3932\n",
      "Epoch [5403/10000], Train Loss: 0.3370, Val Loss: 0.3984\n",
      "Epoch [5404/10000], Train Loss: 0.3368, Val Loss: 0.3911\n",
      "Epoch [5405/10000], Train Loss: 0.3377, Val Loss: 0.4240\n",
      "Epoch [5406/10000], Train Loss: 0.3373, Val Loss: 0.3985\n",
      "Epoch [5407/10000], Train Loss: 0.3380, Val Loss: 0.3917\n",
      "Epoch [5408/10000], Train Loss: 0.3374, Val Loss: 0.4803\n",
      "Epoch [5409/10000], Train Loss: 0.3371, Val Loss: 0.4540\n",
      "Epoch [5410/10000], Train Loss: 0.3377, Val Loss: 0.4101\n",
      "Epoch [5411/10000], Train Loss: 0.3377, Val Loss: 0.4486\n",
      "Epoch [5412/10000], Train Loss: 0.3373, Val Loss: 0.3952\n",
      "Epoch [5413/10000], Train Loss: 0.3377, Val Loss: 0.4282\n",
      "Epoch [5414/10000], Train Loss: 0.3374, Val Loss: 0.4216\n",
      "Epoch [5415/10000], Train Loss: 0.3376, Val Loss: 0.4066\n",
      "Epoch [5416/10000], Train Loss: 0.3382, Val Loss: 0.3997\n",
      "Epoch [5417/10000], Train Loss: 0.3368, Val Loss: 0.4169\n",
      "Epoch [5418/10000], Train Loss: 0.3375, Val Loss: 0.4690\n",
      "Epoch [5419/10000], Train Loss: 0.3368, Val Loss: 0.4157\n",
      "Epoch [5420/10000], Train Loss: 0.3376, Val Loss: 0.4177\n",
      "Epoch [5421/10000], Train Loss: 0.3371, Val Loss: 0.3956\n",
      "Epoch [5422/10000], Train Loss: 0.3383, Val Loss: 0.4257\n",
      "Epoch [5423/10000], Train Loss: 0.3372, Val Loss: 0.4097\n",
      "Epoch [5424/10000], Train Loss: 0.3375, Val Loss: 0.4115\n",
      "Epoch [5425/10000], Train Loss: 0.3372, Val Loss: 0.4178\n",
      "Epoch [5426/10000], Train Loss: 0.3375, Val Loss: 0.4197\n",
      "Epoch [5427/10000], Train Loss: 0.3372, Val Loss: 0.3974\n",
      "Epoch [5428/10000], Train Loss: 0.3372, Val Loss: 0.3961\n",
      "Epoch [5429/10000], Train Loss: 0.3373, Val Loss: 0.5173\n",
      "Epoch [5430/10000], Train Loss: 0.3376, Val Loss: 0.3987\n",
      "Epoch [5431/10000], Train Loss: 0.3376, Val Loss: 0.3973\n",
      "Epoch [5432/10000], Train Loss: 0.3367, Val Loss: 0.3938\n",
      "Epoch [5433/10000], Train Loss: 0.3375, Val Loss: 0.4775\n",
      "Epoch [5434/10000], Train Loss: 0.3370, Val Loss: 0.5412\n",
      "Epoch [5435/10000], Train Loss: 0.3370, Val Loss: 0.4012\n",
      "Epoch [5436/10000], Train Loss: 0.3379, Val Loss: 0.4064\n",
      "Epoch [5437/10000], Train Loss: 0.3369, Val Loss: 0.4099\n",
      "Epoch [5438/10000], Train Loss: 0.3374, Val Loss: 0.4012\n",
      "Epoch [5439/10000], Train Loss: 0.3374, Val Loss: 0.4302\n",
      "Epoch [5440/10000], Train Loss: 0.3378, Val Loss: 0.3979\n",
      "Epoch [5441/10000], Train Loss: 0.3375, Val Loss: 0.4283\n",
      "Epoch [5442/10000], Train Loss: 0.3367, Val Loss: 0.4100\n",
      "Epoch [5443/10000], Train Loss: 0.3372, Val Loss: 0.4110\n",
      "Epoch [5444/10000], Train Loss: 0.3381, Val Loss: 0.4052\n",
      "Epoch [5445/10000], Train Loss: 0.3374, Val Loss: 0.4055\n",
      "Epoch [5446/10000], Train Loss: 0.3372, Val Loss: 0.4004\n",
      "Epoch [5447/10000], Train Loss: 0.3375, Val Loss: 0.4071\n",
      "Epoch [5448/10000], Train Loss: 0.3375, Val Loss: 0.4488\n",
      "Epoch [5449/10000], Train Loss: 0.3371, Val Loss: 0.4551\n",
      "Epoch [5450/10000], Train Loss: 0.3367, Val Loss: 0.3949\n",
      "Epoch [5451/10000], Train Loss: 0.3375, Val Loss: 0.4456\n",
      "Epoch [5452/10000], Train Loss: 0.3371, Val Loss: 0.4996\n",
      "Epoch [5453/10000], Train Loss: 0.3373, Val Loss: 0.4301\n",
      "Epoch [5454/10000], Train Loss: 0.3374, Val Loss: 0.4144\n",
      "Epoch [5455/10000], Train Loss: 0.3369, Val Loss: 0.4153\n",
      "Epoch [5456/10000], Train Loss: 0.3373, Val Loss: 0.3969\n",
      "Epoch [5457/10000], Train Loss: 0.3373, Val Loss: 0.4155\n",
      "Epoch [5458/10000], Train Loss: 0.3377, Val Loss: 0.3954\n",
      "Epoch [5459/10000], Train Loss: 0.3369, Val Loss: 0.4739\n",
      "Epoch [5460/10000], Train Loss: 0.3365, Val Loss: 0.3943\n",
      "Epoch [5461/10000], Train Loss: 0.3370, Val Loss: 0.4527\n",
      "Epoch [5462/10000], Train Loss: 0.3363, Val Loss: 0.4067\n",
      "Epoch [5463/10000], Train Loss: 0.3379, Val Loss: 0.4003\n",
      "Epoch [5464/10000], Train Loss: 0.3372, Val Loss: 0.4102\n",
      "Epoch [5465/10000], Train Loss: 0.3376, Val Loss: 0.4581\n",
      "Epoch [5466/10000], Train Loss: 0.3373, Val Loss: 0.5612\n",
      "Epoch [5467/10000], Train Loss: 0.3374, Val Loss: 0.4001\n",
      "Epoch [5468/10000], Train Loss: 0.3372, Val Loss: 0.3956\n",
      "Epoch [5469/10000], Train Loss: 0.3371, Val Loss: 0.4034\n",
      "Epoch [5470/10000], Train Loss: 0.3372, Val Loss: 0.4480\n",
      "Epoch [5471/10000], Train Loss: 0.3372, Val Loss: 0.4117\n",
      "Epoch [5472/10000], Train Loss: 0.3369, Val Loss: 0.3984\n",
      "Epoch [5473/10000], Train Loss: 0.3374, Val Loss: 0.5636\n",
      "Epoch [5474/10000], Train Loss: 0.3373, Val Loss: 0.4039\n",
      "Epoch [5475/10000], Train Loss: 0.3367, Val Loss: 0.4435\n",
      "Epoch [5476/10000], Train Loss: 0.3370, Val Loss: 0.4173\n",
      "Epoch [5477/10000], Train Loss: 0.3368, Val Loss: 0.4179\n",
      "Epoch [5478/10000], Train Loss: 0.3370, Val Loss: 0.4575\n",
      "Epoch [5479/10000], Train Loss: 0.3375, Val Loss: 0.3927\n",
      "Epoch [5480/10000], Train Loss: 0.3372, Val Loss: 0.5226\n",
      "Epoch [5481/10000], Train Loss: 0.3367, Val Loss: 0.4968\n",
      "Epoch [5482/10000], Train Loss: 0.3372, Val Loss: 0.4081\n",
      "Epoch [5483/10000], Train Loss: 0.3372, Val Loss: 0.3981\n",
      "Epoch [5484/10000], Train Loss: 0.3373, Val Loss: 0.4106\n",
      "Epoch [5485/10000], Train Loss: 0.3369, Val Loss: 0.4580\n",
      "Epoch [5486/10000], Train Loss: 0.3369, Val Loss: 0.3967\n",
      "Epoch [5487/10000], Train Loss: 0.3367, Val Loss: 0.4034\n",
      "Epoch [5488/10000], Train Loss: 0.3371, Val Loss: 0.3998\n",
      "Epoch [5489/10000], Train Loss: 0.3368, Val Loss: 0.4313\n",
      "Epoch [5490/10000], Train Loss: 0.3365, Val Loss: 0.4429\n",
      "Epoch [5491/10000], Train Loss: 0.3368, Val Loss: 0.4781\n",
      "Epoch [5492/10000], Train Loss: 0.3371, Val Loss: 0.4488\n",
      "Epoch [5493/10000], Train Loss: 0.3375, Val Loss: 0.4083\n",
      "Epoch [5494/10000], Train Loss: 0.3367, Val Loss: 0.3929\n",
      "Epoch [5495/10000], Train Loss: 0.3367, Val Loss: 0.3964\n",
      "Epoch [5496/10000], Train Loss: 0.3370, Val Loss: 0.4903\n",
      "Epoch [5497/10000], Train Loss: 0.3365, Val Loss: 0.4008\n",
      "Epoch [5498/10000], Train Loss: 0.3375, Val Loss: 0.4005\n",
      "Epoch [5499/10000], Train Loss: 0.3368, Val Loss: 0.3968\n",
      "Epoch [5500/10000], Train Loss: 0.3367, Val Loss: 0.4877\n",
      "Epoch [5501/10000], Train Loss: 0.3368, Val Loss: 0.4799\n",
      "Epoch [5502/10000], Train Loss: 0.3366, Val Loss: 0.3937\n",
      "Epoch [5503/10000], Train Loss: 0.3365, Val Loss: 0.4742\n",
      "Epoch [5504/10000], Train Loss: 0.3370, Val Loss: 0.4043\n",
      "Epoch [5505/10000], Train Loss: 0.3372, Val Loss: 0.4106\n",
      "Epoch [5506/10000], Train Loss: 0.3374, Val Loss: 0.4183\n",
      "Epoch [5507/10000], Train Loss: 0.3361, Val Loss: 0.3968\n",
      "Epoch [5508/10000], Train Loss: 0.3370, Val Loss: 0.4729\n",
      "Epoch [5509/10000], Train Loss: 0.3366, Val Loss: 0.4146\n",
      "Epoch [5510/10000], Train Loss: 0.3368, Val Loss: 0.4219\n",
      "Epoch [5511/10000], Train Loss: 0.3367, Val Loss: 0.3937\n",
      "Epoch [5512/10000], Train Loss: 0.3363, Val Loss: 0.3967\n",
      "Epoch [5513/10000], Train Loss: 0.3367, Val Loss: 0.5543\n",
      "Epoch [5514/10000], Train Loss: 0.3371, Val Loss: 0.3950\n",
      "Epoch [5515/10000], Train Loss: 0.3360, Val Loss: 0.3966\n",
      "Epoch [5516/10000], Train Loss: 0.3362, Val Loss: 0.3909\n",
      "Epoch [5517/10000], Train Loss: 0.3366, Val Loss: 0.4996\n",
      "Epoch [5518/10000], Train Loss: 0.3370, Val Loss: 0.4159\n",
      "Epoch [5519/10000], Train Loss: 0.3367, Val Loss: 0.4331\n",
      "Epoch [5520/10000], Train Loss: 0.3371, Val Loss: 0.4517\n",
      "Epoch [5521/10000], Train Loss: 0.3365, Val Loss: 0.3962\n",
      "Epoch [5522/10000], Train Loss: 0.3366, Val Loss: 0.4028\n",
      "Epoch [5523/10000], Train Loss: 0.3366, Val Loss: 0.4098\n",
      "Epoch [5524/10000], Train Loss: 0.3366, Val Loss: 0.4244\n",
      "Epoch [5525/10000], Train Loss: 0.3366, Val Loss: 0.4043\n",
      "Epoch [5526/10000], Train Loss: 0.3370, Val Loss: 0.4216\n",
      "Epoch [5527/10000], Train Loss: 0.3362, Val Loss: 0.4151\n",
      "Epoch [5528/10000], Train Loss: 0.3363, Val Loss: 0.3920\n",
      "Epoch [5529/10000], Train Loss: 0.3362, Val Loss: 0.3969\n",
      "Epoch [5530/10000], Train Loss: 0.3369, Val Loss: 0.4094\n",
      "Epoch [5531/10000], Train Loss: 0.3364, Val Loss: 0.3988\n",
      "Epoch [5532/10000], Train Loss: 0.3364, Val Loss: 0.4090\n",
      "Epoch [5533/10000], Train Loss: 0.3363, Val Loss: 0.4255\n",
      "Epoch [5534/10000], Train Loss: 0.3362, Val Loss: 0.4021\n",
      "Epoch [5535/10000], Train Loss: 0.3366, Val Loss: 0.4080\n",
      "Epoch [5536/10000], Train Loss: 0.3367, Val Loss: 0.4042\n",
      "Epoch [5537/10000], Train Loss: 0.3367, Val Loss: 0.4122\n",
      "Epoch [5538/10000], Train Loss: 0.3366, Val Loss: 0.4331\n",
      "Epoch [5539/10000], Train Loss: 0.3368, Val Loss: 0.4047\n",
      "Epoch [5540/10000], Train Loss: 0.3366, Val Loss: 0.4509\n",
      "Epoch [5541/10000], Train Loss: 0.3360, Val Loss: 0.3974\n",
      "Epoch [5542/10000], Train Loss: 0.3363, Val Loss: 0.4364\n",
      "Epoch [5543/10000], Train Loss: 0.3363, Val Loss: 0.4069\n",
      "Epoch [5544/10000], Train Loss: 0.3367, Val Loss: 0.4322\n",
      "Epoch [5545/10000], Train Loss: 0.3368, Val Loss: 0.4020\n",
      "Epoch [5546/10000], Train Loss: 0.3366, Val Loss: 0.3929\n",
      "Epoch [5547/10000], Train Loss: 0.3371, Val Loss: 0.4464\n",
      "Epoch [5548/10000], Train Loss: 0.3363, Val Loss: 0.4080\n",
      "Epoch [5549/10000], Train Loss: 0.3361, Val Loss: 0.4056\n",
      "Epoch [5550/10000], Train Loss: 0.3364, Val Loss: 0.4072\n",
      "Epoch [5551/10000], Train Loss: 0.3355, Val Loss: 0.4852\n",
      "Epoch [5552/10000], Train Loss: 0.3368, Val Loss: 0.4344\n",
      "Epoch [5553/10000], Train Loss: 0.3362, Val Loss: 0.4481\n",
      "Epoch [5554/10000], Train Loss: 0.3366, Val Loss: 0.4684\n",
      "Epoch [5555/10000], Train Loss: 0.3363, Val Loss: 0.5511\n",
      "Epoch [5556/10000], Train Loss: 0.3363, Val Loss: 0.4078\n",
      "Epoch [5557/10000], Train Loss: 0.3361, Val Loss: 0.3929\n",
      "Epoch [5558/10000], Train Loss: 0.3369, Val Loss: 0.4263\n",
      "Epoch [5559/10000], Train Loss: 0.3364, Val Loss: 0.4017\n",
      "Epoch [5560/10000], Train Loss: 0.3367, Val Loss: 0.4002\n",
      "Epoch [5561/10000], Train Loss: 0.3365, Val Loss: 0.4425\n",
      "Epoch [5562/10000], Train Loss: 0.3367, Val Loss: 0.3954\n",
      "Epoch [5563/10000], Train Loss: 0.3362, Val Loss: 0.4009\n",
      "Epoch [5564/10000], Train Loss: 0.3366, Val Loss: 0.4120\n",
      "Epoch [5565/10000], Train Loss: 0.3359, Val Loss: 0.4688\n",
      "Epoch [5566/10000], Train Loss: 0.3356, Val Loss: 0.4582\n",
      "Epoch [5567/10000], Train Loss: 0.3368, Val Loss: 0.4308\n",
      "Epoch [5568/10000], Train Loss: 0.3370, Val Loss: 0.4334\n",
      "Epoch [5569/10000], Train Loss: 0.3357, Val Loss: 0.4423\n",
      "Epoch [5570/10000], Train Loss: 0.3364, Val Loss: 0.3968\n",
      "Epoch [5571/10000], Train Loss: 0.3365, Val Loss: 0.4149\n",
      "Epoch [5572/10000], Train Loss: 0.3365, Val Loss: 0.4039\n",
      "Epoch [5573/10000], Train Loss: 0.3365, Val Loss: 0.4057\n",
      "Epoch [5574/10000], Train Loss: 0.3361, Val Loss: 0.4012\n",
      "Epoch [5575/10000], Train Loss: 0.3360, Val Loss: 0.4312\n",
      "Epoch [5576/10000], Train Loss: 0.3360, Val Loss: 0.3991\n",
      "Epoch [5577/10000], Train Loss: 0.3370, Val Loss: 0.3985\n",
      "Epoch [5578/10000], Train Loss: 0.3361, Val Loss: 0.3976\n",
      "Epoch [5579/10000], Train Loss: 0.3360, Val Loss: 0.4347\n",
      "Epoch [5580/10000], Train Loss: 0.3364, Val Loss: 0.4184\n",
      "Epoch [5581/10000], Train Loss: 0.3363, Val Loss: 0.3931\n",
      "Epoch [5582/10000], Train Loss: 0.3363, Val Loss: 0.4413\n",
      "Epoch [5583/10000], Train Loss: 0.3370, Val Loss: 0.3975\n",
      "Epoch [5584/10000], Train Loss: 0.3364, Val Loss: 0.4166\n",
      "Epoch [5585/10000], Train Loss: 0.3361, Val Loss: 0.4000\n",
      "Epoch [5586/10000], Train Loss: 0.3364, Val Loss: 0.4030\n",
      "Epoch [5587/10000], Train Loss: 0.3358, Val Loss: 0.4037\n",
      "Epoch [5588/10000], Train Loss: 0.3359, Val Loss: 0.4113\n",
      "Epoch [5589/10000], Train Loss: 0.3363, Val Loss: 0.3940\n",
      "Epoch [5590/10000], Train Loss: 0.3364, Val Loss: 0.4202\n",
      "Epoch [5591/10000], Train Loss: 0.3366, Val Loss: 0.4050\n",
      "Epoch [5592/10000], Train Loss: 0.3361, Val Loss: 0.3952\n",
      "Epoch [5593/10000], Train Loss: 0.3368, Val Loss: 0.3949\n",
      "Epoch [5594/10000], Train Loss: 0.3361, Val Loss: 0.3952\n",
      "Epoch [5595/10000], Train Loss: 0.3361, Val Loss: 0.4040\n",
      "Epoch [5596/10000], Train Loss: 0.3362, Val Loss: 0.4843\n",
      "Epoch [5597/10000], Train Loss: 0.3366, Val Loss: 0.4267\n",
      "Epoch [5598/10000], Train Loss: 0.3364, Val Loss: 0.3970\n",
      "Epoch [5599/10000], Train Loss: 0.3361, Val Loss: 0.4521\n",
      "Epoch [5600/10000], Train Loss: 0.3367, Val Loss: 0.4111\n",
      "Epoch [5601/10000], Train Loss: 0.3362, Val Loss: 0.4099\n",
      "Epoch [5602/10000], Train Loss: 0.3361, Val Loss: 0.4046\n",
      "Epoch [5603/10000], Train Loss: 0.3363, Val Loss: 0.4035\n",
      "Epoch [5604/10000], Train Loss: 0.3357, Val Loss: 0.4449\n",
      "Epoch [5605/10000], Train Loss: 0.3367, Val Loss: 0.5158\n",
      "Epoch [5606/10000], Train Loss: 0.3364, Val Loss: 0.4316\n",
      "Epoch [5607/10000], Train Loss: 0.3364, Val Loss: 0.4133\n",
      "Epoch [5608/10000], Train Loss: 0.3361, Val Loss: 0.4959\n",
      "Epoch [5609/10000], Train Loss: 0.3359, Val Loss: 0.3958\n",
      "Epoch [5610/10000], Train Loss: 0.3362, Val Loss: 0.4195\n",
      "Epoch [5611/10000], Train Loss: 0.3362, Val Loss: 0.5006\n",
      "Epoch [5612/10000], Train Loss: 0.3359, Val Loss: 0.4489\n",
      "Epoch [5613/10000], Train Loss: 0.3368, Val Loss: 0.4625\n",
      "Epoch [5614/10000], Train Loss: 0.3366, Val Loss: 0.3936\n",
      "Epoch [5615/10000], Train Loss: 0.3358, Val Loss: 0.3932\n",
      "Epoch [5616/10000], Train Loss: 0.3363, Val Loss: 0.3904\n",
      "Epoch [5617/10000], Train Loss: 0.3365, Val Loss: 0.4194\n",
      "Epoch [5618/10000], Train Loss: 0.3359, Val Loss: 0.4007\n",
      "Epoch [5619/10000], Train Loss: 0.3363, Val Loss: 0.4231\n",
      "Epoch [5620/10000], Train Loss: 0.3363, Val Loss: 0.4003\n",
      "Epoch [5621/10000], Train Loss: 0.3361, Val Loss: 0.3946\n",
      "Epoch [5622/10000], Train Loss: 0.3367, Val Loss: 0.4036\n",
      "Epoch [5623/10000], Train Loss: 0.3364, Val Loss: 0.4004\n",
      "Epoch [5624/10000], Train Loss: 0.3365, Val Loss: 0.3984\n",
      "Epoch [5625/10000], Train Loss: 0.3369, Val Loss: 0.4101\n",
      "Epoch [5626/10000], Train Loss: 0.3359, Val Loss: 0.3994\n",
      "Epoch [5627/10000], Train Loss: 0.3364, Val Loss: 0.4338\n",
      "Epoch [5628/10000], Train Loss: 0.3359, Val Loss: 0.4028\n",
      "Epoch [5629/10000], Train Loss: 0.3362, Val Loss: 0.4366\n",
      "Epoch [5630/10000], Train Loss: 0.3366, Val Loss: 0.4328\n",
      "Epoch [5631/10000], Train Loss: 0.3359, Val Loss: 0.4622\n",
      "Epoch [5632/10000], Train Loss: 0.3363, Val Loss: 0.4232\n",
      "Epoch [5633/10000], Train Loss: 0.3360, Val Loss: 0.4950\n",
      "Epoch [5634/10000], Train Loss: 0.3361, Val Loss: 0.4473\n",
      "Epoch [5635/10000], Train Loss: 0.3365, Val Loss: 0.5926\n",
      "Epoch [5636/10000], Train Loss: 0.3364, Val Loss: 0.3980\n",
      "Epoch [5637/10000], Train Loss: 0.3363, Val Loss: 0.4228\n",
      "Epoch [5638/10000], Train Loss: 0.3360, Val Loss: 0.4429\n",
      "Epoch [5639/10000], Train Loss: 0.3364, Val Loss: 0.3928\n",
      "Epoch [5640/10000], Train Loss: 0.3359, Val Loss: 0.4247\n",
      "Epoch [5641/10000], Train Loss: 0.3365, Val Loss: 0.4006\n",
      "Epoch [5642/10000], Train Loss: 0.3363, Val Loss: 0.4558\n",
      "Epoch [5643/10000], Train Loss: 0.3366, Val Loss: 0.4414\n",
      "Epoch [5644/10000], Train Loss: 0.3363, Val Loss: 0.3949\n",
      "Epoch [5645/10000], Train Loss: 0.3368, Val Loss: 0.4025\n",
      "Epoch [5646/10000], Train Loss: 0.3361, Val Loss: 0.4958\n",
      "Epoch [5647/10000], Train Loss: 0.3369, Val Loss: 0.5460\n",
      "Epoch [5648/10000], Train Loss: 0.3359, Val Loss: 0.4117\n",
      "Epoch [5649/10000], Train Loss: 0.3363, Val Loss: 0.3976\n",
      "Epoch [5650/10000], Train Loss: 0.3363, Val Loss: 0.4018\n",
      "Epoch [5651/10000], Train Loss: 0.3362, Val Loss: 0.4107\n",
      "Epoch [5652/10000], Train Loss: 0.3361, Val Loss: 0.4151\n",
      "Epoch [5653/10000], Train Loss: 0.3363, Val Loss: 0.4250\n",
      "Epoch [5654/10000], Train Loss: 0.3360, Val Loss: 0.3939\n",
      "Epoch [5655/10000], Train Loss: 0.3366, Val Loss: 0.3945\n",
      "Epoch [5656/10000], Train Loss: 0.3356, Val Loss: 0.4153\n",
      "Epoch [5657/10000], Train Loss: 0.3366, Val Loss: 0.4156\n",
      "Epoch [5658/10000], Train Loss: 0.3362, Val Loss: 0.4006\n",
      "Epoch [5659/10000], Train Loss: 0.3358, Val Loss: 0.3983\n",
      "Epoch [5660/10000], Train Loss: 0.3364, Val Loss: 0.4053\n",
      "Epoch [5661/10000], Train Loss: 0.3362, Val Loss: 0.4277\n",
      "Epoch [5662/10000], Train Loss: 0.3362, Val Loss: 0.4123\n",
      "Epoch [5663/10000], Train Loss: 0.3364, Val Loss: 0.6268\n",
      "Epoch [5664/10000], Train Loss: 0.3364, Val Loss: 0.3946\n",
      "Epoch [5665/10000], Train Loss: 0.3360, Val Loss: 0.4265\n",
      "Epoch [5666/10000], Train Loss: 0.3362, Val Loss: 0.3995\n",
      "Epoch [5667/10000], Train Loss: 0.3362, Val Loss: 0.4027\n",
      "Epoch [5668/10000], Train Loss: 0.3357, Val Loss: 0.3921\n",
      "Epoch [5669/10000], Train Loss: 0.3357, Val Loss: 0.4552\n",
      "Epoch [5670/10000], Train Loss: 0.3361, Val Loss: 0.4388\n",
      "Epoch [5671/10000], Train Loss: 0.3362, Val Loss: 0.4041\n",
      "Epoch [5672/10000], Train Loss: 0.3363, Val Loss: 0.3978\n",
      "Epoch [5673/10000], Train Loss: 0.3361, Val Loss: 0.4033\n",
      "Epoch [5674/10000], Train Loss: 0.3360, Val Loss: 0.4293\n",
      "Epoch [5675/10000], Train Loss: 0.3363, Val Loss: 0.4176\n",
      "Epoch [5676/10000], Train Loss: 0.3357, Val Loss: 0.3984\n",
      "Epoch [5677/10000], Train Loss: 0.3366, Val Loss: 0.4191\n",
      "Epoch [5678/10000], Train Loss: 0.3364, Val Loss: 0.4310\n",
      "Epoch [5679/10000], Train Loss: 0.3363, Val Loss: 0.4048\n",
      "Epoch [5680/10000], Train Loss: 0.3358, Val Loss: 0.4746\n",
      "Epoch [5681/10000], Train Loss: 0.3359, Val Loss: 0.5636\n",
      "Epoch [5682/10000], Train Loss: 0.3361, Val Loss: 0.4516\n",
      "Epoch [5683/10000], Train Loss: 0.3359, Val Loss: 0.3973\n",
      "Epoch [5684/10000], Train Loss: 0.3363, Val Loss: 0.4217\n",
      "Epoch [5685/10000], Train Loss: 0.3359, Val Loss: 0.4074\n",
      "Epoch [5686/10000], Train Loss: 0.3366, Val Loss: 0.4024\n",
      "Epoch [5687/10000], Train Loss: 0.3361, Val Loss: 0.4240\n",
      "Epoch [5688/10000], Train Loss: 0.3358, Val Loss: 0.5111\n",
      "Epoch [5689/10000], Train Loss: 0.3362, Val Loss: 0.3958\n",
      "Epoch [5690/10000], Train Loss: 0.3366, Val Loss: 0.5600\n",
      "Epoch [5691/10000], Train Loss: 0.3359, Val Loss: 0.4195\n",
      "Epoch [5692/10000], Train Loss: 0.3363, Val Loss: 0.4020\n",
      "Epoch [5693/10000], Train Loss: 0.3365, Val Loss: 0.3980\n",
      "Epoch [5694/10000], Train Loss: 0.3354, Val Loss: 0.4155\n",
      "Epoch [5695/10000], Train Loss: 0.3360, Val Loss: 0.4180\n",
      "Epoch [5696/10000], Train Loss: 0.3362, Val Loss: 0.4034\n",
      "Epoch [5697/10000], Train Loss: 0.3357, Val Loss: 0.3969\n",
      "Epoch [5698/10000], Train Loss: 0.3362, Val Loss: 0.4153\n",
      "Epoch [5699/10000], Train Loss: 0.3361, Val Loss: 0.4213\n",
      "Epoch [5700/10000], Train Loss: 0.3358, Val Loss: 0.4145\n",
      "Epoch [5701/10000], Train Loss: 0.3361, Val Loss: 0.4012\n",
      "Epoch [5702/10000], Train Loss: 0.3359, Val Loss: 0.4271\n",
      "Epoch [5703/10000], Train Loss: 0.3360, Val Loss: 0.4289\n",
      "Epoch [5704/10000], Train Loss: 0.3359, Val Loss: 0.4656\n",
      "Epoch [5705/10000], Train Loss: 0.3359, Val Loss: 0.4082\n",
      "Epoch [5706/10000], Train Loss: 0.3359, Val Loss: 0.3991\n",
      "Epoch [5707/10000], Train Loss: 0.3364, Val Loss: 0.3944\n",
      "Epoch [5708/10000], Train Loss: 0.3362, Val Loss: 0.4509\n",
      "Epoch [5709/10000], Train Loss: 0.3361, Val Loss: 0.3974\n",
      "Epoch [5710/10000], Train Loss: 0.3359, Val Loss: 0.4581\n",
      "Epoch [5711/10000], Train Loss: 0.3366, Val Loss: 0.3963\n",
      "Epoch [5712/10000], Train Loss: 0.3365, Val Loss: 0.4850\n",
      "Epoch [5713/10000], Train Loss: 0.3362, Val Loss: 0.4437\n",
      "Epoch [5714/10000], Train Loss: 0.3363, Val Loss: 0.3934\n",
      "Epoch [5715/10000], Train Loss: 0.3356, Val Loss: 0.4427\n",
      "Epoch [5716/10000], Train Loss: 0.3357, Val Loss: 0.4265\n",
      "Epoch [5717/10000], Train Loss: 0.3358, Val Loss: 0.4554\n",
      "Epoch [5718/10000], Train Loss: 0.3367, Val Loss: 0.4127\n",
      "Epoch [5719/10000], Train Loss: 0.3361, Val Loss: 0.4270\n",
      "Epoch [5720/10000], Train Loss: 0.3361, Val Loss: 0.4518\n",
      "Epoch [5721/10000], Train Loss: 0.3361, Val Loss: 0.4103\n",
      "Epoch [5722/10000], Train Loss: 0.3362, Val Loss: 0.4192\n",
      "Epoch [5723/10000], Train Loss: 0.3360, Val Loss: 0.4105\n",
      "Epoch [5724/10000], Train Loss: 0.3361, Val Loss: 0.3991\n",
      "Epoch [5725/10000], Train Loss: 0.3360, Val Loss: 0.4068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m## Calculate average training loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spacesci/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spacesci/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/spacesci/lib/python3.10/site-packages/torch/optim/adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    235\u001b[0m         group,\n\u001b[1;32m    236\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         state_steps,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/spacesci/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spacesci/lib/python3.10/site-packages/torch/optim/adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spacesci/lib/python3.10/site-packages/torch/optim/adam.py:684\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    682\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 684\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[1;32m    686\u001b[0m     ]\n\u001b[1;32m    687\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[1;32m    689\u001b[0m     ]\n\u001b[1;32m    691\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "File \u001b[0;32m~/miniconda3/envs/spacesci/lib/python3.10/site-packages/torch/optim/adam.py:684\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    682\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt)\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 684\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[1;32m    686\u001b[0m     ]\n\u001b[1;32m    687\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[1;32m    689\u001b[0m     ]\n\u001b[1;32m    691\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(n_hidden, n_lstm_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "## Training loop\n",
    "best_val_loss = 1e9\n",
    "best_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "    ## Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    ## Calculate average training loss\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    \n",
    "    ## Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    ## Calculate average validation loss\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    ## Print training and validation loss\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    ## Save the model if validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. Saving model...')\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        \n",
    "        ## Save the model checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': best_epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_val_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, f'./results/model{round(best_val_loss*10000)}.pth')\n",
    "        torch.save(checkpoint, './results/best_model.pth')\n",
    "        \n",
    "print('Training Complete...')\n",
    "print(f'Best model saved at epoch {best_epoch} with validation loss: {best_val_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacesci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
